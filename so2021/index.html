<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="author" content="Jesús Torres">
<title>Sistemas Operativos</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
    .imageblock {
        text-align: center;
    }
    .imageblock > .content {
        margin-bottom: 1rem;
    }
    .imageblock > .title {
        text-align: inherit;
    }
</style>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Sistemas Operativos</h1>
<div class="details">
<span id="author" class="author">Jesús Torres</span><br>
<span id="email" class="email"><a href="mailto:jmtorres@ull.es">jmtorres@ull.es</a></span><br>
<span id="revdate">Curso 2020-2021</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Tabla de Contenido</div>
<ul class="sectlevel1">
<li><a href="#_ejemplos_de_código">Ejemplos de código</a></li>
<li><a href="#_introducción">Parte I: Introducción</a>
<ul class="sectlevel1">
<li><a href="#_qué_es_un_sistema_operativo">1. ¿Qué es un sistema operativo?</a>
<ul class="sectlevel2">
<li><a href="#_definición_de_sistema_operativo">1.1. Definición de sistema operativo</a></li>
<li><a href="#_funciones_del_sistema_operativo">1.2. Funciones del sistema operativo</a></li>
</ul>
</li>
<li><a href="#_tipos_de_sistemas_operativos">2. Tipos de sistemas operativos</a>
<ul class="sectlevel2">
<li><a href="#_mainframe">2.1. Mainframe</a></li>
<li><a href="#_sistemas_de_escritorio">2.2. Sistemas de escritorio</a></li>
<li><a href="#_sistemas_de_mano">2.3. Sistemas de mano</a></li>
<li><a href="#_sistemas_multiprocesador">2.4. Sistemas multiprocesador</a></li>
<li><a href="#_sistemas_distribuidos">2.5. Sistemas distribuidos</a></li>
<li><a href="#_sistemas_en_cluster">2.6. Sistemas en cluster</a></li>
<li><a href="#_sistemas_de_tiempo_real">2.7. Sistemas de tiempo real</a></li>
</ul>
</li>
<li><a href="#_historia_de_los_sistemas_operativos">3. Historia de los sistemas operativos</a>
<ul class="sectlevel2">
<li><a href="#_historia_primera_generación">3.1. 1ª Generación (1945-55)</a></li>
<li><a href="#_historia_segunda_generación">3.2. 2ª Generación (1955-64)</a></li>
<li><a href="#_historia_tercera_generación">3.3. 3ª Generación (1965-1968)</a></li>
<li><a href="#_historia_cuarta_generación">3.4. 4ª Generación (1965-1980)</a></li>
<li><a href="#_5º_generación_desde_1980">3.5. 5º Generación (desde 1980):</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_organización_de_los_sistemas_operativos">Parte II: Organización de los sistemas operativos</a>
<ul class="sectlevel1">
<li><a href="#_componentes_del_sistema">4. Componentes del sistema</a>
<ul class="sectlevel2">
<li><a href="#_gestión_de_procesos">4.1. Gestión de procesos</a></li>
<li><a href="#_gestión_de_la_memoria_principal">4.2. Gestión de la memoria principal</a></li>
<li><a href="#_gestión_del_sistema_de_es">4.3. Gestión del sistema de E/S</a></li>
<li><a href="#_gestión_del_almacenamiento_secundario">4.4. Gestión del almacenamiento secundario</a></li>
<li><a href="#_gestión_del_sistema_de_archivos">4.5. Gestión del sistema de archivos</a></li>
<li><a href="#_gestión_de_red">4.6. Gestión de red</a></li>
<li><a href="#_protección_y_seguridad">4.7. Protección y seguridad</a></li>
</ul>
</li>
<li><a href="#_servicios_del_sistema">5. Servicios del sistema</a>
<ul class="sectlevel2">
<li><a href="#_servicios_que_garantizan_el_funcionamiento_eficiente_del_sistema">5.1. Servicios que garantizan el funcionamiento eficiente del sistema</a></li>
<li><a href="#_servicios_útiles_para_el_usuario">5.2. Servicios útiles para el usuario</a></li>
<li><a href="#_interfaz_de_usuario">5.3. Interfaz de usuario</a></li>
</ul>
</li>
<li><a href="#_interfaz_de_programación_de_aplicaciones">6. Interfaz de programación de aplicaciones</a>
<ul class="sectlevel2">
<li><a href="#_interfaces_de_programación_de_aplicaciones">6.1. Interfaces de programación de aplicaciones</a></li>
<li><a href="#_llamadas_al_sistema">6.2. Llamadas al sistema</a></li>
<li><a href="#_librería_del_sistema">6.3. Librería del sistema</a></li>
<li><a href="#_librería_estándar">6.4. Librería estándar</a></li>
<li><a href="#_con_todas_las_piezas_juntas">6.5. Con todas las piezas juntas</a></li>
</ul>
</li>
<li><a href="#_operación_del_sistema_operativo">7. Operación del sistema operativo</a>
<ul class="sectlevel2">
<li><a href="#_software_controlado_mediante_interrupciones">7.1. Software controlado mediante interrupciones</a></li>
<li><a href="#_operación_en_modo_dual">7.2. Operación en modo dual</a></li>
<li><a href="#_protección_de_la_memoria">7.3. Protección de la memoria</a></li>
<li><a href="#_el_temporizador">7.4. El temporizador</a></li>
<li><a href="#_maquinas_virtuales">7.5. Maquinas virtuales</a></li>
<li><a href="#_arranque_del_sistema">7.6. Arranque del sistema</a></li>
</ul>
</li>
<li><a href="#_sistemas_operativos_por_su_estructura">8. Sistemas operativos por su estructura</a>
<ul class="sectlevel2">
<li><a href="#_estructura_sencilla">8.1. Estructura sencilla</a></li>
<li><a href="#_estructura_en_capas">8.2. Estructura en capas</a></li>
<li><a href="#_microkernel">8.3. Microkernel</a></li>
<li><a href="#_estructura_modular">8.4. Estructura modular</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_gestión_de_procesos_2">Parte III: Gestión de procesos</a>
<ul class="sectlevel1">
<li><a href="#_procesos">9. Procesos</a>
<ul class="sectlevel2">
<li><a href="#_el_proceso">9.1. El proceso</a></li>
<li><a href="#_estados_de_los_procesos">9.2. Estados de los procesos</a></li>
<li><a href="#_bloque_de_control_de_proceso">9.3. Bloque de control de proceso</a></li>
<li><a href="#_colas_de_planificación">9.4. Colas de planificación</a></li>
<li><a href="#_planificación_de_procesos">9.5. Planificación de procesos</a></li>
<li><a href="#_cambio_de_contexto">9.6. Cambio de contexto</a></li>
<li><a href="#_operaciones_sobre_los_procesos">9.7. Operaciones sobre los procesos</a></li>
<li><a href="#_procesos_cooperativos">9.8. Procesos cooperativos</a></li>
</ul>
</li>
<li><a href="#_comunicación_mediante_de_paso_de_mensajes">10. Comunicación mediante de paso de mensajes</a>
<ul class="sectlevel2">
<li><a href="#_tamaño_del_mensaje">10.1. Tamaño del mensaje</a></li>
<li><a href="#_referenciación">10.2. Referenciación</a></li>
<li><a href="#_buffering_2">10.3. Buffering</a></li>
<li><a href="#_operaciones_síncronas_y_asíncronas">10.4. Operaciones síncronas y asíncronas</a></li>
<li><a href="#_ejemplos_de_sistemas_de_paso_de_mensajes">10.5. Ejemplos de sistemas de paso de mensajes</a></li>
</ul>
</li>
<li><a href="#_memoria_compartida">11. Memoria compartida</a>
<ul class="sectlevel2">
<li><a href="#_memoria_compartida_anónima">11.1. Memoria compartida anónima</a></li>
<li><a href="#_memoria_compartida_con_nombre">11.2. Memoria compartida con nombre</a></li>
</ul>
</li>
<li><a href="#_hilos">12. Hilos</a>
<ul class="sectlevel2">
<li><a href="#_introducción_2">12.1. Introducción</a></li>
<li><a href="#_modelos_multihilo">12.2. Modelos multihilo</a></li>
<li><a href="#_otras_consideraciones_sobre_los_hilos">12.3. Otras consideraciones sobre los hilos</a></li>
</ul>
</li>
<li><a href="#_sincronización">13. Sincronización</a>
<ul class="sectlevel2">
<li><a href="#_el_problema_de_las_secciones_críticas">13.1. El problema de las secciones críticas</a></li>
<li><a href="#_semáforos_mutex_y_spinlocks">13.2. Semáforos, <em>mutex</em> y <em>spinlocks</em></a></li>
</ul>
</li>
<li><a href="#_planificación_de_la_cpu">14. Planificación de la CPU</a>
<ul class="sectlevel2">
<li><a href="#_planificación_expropiativa">14.1. Planificación expropiativa</a></li>
<li><a href="#_el_asignador">14.2. El asignador</a></li>
<li><a href="#_criterios_de_planificación">14.3. Criterios de planificación</a></li>
<li><a href="#_ciclo_de_ráfagas_de_cpu_y_de_es">14.4. Ciclo de ráfagas de CPU y de E/S</a></li>
<li><a href="#_planificación">14.5. Planificación</a></li>
<li><a href="#_planificación_de_tiempo_real">14.6. Planificación de tiempo real</a></li>
<li><a href="#_planificación_en_sistemas_multiprocesador">14.7. Planificación en sistemas multiprocesador</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_gestión_de_la_memoria">Parte IV: Gestión de la memoria</a>
<ul class="sectlevel1">
<li><a href="#_memoria_principal">15. Memoria principal</a>
<ul class="sectlevel2">
<li><a href="#_reubicación_de_las_direcciones">15.1. Reubicación de las direcciones</a></li>
<li><a href="#_enlazado_dinámico_y_librerías_compartidas">15.2. Enlazado dinámico y librerías compartidas</a></li>
<li><a href="#_asignación_de_memoria_contigua">15.3. Asignación de memoria contigua</a></li>
</ul>
</li>
<li><a href="#_paginación">16. Paginación</a>
<ul class="sectlevel2">
<li><a href="#_método_básico">16.1. Método básico</a></li>
<li><a href="#_soporte_hardware_de_la_tabla_de_páginas">16.2. Soporte hardware de la tabla de páginas</a></li>
<li><a href="#_protección">16.3. Protección</a></li>
<li><a href="#_páginas_compartidas">16.4. Páginas compartidas</a></li>
</ul>
</li>
<li><a href="#_paginación_bajo_demanda">17. Paginación bajo demanda</a>
<ul class="sectlevel2">
<li><a href="#_memoria_virtual">17.1. Memoria virtual</a></li>
<li><a href="#_método_básico_2">17.2. Método básico</a></li>
<li><a href="#_requerimientos_de_la_paginación_bajo_demanda">17.3. Requerimientos de la paginación bajo demanda</a></li>
<li><a href="#_rendimiento_de_la_paginación_bajo_demanda">17.4. Rendimiento de la paginación bajo demanda</a></li>
<li><a href="#_copy_on_write">17.5. Copy-on-write</a></li>
<li><a href="#_archivos_mapeados_en_memoria">17.6. Archivos mapeados en memoria</a></li>
<li><a href="#_reemplazo_de_página">17.7. Reemplazo de página</a></li>
<li><a href="#_asignación_de_marcos_de_página">17.8. Asignación de marcos de página</a></li>
<li><a href="#_hiperpaginación">17.9. Hiperpaginación</a></li>
<li><a href="#_otras_consideraciones">17.10. Otras consideraciones</a></li>
</ul>
</li>
<li><a href="#_interfaz_de_gestión_de_la_memoria">18. Interfaz de gestión de la memoria</a>
<ul class="sectlevel2">
<li><a href="#_uso_del_espacio_de_direcciones_virtual_del_proceso">18.1. Uso del espacio de direcciones virtual del proceso</a></li>
<li><a href="#_gestión_de_la_memoria_del_montón">18.2. Gestión de la memoria del montón</a></li>
<li><a href="#_fragmentación">18.3. Fragmentación</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_gestión_del_almacenamiento">Parte V: Gestión del almacenamiento</a>
<ul class="sectlevel1">
<li><a href="#_dispositivos_de_almacenamiento">19. Dispositivos de almacenamiento</a>
<ul class="sectlevel2">
<li><a href="#_discos_magnéticos">19.1. Discos magnéticos</a></li>
<li><a href="#_discos_ópticos">19.2. Discos ópticos</a></li>
<li><a href="#_memorias_de_estado_sólido">19.3. Memorias de estado sólido</a></li>
</ul>
</li>
<li><a href="#_archivos_y_sistemas_de_archivos">20. Archivos y sistemas de archivos</a></li>
<li><a href="#_volúmenes_de_datos">21. Volúmenes de datos</a>
<ul class="sectlevel2">
<li><a href="#_raid">21.1. RAID</a></li>
<li><a href="#_particiones">21.2. Particiones</a></li>
<li><a href="#_volúmenes_dinámicos">21.3. Volúmenes dinámicos</a></li>
</ul>
</li>
<li><a href="#_sistemas_de_archivos">22. Sistemas de archivos</a>
<ul class="sectlevel2">
<li><a href="#_estructura_de_un_sistema_de_archivos">22.1. Estructura de un sistema de archivos</a></li>
<li><a href="#_estructuras_de_metadatos">22.2. Estructuras de metadatos</a></li>
<li><a href="#_montaje_de_sistemas_de_archivos">22.3. Montaje de sistemas de archivos</a></li>
<li><a href="#_archivos">22.4. Archivos</a></li>
<li><a href="#_estructura_de_directorios">22.5. Estructura de directorios</a></li>
</ul>
</li>
<li><a href="#_compartición_de_archivos">23. Compartición de archivos</a>
<ul class="sectlevel2">
<li><a href="#_múltiples_usuarios_y_protección">23.1. Múltiples usuarios y protección</a></li>
<li><a href="#_semántica_de_coherencia">23.2. Semántica de coherencia</a></li>
<li><a href="#_bloqueos_de_archivo">23.3. Bloqueos de archivo</a></li>
</ul>
</li>
<li><a href="#_coherencia">24. Coherencia</a>
<ul class="sectlevel2">
<li><a href="#_comprobación_de_coherencia">24.1. Comprobación de coherencia</a></li>
<li><a href="#_soft_updates">24.2. Soft Updates</a></li>
<li><a href="#_sistemas_de_archivos_basados_en_registro">24.3. Sistemas de archivos basados en registro</a></li>
<li><a href="#_sistemas_de_archivos_basados_en_copia_durante_la_escritura">24.4. Sistemas de archivos basados en copia durante la escritura</a></li>
</ul>
</li>
<li><a href="#_implementación_de_sistemas_de_archivos">25. Implementación de sistemas de archivos</a>
<ul class="sectlevel2">
<li><a href="#_implementación_de_directorios">25.1. Implementación de directorios</a></li>
<li><a href="#_métodos_de_asignación">25.2. Métodos de asignación</a></li>
<li><a href="#_gestión_del_espacio_libre">25.3. Gestión del espacio libre</a></li>
<li><a href="#_sistemas_de_archivos_virtuales">25.4. Sistemas de archivos virtuales</a></li>
</ul>
</li>
<li><a href="#_planificación_de_disco">26. Planificación de disco</a>
<ul class="sectlevel2">
<li><a href="#_rendimiento_del_acceso_a_disco">26.1. Rendimiento del acceso a disco</a></li>
<li><a href="#_cola_de_es_al_disco">26.2. Cola de E/S al disco</a></li>
<li><a href="#_planificación_fcfs">26.3. Planificación FCFS</a></li>
<li><a href="#_planificación_sstf">26.4. Planificación SSTF</a></li>
<li><a href="#_planificación_scan_y_c_scan">26.5. Planificación SCAN y C-SCAN</a></li>
<li><a href="#_planificación_look_y_c_look">26.6. Planificación LOOK y C-LOOK</a></li>
<li><a href="#_planificación_n_step_scan_n_step_look_y_fscan">26.7. Planificación N-Step-SCAN, N-Step-LOOK y FSCAN</a></li>
<li><a href="#_planificación_cfq">26.8. Planificación CFQ</a></li>
</ul>
</li>
<li><a href="#_bibliografía">Bibliografía</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_ejemplos_de_código">Ejemplos de código</h2>
<div class="sectionbody">
<div class="paragraph">
<p>En algunos capítulos se enlazan ejemplos de código para ilustrar en mayor detalle los conceptos tratados.
Todos los ejemplos están disponibles en el repositorio <span class="icon"><i class="fa fa-github"></i></span> <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/tree/master">ull-esit-sistemas-operativos/ssoo-ejemplos</a>, de donde se pueden descargar.</p>
</div>
<div class="paragraph">
<p>Para compilar los ejemplos, es necesario disponer de herramientas de desarrollo para C y C++.
Por ejemplo, en la distribución Debian de GNU/Linux y derivadas —como Ubuntu o Linux Mint— basta con tener instalados los paquetes <strong>build-essential</strong> y <strong>cmake</strong>.
Mientras que en Microsoft Windows hacen falta las <a href="https://go.microsoft.com/fwlink/?linkid=840931"><strong>Visual Studio Build Tools</strong></a>.</p>
</div>
<div class="paragraph">
<p>Para compilar es necesario hacer lo siguiente desde la línea de comandos:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Ir al directorio raíz del repositorio descargado y descomprimido.</p>
</li>
<li>
<p>Ejecutar <code>cmake -B build</code> para configurar el proyecto.</p>
</li>
<li>
<p>Ejecutar <code>cmake --build build</code> para compilar los ejemplos.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>En Microsoft Windows estos comandos deben ejecutarse desde la consola de <strong>Developer Command Prompt</strong>.</p>
</div>
<div class="paragraph">
<p>En cada sistema solo se compilarán los ejemplos compatibles, que se guardarán en el directorio <code>build/bin/</code>, desde dónde se pueden ejecutar para probarlos.</p>
</div>
<div class="paragraph">
<p>El código fuente de los ejemplos está en el directorio <code>src/</code>, dentro del subdirectorio numerado con el capítulo correspondiente.</p>
</div>
</div>
</div>
<h1 id="_introducción" class="sect0">Parte I: Introducción</h1>
<div class="sect1">
<h2 id="_qué_es_un_sistema_operativo">1. ¿Qué es un sistema operativo?</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>7 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>¿Qué es un sistema operativo? ¿cuáles son sus responsabilidades en el contexto de un sistema informático? ¿cómo cumple con ellas?
Éstas son algunas de las cuestiones que responderemos en este capítulo.
Aunque, cómo veremos, no son preguntas sencillas de responder.</p>
</div>
<div class="sect2">
<h3 id="_definición_de_sistema_operativo">1.1. Definición de sistema operativo</h3>
<div class="paragraph">
<p>En general no existe una definición universal de lo qué es un <strong>sistema operativo</strong>, aunque si muchas propuestas de diferentes autores:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Hay quién considera que simplemente es una cuestión del mercado: «lo que nos venden cuando llegamos a una tienda y pedimos un sistema operativo».</p>
<div class="paragraph">
<p>En realidad esta definición no es muy precisa, puesto que las características incluidas pueden variar enormemente de un sistema a otro.
Por ejemplo, algunos sistemas operativos apenas alcanzan el megabyte de espacio, careciendo incluso de las aplicaciones más básicas, mientras que otros ocupan gigabytes de espacio, incluyen una interfaz gráfica basada en ventanas y las aplicaciones más comunes que cualquier usuario puede necesitar.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Aunque pueda parecer lo contrario, la cuestión de qué componentes son parte o no de un sistema operativo no es trivial. Por ejemplo, Microsoft y el Departamento de Justicia de los Estados Unidos se enfrentaron en 1998 por la inclusión del navegador Internet Explorer como parte del sistema operativo Microsoft Windows.</p>
</div>
<div class="paragraph">
<p>Microsoft afirmaba que ambos productos eran realmente uno solo y que su unión fue el resultado de un proceso de innovación.
Mientras tanto, la otra parte alegaba que el navegador era un producto distinto y separado, que no formaba parte del sistema operativo y que todo el asunto restringía la libre competencia en el mercado de los navegadores.</p>
</div>
<div class="paragraph">
<p>Seguramente en 1998 los argumentos del Departamento de Justicia de los Estados Unidos tenían mucho sentido, ¿pero qué ocurriría si se planteara este mismo asunto en la actualidad?.
¿Concibes que tu móvil o tu ordenador no trajeran de serie un navegador?</p>
</div>
<div class="paragraph">
<p>Para más información, véase <a href="https://es.wikipedia.org/wiki/Caso_Estados_Unidos_contra_Microsoft">«Caso Estados Unidos contra Microsoft&#8201;&#8212;&#8201;Wikipedia»</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Una definición mucho más común es que el sistema operativo es «aquel programa que se ejecuta continuamente en el ordenador» —lo que denominamos comúnmente como <em><strong>kernel</strong></em> o <strong>núcleo</strong> del sistema— siendo todo lo demás programas del sistema y aplicaciones.</p>
<div class="paragraph">
<p>Sin embargo, en algunos casos ésta definición excluye como parte del sistema operativo algunos servicios que intuitivamente solemos considerar dentro del mismo.
Por ejemplo, si aplicamos esta definición a los sistemas operativos de estructura microkernel, no podríamos decir que servicios básicos como la comunicación en red, los sistemas de archivos y la gestión de la memoria son parte del sistema operativo.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Como veremos en el <a href="#_microkernel">Apartado 8.3</a>, en los sistemas operativos <em>microkernel</em> la funcionalidad implementada en el núcleo del sistema es la mínima necesaria.
Por lo tanto, según la definición anterior, muchos de los componentes y servicios básicos que damos por supuestos a un sistema operativo no formarían parte del mismo en ese tipo de sistemas.</p>
</div>
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_funciones_del_sistema_operativo">1.2. Funciones del sistema operativo</h3>
<div class="paragraph">
<p>Por lo que hemos visto hasta ahora, parece evidente que no es sencillo definir lo que «es» un sistema operativo.
Sin embargo, es posible que tengamos más suerte definiéndolo a través de lo que «hace».
Es decir, describiendo sus funciones dentro de un sistema informático cualquiera.</p>
</div>
<div id="componentes_sistema_informático" class="imageblock">
<div class="content">
<img src="C01-definición/images/componentes_sistema_informático.svg" alt="componentes sistema informático">
</div>
<div class="title">Figura 1. Vista abstracta de los componentes de un sistema informático.</div>
</div>
<div class="paragraph">
<p>Un <strong>sistema informático</strong> puede ser dividido, <em>grosso modo</em>, en cuatro componentes: el hardware, los usuarios, los programas de aplicación y el sistema operativo (véase la <a href="#componentes_sistema_informático">Figura 1</a>):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Programas de aplicación</strong>. El objetivo fundamental de cualquier sistema informático es ejecutar programas para resolver los problemas informáticos de los usuarios.
Con ese objetivo se construye su hardware y se desarrollan los programas de aplicación —procesadores de textos, hojas de cálculo, compiladores, navegadores de Internet, etc.— que usan los usuarios para resolver sus problemas.</p>
</li>
<li>
<p><strong>Hardware</strong>. El hardware —la CPU, la memoria, los dispositivos de entrada salida, etc.— proporcionan los recursos computacionales del sistema informático.
Los programas de aplicación necesitan usar estos recursos computacionales para resolver los problemas informáticos de los usuarios.</p>
</li>
<li>
<p><strong>Sistema operativo</strong>. En un sistema informático las aplicaciones necesitan realizar operaciones comunes, como acceder a los dispositivos de E/S o reservar porciones de la memoria.
En lugar de que cada aplicación intente hacerlo por su cuenta, es mucho más sencillo que estas operaciones comunes estén centralizadas en el sistema operativo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Por lo tanto, el sistema operativo controla, coordina el acceso y asigna los recursos computacionales del hardware a los distintos programas de aplicación.</p>
</div>
<div class="paragraph">
<p>En realidad ésta es solo una de las dos perspectivas desde las que se pueden analizar las funciones del sistema operativo.
Es la denominada como: <strong>perspectiva del sistema informático</strong>, mientras que la otra es la <strong>perspectiva del usuario</strong>.</p>
</div>
<div class="sect3">
<h4 id="_perspectiva_del_sistema_informático">1.2.1. Perspectiva del sistema informático</h4>
<div class="paragraph">
<p>Un sistema informático tiene múltiples recursos hardware, como son: tiempo de CPU, espacio de memoria, espacio de almacenamiento de archivos, dispositivos de E/S, etc.
También tiene recursos software ofrecidos por algunos programas que se ejecutan en el sistema, como son: servicios de red, servicios de impresión, seguridad, etc.—.
Estos recursos los necesitan los programas de aplicación para resolver los problemas informáticos de los usuarios.</p>
</div>
<div class="paragraph">
<p>Dentro del sistema informático, el sistema operativo es el programa más íntimamente relacionado con el hardware y su función es gestionar los recursos hardware y software disponibles, asignarlos a los diferentes programas, resolver los conflictos en las peticiones y hacer que el sistema opere eficientemente para resolver los problemas de los usuarios.</p>
</div>
<div class="paragraph">
<p>Además, el sistema operativo es el programa encargado del control de la ejecución de los programas de los usuarios, por lo que tiene la tarea de prevenir errores y el uso inadecuado del ordenador.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>En resumen, desde la perspectiva del sistema informático, las funciones del <strong>sistema operativo</strong> son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Gestionar los recursos computacionales del sistema informático.</p>
</li>
<li>
<p>Controlar la ejecución de los programas de usuario y el acceso a los dispositivos de E/S.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Un <strong>sistema operativo</strong>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>No hace trabajo directamente útil para los usuarios.</p>
</li>
<li>
<p>Pero proporciona un entorno adecuado para que los programas de aplicación lo hagan.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Los sistemas operativos existen porque es más sencillo crear sistemas informáticos útiles para los usuarios con ellos que sin ellos.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_perspectiva_del_usuario">1.2.2. Perspectiva del usuario</h4>
<div class="paragraph">
<p>Si intentamos definir las funciones del sistema operativo desde nuestra experiencia como usuarios, seguramente haríamos referencia a la interfaz que nos proporciona para utilizar el sistema informático.
Sin embargo, debemos tener en cuenta que la interfaz varía con el tipo de sistema, por lo que definir las funciones del sistema operativo desde la perspectiva del usuario es mucho más difícil.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, los usuarios que se sientan frente a un sistema de escritorio disponen de: monitor, teclado, ratón y una unidad central.
Estos sistemas se diseñan buscando la máxima productividad en equipos donde un usuario monopoliza todos los recursos; por lo que el sistema operativo se diseña considerando fundamentalmente la facilidad de uso, poniendo algo de atención en el rendimiento y nada en el aprovechamiento de los recursos.</p>
</div>
<div class="paragraph">
<p>Esto difiere mucho de otro tipo de sistema informático dónde múltiples usuarios se sientan frente a terminales conectadas a un gran ordenador central.
Así todos los usuarios comparten los recursos del sistema informático y pueden intercambiar información entre sí.
En este tipo de sistemas el sistema operativo maximiza el aprovechamiento de los recursos con el objeto de garantizar que toda la CPU, memoria y E/S son empleadas de forma eficiente y que ningún usuario utiliza más de lo que le corresponde.
Obviamente, en este tipo de sistemas la facilidad de uso está en un segundo plano.</p>
</div>
<div class="paragraph">
<p>Otros sistemas operativos se diseñan para sistemas informáticos que tienen poca o ninguna interacción con los usuarios.
Es, por ejemplo, el caso de los sistema empotrados de los electrodomésticos.</p>
</div>
<div class="paragraph">
<p>Todos estos tipos de sistemas tienen interfaces muy diferentes, lo que dificulta obtener una definición única de sistema operativo desde la perspectiva del usuario.</p>
</div>
<div class="paragraph">
<p>En los tres casos los objetivos con los que se diseña el sistema operativo son opuestos, por lo que seguramente sea diferente «lo que tiene que hacer» cada sistema operativo para alcanzarlos.
Sin embargo, en los tres casos el sistema operativo es el responsable de la gestión de los recursos computacionales y del control de los programas, funciones que definimos anteriormente desde la perspectiva del sistema informático y que no cambian de un tipo de sistema a otro.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tipos_de_sistemas_operativos">2. Tipos de sistemas operativos</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>22 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Ahora que sabemos que todos los sistemas operativos hacen lo mismo pero que el «cómo» lo hacen difiere de un tipo de sistema informático a otro, vamos a ver los tipos de sistemas informáticos, las características de los sistemas operativos que los gestionan y cómo han evolucionado a lo largo de la historia.</p>
</div>
<div class="sect2">
<h3 id="_mainframe">2.1. Mainframe</h3>
<div class="paragraph">
<p>Los <strong>ordenadores centrales</strong> o <em><strong>mainframes</strong></em> fueron los primeros computadores utilizados en muchas aplicaciones comerciales y científicas.
Se caracterizan no tanto por la potencia de su CPU como por su: gran capacidad de memoria, gran capacidad de almacenamiento secundario, gran cantidad de dispositivos de E/S y rapidez de éstos y alta fiabilidad.</p>
</div>
<div class="paragraph">
<p>Los <em>mainframes</em> pueden funcionar durante años sin problemas ni interrupciones y las reparaciones se realizan sin detener su funcionamiento.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>La mayor diferencia entre los superordenadores y los <em>mainframes</em> está en que los primeros se centran en resolver problemas limitados por la velocidad de cálculo —lo cual requiere miles de CPU de alto rendimiento— mientras que los segundos se centran en la fiabilidad y en problemas limitados por la E/S —por lo que los <em>mainframes</em> suelen tener «solo» entre una y varias docenas de CPU—.</p>
</div>
<div class="paragraph">
<p>Para más información sobre los <em>mainframes</em>, véase <a href="http://es.wikipedia.org/wiki/Ordenador_central">«Ordenador central&#8201;&#8212;&#8201;Wikipedia»</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Los <em>mainframes</em> aparecieron a finales de la década de los 50 del siglo pasado y han seguido evolucionando hasta la actualidad, por lo que dentro de este tipo de sistemas nos encontramos con varios categorías.</p>
</div>
<div class="sect3">
<h4 id="_sistemas_de_procesamiento_por_lotes">2.1.1. Sistemas de procesamiento por lotes</h4>
<div class="paragraph">
<p>
</p>
</div>
<div class="paragraph">
<p>Los primeros <em>mainframe</em> eran enormes máquinas operadas desde una consola y conectados a lectores de tarjetas perforadas, dispositivos de cinta e impresoras.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Para imágenes y más información sobre las tarjetas perforadas, véase <a href="https://en.wikipedia.org/wiki/Computer_programming_in_the_punched_card_era">«Computer programming in the punched card era&#8201;&#8212;&#8201;Wikipedia»</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>El trabajo era preparado por cada programador —normalmente en tarjetas perforadas— y entregado al operador del sistema, que era quién tenía acceso al sistema y la responsabilidad de ejecutar los programas y devolver los resultados al programador correspondiente.</p>
</div>
<div class="paragraph">
<p>No había sistema operativo y el operador debía cargar y ejecutar cada programa de uno en uno.</p>
</div>
<div id="consola_ibm_705" class="imageblock">
<div class="content">
<img src="C02-tipos_de_sistemas/images/consola_ibm_705.jpg" alt="consola ibm 705">
</div>
<div class="title">Figura 2. Operadora en la consola de un mainframe IBM 705&#8201;&#8212;&#8201;Fuente: <a href="https://www.ibm.com/ibm/history/ibm100/images/icp/Y444110I58591Z46/us__en_us__ibm100__700_series__705__620x350.jpg">IBM</a></div>
</div>
<div class="paragraph">
<p>Estos sistemas se convirtieron en <strong>sistemas de procesamiento por lotes</strong> o <strong>sistemas en <em>batch</em></strong> cuando se comenzó a utilizar un pequeño programa —llamado <strong>monitor del sistema</strong>— cuya función era cargar y ejecutar sin interrupción un conjunto —o lote— de programas.</p>
</div>
<div class="paragraph">
<p>Para preparar los lotes, por lo general, el operador cargaba previamente en cinta magnética el conjunto de programas a partir de las tarjetas perforadas proporcionadas por los programadores.
Para ello se utilizaba un lector de tarjetas autónomo, independiente del <em>mainframe</em>.</p>
</div>
<div id="sistemas_procesamiento_lotes" class="imageblock">
<div class="content">
<img src="C02-tipos_de_sistemas/images/sistemas_procesamiento_lotes.svg" alt="sistemas procesamiento lotes">
</div>
<div class="title">Figura 3. Organización de la memoria en sistemas de procesamiento por lotes.</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>El <strong>monitor del sistema</strong> es un predecesor de los sistemas operativos y tenía las siguientes características:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Permanecía cargado durante todo el tiempo en la memoria del sistema (véase la <a href="#sistemas_procesamiento_lotes">Figura 3</a>).</p>
</li>
<li>
<p>Su única tarea era cargar y transferir automáticamente la ejecución de un programa al siguiente cuando el anterior terminaba.</p>
</li>
<li>
<p>El mayor inconveniente de este tipo de sistemas era que la CPU permanecía mucho tiempo desocupada porque era —y sigue siendo— varios ordenes de magnitud más rápida que los dispositivos de E/S.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Cualquier programa necesita realizar operaciones de E/S para obtener los datos requeridos para sus cálculos —guardados en tarjetas perforadas y unidades de cinta o, si hablamos de hoy en día, en discos duros y memorias USB—.
También necesita hacer operaciones de E/S para guardar o imprimir los resultados de esos cálculos.</p>
</div>
<div class="paragraph">
<p>Si solo se puede ejecutar un programa la vez, cuando el programa solicita una operación de E/S, la CPU queda a la espera de que esta termine para continuar con la ejecución del programa, por lo que se pierde tiempo de CPU en no hacer nada.
Este desaprovechamiento de la CPU es peor cuanto más rápida es la CPU respecto a los dispositivos de E/S.</p>
</div>
</div>
<div class="sect3">
<h4 id="_sistemas_multiprogramados">2.1.2. Sistemas multiprogramados</h4>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>La solución al inconveniente de los sistemas de procesamiento por lotes con la E/S fue que los programas no accedieran directamente al dispositivo de E/S, sino que, en su lugar, solicitaran la operación al <strong>monitor del sistema</strong> para que éste la solicitara al hardware.
Así el sistema operativo —como podemos comenzar a llamarlo— tiene la oportunidad de sustituir el programa en la CPU por otro, mientras la operación de E/S se completa.</p>
</div>
<div class="paragraph">
<p>Además, con la aparición de la tecnología de los discos magnéticos en la década de los 60 del siglo pasado, los trabajos de los programadores comenzaron a ser almacenados en discos, desde donde eran escogidos por el sistema operativo para su ejecución.</p>
</div>
<div class="paragraph">
<p>A estos sistemas se los llamó <strong>multiprogramados</strong>.</p>
</div>
<div id="sistemas_multiprogramados" class="imageblock">
<div class="content">
<img src="C02-tipos_de_sistemas/images/sistemas_multiprogramados.svg" alt="sistemas multiprogramados">
</div>
<div class="title">Figura 4. Organización de la memoria en sistemas multiprogramados.</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>En los <strong>sistemas multiprogramados</strong> la ejecución de los trabajos funcionaba de la siguiente manera:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>En el disco magnético se almacenaba una cola donde se iban colocando todos los trabajos que tenían que ser ejecutados.</p>
</li>
<li>
<p>El sistema operativo cargaba varios trabajos en memoria del conjunto de trabajos en la cola en el disco magnético (véase la <a href="#sistemas_multiprogramados">Figura 4</a>).</p>
</li>
<li>
<p>El sistema operativo cede la CPU a uno de los trabajos en memoria.</p>
</li>
<li>
<p>Cuando el trabajo en la CPU requería usar la E/S se lo pedía al sistema operativo.
En lugar de mantener a la CPU ocupada inútilmente, el sistema operativo programaba la operación de E/S pero escogía otro trabajo de entre los que estaban en memoria y lo ejecutaba en la CPU.</p>
<div class="paragraph">
<p>Cuando la operación de E/S del anterior trabajo terminaba, el programa que ocupaba la CPU no era interrumpido, sino que debía esperar a una nueva oportunidad de ser escogido para ejecutarse en la CPU.</p>
</div>
</li>
<li>
<p>Cuando un programa en la CPU terminaba, sus recursos se liberaban, dejando memoria libre.
Por lo tanto, el sistema operativo escogía un nuevo trabajo de la cola de trabajos en el disco magnético y lo cargaba en la memoria.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Todo este proceso se repetía mientras hubiera trabajos que ejecutar en la cola de trabajos en el disco.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Para operar de la forma descrita es necesario que el sistema operativo realice tres tareas esenciales:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La <strong>planificación de trabajos</strong>, cuya responsabilidad es seleccionar el siguiente trabajo que será cargado en la memoria principal para mantenerla llena.</p>
</li>
<li>
<p>La <strong>planificación de la CPU</strong>, cuya responsabilidad es elegir el siguiente trabajo que será ejecutado en la CPU, de entre los disponibles en la memoria principal.</p>
</li>
<li>
<p>La <strong>gestión de la memoria</strong>, cuya responsabilidad es repartir la memoria principal entre los trabajos alojados en la misma.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Un ejemplo de este tipo de sistemas operativos es el IBM OS/360, que fue lanzado en 1966 para utilizarlo en los <em>mainframes</em> IBM System/360 (véase el <a href="#_historia_segunda_generación">Apartado 3.2</a>).</p>
</div>
</div>
<div class="sect3">
<h4 id="_sistemas_de_tiempo_compartido">2.1.3. Sistemas de tiempo compartido</h4>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Los sistemas multiprogramados ofrecían un uso más eficiente de la CPU pero no eran capaces de proporcionar interacción directa con los usuarios.
Los programadores seguían teniendo que entregar los trabajos al operador y esperar a que éste les devolviera los resultados.</p>
</div>
<div class="paragraph">
<p>Los <strong>sistemas de tiempo compartido</strong> se desarrollaron tras observar que al dar acceso a un grupo de usuarios se podía conseguir un uso más eficiente del sistema, en comparación a cuando solo podía ser utilizado por un usuario a la vez.
Esto es debido a que, generalmente, un usuario introduce información de forma continua para luego detenerse durante largos periodos de tiempo, mientras que en un grupo de usuarios, las pausas de uno de ellos se pueden llenar con la actividad de los otros.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Los <strong>sistemas de tiempo compartido</strong> se caracterizaban por:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Tener <strong>terminales</strong>, es decir, hardware especializado en hacer de interfaz directa entre los usuarios y el sistema.
A través de estas terminales los usuarios podían dar órdenes al sistema e interactuar con sus trabajos.
Podían haber múltiples usuarios al mismo tiempo pero cada uno solo podía tener un trabajo en ejecución a la vez.</p>
</li>
<li>
<p>Usar la <strong>multiprogramación</strong> para tener varios trabajos en la memoria principal al mismo tiempo e intercambiar el trabajo en la CPU cuando éste solicitaba una operación de E/S, como ya se venía haciendo en los <strong>sistemas multiprogramados</strong> para hacer un uso más eficiente de la CPU.</p>
</li>
<li>
<p>Repartir el tiempo de CPU entre usuarios.
El sistema operativo asignaba un tiempo de CPU a cada usuario —denominado <strong>ventana de tiempo</strong> o <strong>cuanto</strong> de CPU—.
Cuando este tiempo se agotaba, el sistema intercambiaba el trabajo en la CPU por el de otro usuario en el sistema.
La ventana de tiempo era extremadamente pequeña, dando a cada usuario la impresión de que su trabajo nunca se detenía, como si dispusiera de la CPU en exclusiva.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Los sistemas que, como los de tiempo compartido, pueden ser utilizados por varios usuarios simultáneamente se denominan sistemas <strong>multiusuario</strong> .</p>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En los primeros sistemas se usaban <strong>terminales</strong> electro-mecánicos con un teclado y una impresora, como el <a href="https://en.wikipedia.org/wiki/Teletype_Model_33">Teletype Model 3</a> (1963).
Posteriormente llegaron los terminales electrónicos, que usaban un monitor en lugar de una impresora, como el <a href="https://es.wikipedia.org/wiki/IBM_3270">IBM 3270</a>.
En cualquier caso solo disponían del hardware necesario para realizar la tarea de conectar a los usuarios con el ordenador central.</p>
</div>
<div class="paragraph">
<p>Estos terminales no deben confundirse con las terminales por software que traen algunos sistemas operativos modernos.
Las terminales por software o <em>terminales virtuales</em> se programan para emular las especificaciones de alguna versión de esas terminales físicas antiguas que hemos comentado.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Los sistemas de tiempo compartido significaron un salto importante en complejidad por diversas razones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Como varios trabajos están en la memoria principal al mismo tiempo, el sistema operativo requiere mecanismos de <strong>gestión de la memoria</strong> y <strong>protección</strong>.</p>
</li>
<li>
<p>Para tener un tiempo de respuesta razonable, los trabajos deben estar cargados en la memoria principal.
Para que quepan más trabajos de los usuarios en la memoria, el sistema operativo debe utilizar técnicas de <strong>memoria virtual</strong> para ejecutar trabajos que no están completamente cargados en la memoria principal.</p>
</li>
<li>
<p>Como la CPU debe ser compartida entre todos los trabajos, el sistema operativo necesita mecanismos de <strong>planificación de la CPU</strong>.</p>
</li>
<li>
<p>Como varios trabajos pueden tener la necesidad de cooperar y que su ejecución siga cierto orden, el sistema operativo debe proporcionar mecanismos de <strong>sincronización</strong> y <strong>comunicación</strong>.</p>
</li>
<li>
<p>Como el sistema debe disponer de un <strong>sistema de archivos</strong> para repartir el espacio en disco y facilitar a los usuarios el acceso y gestión de sus datos, el sistema operativo necesita un componente de <strong>gestión de discos</strong>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Las primeras versiones de UNIX —lanzado por primera vez en 1970— el sistema operativo VMS —desarrollado en 1978— para los VAX de Digital Equipment Corportation y el IBM OS/400 —introducido en 1988— utilizado en los minicomputadoras AS/400, son algunos ejemplos de sistemas operativos de tiempo compartido (véase el <a href="#_historia_tercera_generación">Apartado 3.3</a>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Estrictamente hablando, el término <strong>sistemas de tiempo compartido</strong> hace referencia a estos <em>mainframes</em> desarrollados a partir de principios de la década de 1970.
Así que no es común utilizarlo con <em>mainframe</em> modernos.</p>
</div>
<div class="paragraph">
<p>Los <em>mainframe</em> modernos permiten a un mismo usuario ejecutar varios trabajos al mismo tiempo, repartiendo el tiempo de CPU entre todos los trabajo en el sistema y no solo entre los usuarios.
Y lo mismo ocurre en la mayor parte de los sistemas operativos de propósito general actuales —utilizados en ordenadores de escritorio, servidores, portátiles y dispositivos móviles— que con el tiempo han copiado muchas características de los <strong>sistemas de tiempo compartido</strong>.
Por eso el termino actuales <strong>sistema multitarea</strong>, que es mucho más general.</p>
</div>
<div class="paragraph">
<p>La <strong>multitarea</strong>  es un método para tener varios procesos en memoria y ejecutarlos «al mismo tiempo».
Generalmente requiere de técnicas de multiprogramación, como las empleadas por los antiguos <strong>sistemas multiprogramados</strong>, y de reparto del tiempo de CPU, como ocurre en los antiguos <strong>sistemas de tiempo compartido</strong>.
Por eso se puede decir que esos dos tipos de sistemas <em>mainframe</em> eran <strong>sistemas multitarea</strong>.
Al igual que lo son los <em>mainframe</em> modernos y muchos sistemas operativos actuales de escritorio y de dispositivos móviles.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_de_escritorio">2.2. Sistemas de escritorio</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>En la década de los 70 del siglo pasado también aparecieron las primeras CPU en microprocesadores y con éstas llegaron las <strong>microcomputadoras</strong> o <strong>microordenadores</strong>.
Las primeras <strong>microcomputadoras</strong> no incluían teclado ni monitor y se programaban usando interruptores y ledes ubicados en el frontal de la unidad.
Pero en torno a 1977 apareció la segunda generación de <strong>microcomputadoras</strong>, que si incluían estos periféricos de E/S, por lo que eran más fáciles de usar que sus predecesoras.
Entonces comenzaron a recibir el nombre de <em>ordenadores domésticos</em> y de su mano llegaron los primeros <strong>sistemas operativos de escritorio</strong>.</p>
</div>
<div id="ordenadores_domésticos_1977" class="imageblock">
<div class="content">
<img src="C02-tipos_de_sistemas/images/ordenadores_domésticos_1977.jpg" alt="ordenadores domésticos 1977">
</div>
<div class="title">Figura 5. Los tres ordenadores que la revista Byte denominó como la "Trinidad de 1977" de la computación doméstica: el <a href="https://es.wikipedia.org/wiki/Commodore_PET">Commodore PET 2001</a>, el <a href="https://es.wikipedia.org/wiki/Apple_II">Apple II</a> y el <a href="https://es.wikipedia.org/wiki/TRS-80">TRS-80 Model I</a>&#8201;&#8212;&#8201;Fuente: <a href="https://commons.wikimedia.org/wiki/File:Trinity77.jpg">Wikipedia</a></div>
</div>
<div class="paragraph">
<p>Los <em>mainframes</em> y las minicomputadoras de la época siguieron siendo los ordenadores corporativos por excelencia, ya que eran mucho más grandes y potentes, y también costosos.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El término en desuso <strong>minicomputadora</strong> o <strong>miniordenador</strong> hace referencia a máquinas multiusuario de rango medio, entre los <em>mainframes</em> y los ordenadores domésticos.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Los primeros <strong>sistemas operativos de escritorio</strong> eran muy básicos.
Por ejemplo, en un sistema diseñado para ser utilizado por un único usuario no tiene sentido implementar un sistema de archivos con permisos.
Así que, los primeros sistemas operativos de escritorio carecían de esta característica que, sin embargo, ya existía en los sistemas de tiempo compartido de la época.
De la misma manera, carecían de otros mecanismos de protección y no eran ni multiusuario ni multitarea.</p>
</div>
<div class="paragraph">
<p>Pese a estas diferencias, los <strong>sistemas operativos de escritorio</strong> se han beneficiado del desarrollo de los sistemas operativos para <em>mainframes</em>.
Los sistemas de escritorio actuales son <strong>multiusuario</strong> y <strong>multitarea</strong>; incluyen sistemas de archivos con permisos, autenticación y mecanismos de protección de la memoria —como medidas para proteger los datos de los usuarios— y han incorporado muchas otras características de los sistemas operativos para <em>mainframe</em>.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Aunque con el tiempo los sistemas de escritorio han ido adquiriendo características desarrolladas en los <em>mainframe</em>, no debemos olvidar que ambos tipos de sistemas se siguen diseñando con objetivos diferentes.
Mientras que en los <em>mainframe</em> se persigue maximizar la fiabilidad y utilización eficiente de los recursos, en los sistemas de escritorio se maximiza la facilidad de uso y el tiempo de respuesta al usuario, poniendo algo de atención al rendimiento.</p>
</div>
<div class="paragraph">
<p>Los <strong>sistemas operativos de escritorio</strong> modernos ya nos son «solo de escritorio» ni se ejecutan únicamente en ordenadores domésticos.
Se utilizan en un altísimo porcentaje en servidores, superordenadores y hasta en dispositivos móviles.
Por eso, en la actualidad, el término <strong>sistema operativo de propósito general</strong>  es mucho más adecuado.</p>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El <strong>tiempo de respuesta</strong> al usuario se puede considerar como el intervalo de tiempo entre un comando de un usuario —por ejemplo un clic— y la respuesta del sistema a dicho comando.
En ocasiones este tiempo se minimiza a costa de un uso menos eficiente de los recursos del sistema, por lo que no es un objetivo deseable para diseñar un <em>mainframe</em>.
Para más información, véase el <a href="#_criterios_de_planificación">Apartado 14.3</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Son muchos los ejemplos de sistemas operativos en esta categoría. Van desde CP/M —lanzado en 1977— hasta los actuales GNU/Linux, Microsoft Windows y Apple macOS, pasando por MS-DOS, IBM OS/2 y todas las versiones anteriores de Microsoft Windows (véase el <a href="#_historia_cuarta_generación">Apartado 3.4</a>).</p>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_de_mano">2.3. Sistemas de mano</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Con el nombre genérico de <strong>sistemas de mano</strong> hacemos referencia a las <em>tablets</em>, lectores de libros electrónicos y teléfonos móviles.
Los desarrolladores de aplicaciones y sistemas de mano deben enfrentarse a diversos desafíos, originados por el tamaño limitado de los dispositivos y la alimentación mediante el uso de baterías.
Debido a esas limitaciones muchos sistemas de mano tienen poca cantidad de memoria, procesadores lentos —en comparación con sus equivalentes de escritorio— y pantallas más pequeñas.</p>
</div>
<div class="paragraph">
<p>En el diseño del sistema operativo suele primar la facilidad de uso y buscar un buen equilibrio entre rendimiento y tiempo de vida de la batería.</p>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_multiprocesador">2.4. Sistemas multiprocesador</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Un <strong>sistema multiprocesador</strong> es aquel ordenador hay procesadores interconectados que comparten el bus del sistema, el reloj y, en ocasiones la memoria, y los periféricos.</p>
</div>
<div class="paragraph">
<p>Hace años esto solo se daban en sistemas con varias CPU, lo que era relativamente común en servidores y sistemas de alto rendimiento para trabajos técnicos o científicos.
Sin embargo, en la actualidad cualquier dispositivo digital u ordenador doméstico puede tener una CPU con múltiples núcleos, lo que los convierte en sistemas multiprocesador.</p>
</div>
<div class="paragraph">
<p>Las principales de ventajas de estos sistemas son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Aumentan la cantidad de trabajo realizado</strong>. A mayor número de procesadores, mayor cantidad
de trabajo puede realizar el sistema.
Sin embargo debemos de tener en cuenta que un sistema con \$N\$ CPU no es un sistema \$N\$ veces más
rápido.
Cuando varios procesadores cooperan para realizar una tarea, existe cierta pérdida de
rendimiento debida a los mecanismos de sincronización requeridos para controlar el acceso a los recursos compartidos por los procesadores.</p>
</li>
<li>
<p><strong>Economía de escala</strong>. Un sistema multiprocesador puede costar menos que múltiples sistemas monoprocesadores conectados para hacer un trabajo equivalente, porque comparten periféricos, almacenamiento, alimentación, etc.</p>
</li>
<li>
<p><strong>Alta disponibilidad</strong>. Con el hardware adecuado el sistema puede ser tolerante al fallo de uno de los procesadores.
En caso de fallo el sistema no se detendría pero si trabajaría más despacio.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En la actualidad existen dos tipos de sistemas multiprocesador:</p>
</div>
<div id="smp" class="imageblock">
<div class="content">
<img src="C02-tipos_de_sistemas/images/multiprocesamiento_simétrico.svg" alt="multiprocesamiento simétrico">
</div>
<div class="title">Figura 6. Arquitectura de un sistema de multiprocesamiento simétrico.</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En los <strong>sistemas de multiprocesamiento simétrico</strong> o <strong>SMP</strong> (<em>Symmetric Multiprocessing</em>) todos los procesadores son iguales.
Todos comparten los mismos recursos, pueden acceder a los
mismos dispositivos (véase la <a href="#smp">Figura 6</a>) y cada uno ejecuta una copia del núcleo del sistema operativo.
El sistema operativo debe haber sido diseñado para saber repartir el trabajo entre los procesadores y compartir adecuadamente entre tareas y procesadores el resto de recursos del sistema.
Casi todos los sistemas multiprocesador modernos son de este tipo.</p>
</li>
<li>
<p>En los <strong>sistemas de multiprocesamiento asimétrico</strong> o <strong>AMP</strong> (<em>Asymmetric Multiprocessing</em>) hay un procesador principal y varios secundarios a quienes el principal planifica y entrega las tareas que deben ejecutar.
En ocasiones los procesadores secundarios se distinguen del principal por haber sido diseñados para realizar algún tipo concreto de tareas de forma muy eficiente o por estar conectadas a hardware especial.
Ejemplos de esto son las <a href="https://es.wikipedia.org/wiki/Unidad_de_procesamiento_gr%C3%A1fico">GPU</a>, que no son sino procesadores diseñados específicamente para el procesamiento de gráficos, o las CPU de E/S conectadas a
discos duros para gestionarlos de forma más eficiente.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Un ejemplo bastante ilustrativo es el de <a href="https://es.wikipedia.org/wiki/Cell_(microprocesador)">Cell</a>, la CPU de PlayStation 3.
Tenía un núcleo principal de propósito general y 8 núcleos optimizados para ejecutar de forma muy eficiente operaciones vectoriales.
Con la ayuda del sistema operativo, los programas debían envían tareas matemáticamente intensivas a los procesadores secundarios, si querían extraer el máximo provecho de la arquitectura.</p>
</div>
<div class="paragraph">
<p>Desarrollar para un sistema así es más complejo.
Por lo que, aunque sobre el papel esta arquitectura ofrecía gran rendimiento, aprovecharlo era un verdadero reto para los desarrolladores.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_distribuidos">2.5. Sistemas distribuidos</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>En la actualidad es común el uso de redes para interconectar ordenadores individuales —por ejemplo Internet o la red de área local de una oficina— cada uno equipado con su procesador, su memoria, sus dispositivos de almacenamiento, su fuente de alimentación, etc.
En las redes de ordenadores los procesadores de dichos ordenadores se comunican con otros procesadores a través de líneas de comunicación, como: redes Ethernet, líneas telefónicas o wifi.
Estos sistemas son comúnmente denominados <strong>sistemas distribuidos</strong>.</p>
</div>
<div class="paragraph">
<p>Sin entrar en detalles, los sistemas distribuidos pueden ser clasificados en <strong>sistemas cliente-servidor</strong> y <strong>sistemas de redes entre iguales</strong>.</p>
</div>
<div class="sect3">
<h4 id="_sistemas_cliente_servidor">2.5.1. Sistemas cliente-servidor</h4>
<div class="paragraph">
<p>En los <strong>sistemas cliente-servidor</strong>  existen ordenadores que actúan como <strong>servidores</strong> encargados de satisfacer las peticiones generadas por otros ordenadores que actúan como <strong>clientes</strong>.</p>
</div>
<div class="paragraph">
<p>Este tipo de sistemas han sustituido, en un gran número de casos, a los terminales conectados a <em>mainframes</em>, debido a que los sistemas de escritorio son cada vez más potentes y baratos.
Concretamente:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Los terminales han sido sustituidos por sistemas de escritorio que, al disponer de más recursos, son capaces de realizar muchas de las funcionalidades que anteriormente eran manejadas directamente por los <em>mainframes</em>.</p>
</li>
<li>
<p>Al mismo tiempo estos <em>mainframes</em> se han reemplazado por servidores, no muy diferentes a los sistemas de escritorios, pero preparados para atender las peticiones de sus clientes.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Ejemplos de este este tipo de sistemas son los servidores de base de datos, que responden a las consultas SQL de los clientes, o los servidores de archivos, que proporcionan una interfaz de sistema de archivos con la que los clientes pueden crear, leer, escribir y borrar archivos en el servidor; de forma similar a como si estuvieran almacenados localmente en el propio cliente.</p>
</div>
</div>
<div class="sect3">
<h4 id="_sistemas_de_redes_entre_iguales">2.5.2. Sistemas de redes entre iguales</h4>
<div class="paragraph">
<p>En los <strong>sistemas de redes entre iguales</strong>   o <strong>P2P</strong> (<em>peer-to-peer</em>) clientes y servidores no se distinguen los unos de los otros.
Todos los nodos del sistema son iguales y cada uno puede actuar como cliente o servidor, dependiendo de cuándo piden o proporcionan un servicio.</p>
</div>
<div class="paragraph">
<p>La ventaja fundamental de este tipo de sistemas es que en los sistemas cliente-servidor el servidor puede ser el cuello de botella del rendimiento, pero en los sistemas de redes entre iguales la carga se distribuye entre todos los nodos de la red.
Ejemplos de este tipo de sistemas son las redes <a href="https://es.wikipedia.org/wiki/BitTorrent">BitTorrent</a> y <a href="https://es.wikipedia.org/wiki/Bitcoin">Bitcoin</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Un servidor puede ser el cuello de botella no solo por su potencia sino también por el ancho de banda de su conexión a la red.
La potencia del servidor es lo de menos cuando se intenta distribuir en Internet archivos de gran tamaño —por ejemplo imágenes de CD o DVD— pues el problema es que varias descargas simultáneas pueden consumir todo el ancho de banda del servidor durante largos periodos de tiempo.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_sistemas_operativos_para_sistemas_distribuidos">2.5.3. Sistemas operativos para sistemas distribuidos</h4>
<div class="paragraph">
<p>Desde el punto de vista de los sistemas operativos para sistemas distribuidos es posible hacer la siguiente distinción:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>sistemas operativos de red</strong>  ofrecen a las aplicaciones que corren sobre ellos servicios de acceso a redes de ordenadores.
Por ejemplo, implementan algún mecanismo que permita a diferentes procesos en diferentes ordenadores enviar y recibir mensajes.
Además suelen incorporar la opción de proporcionar algunos servicios de red, como la compartición de archivos y dispositivos con otros equipos de la misma red.</p>
<div class="paragraph">
<p>Los ordenadores con sistemas operativos de red son autónomos.
Simplemente es que gracias al sistema operativo de red, conocen la existencia de la red y saben usarla para comunicarse con otros ordenadores de la misma.</p>
</div>
<div class="paragraph">
<p>Este tipo de sistemas operativos son los más utilizados en los tipos de sistemas distribuidos comentados anteriormente.
En la actualidad, la inmensa mayoría de sistemas de escritorio y dispositivos de mano utilizan sistemas operativos de red.</p>
</div>
</li>
<li>
<p>Los <strong>sistemas operativos distribuidos</strong>  crean en el usuario la ilusión de que está en un único ordenador, aunque en realidad el sistema operativo controla todos los ordenadores de la red, dando al usuario acceso transparente a los recursos en todos los equipos de la misma.</p>
<div class="paragraph">
<p>Con este tipo de sistemas operativos el usuario no sabe en qué ordenador se ejecutan sus procesos, dónde se almacenan sus archivos, ni qué equipo tiene conectado los distintos periféricos a los que tiene acceso.</p>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Un ejemplo de sistema operativo distribuido es <a href="https://en.wikipedia.org/wiki/Amoeba_(operating_system)">Amoeba</a>, un sistema operativo distribuido de investigación escrito por Andrew S. Tanenbaum en Vrije Universiteit.
Para más información, véase el <a href="http://www.cs.vu.nl/pub/amoeba/">sitio web de Amoeba</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_en_cluster">2.6. Sistemas en cluster</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Como los sistemas distribuidos, los <strong>sistemas en <em>cluster</em></strong> interconectar ordenadores individuales.
Sin embargo generalmente se acepta que los <strong>sistemas en <em>cluster</em></strong> comparten el almacenamiento y estén conectados por medio de una red local, condiciones que no tienen por qué darse en los sistemas distribuidos.</p>
</div>
<div class="paragraph">
<p>Los <strong>sistemas en <em>cluster</em></strong> se utilizan para:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Obtener servicios con alta disponibilidad</strong>.
Para ello un nodo del <em>cluster</em> puede estar ejecutando un servicio mientras otro nodo lo monitoriza.
En caso de fallo en el nodo que da el servicio, el que lo monitoriza lo sustituye.</p>
<div class="paragraph">
<p>Si es necesario proporcionar varios servicios, el mecanismo anterior se puede extender repartiendo los servicios entre dos o más nodos y haciendo que se monitoricen entre ellos.</p>
</div>
</li>
<li>
<p><strong>Computación de alto rendimiento</strong> o <strong>HPC</strong>.
En este caso todos los nodos se utilizan para dar un mismo servicio.
Un nodo especial, denominado balanceador de carga, tiene la responsabilidad de repartir el trabajo entre los nodos.</p>
<div class="paragraph">
<p>Este tipo de <strong>sistemas en <em>cluster</em></strong> se utiliza para realizar trabajos de cálculo muy pesados, como simulaciones —por ejemplo simulación meteorológica, nuclear o de gestión hospitalaria— o romper sistemas de cifrado.</p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>También es muy utilizado en servidores de Internet —como servidores web, correo electrónico o de mensajería instantánea— o servidores de base de datos que deban dar
servicio a una gran cantidad de clientes simultáneamente.
En estos casos el balanceador de carga realiza su trabajo repartiendo las conexiones de los usuarios entre los servidores del <em>cluster</em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_de_tiempo_real">2.7. Sistemas de tiempo real</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Los <strong>sistemas de tiempo real</strong> se utilizan cuando existen requerimientos estrictos de tiempo en la ejecución de ciertas tareas o en el procesamiento de flujos de datos.</p>
</div>
<div class="paragraph">
<p>En general se usan frecuentemente en dispositivos de control donde, dentro de unos márgenes estrictos de tiempo, se deben tomar datos de uno o varios sensores, para analizarlos posteriormente y realizar, en consecuencia, alguna acción con algún mecanismo de control.
Por ejemplo, se suelen utilizar en sistemas de control industrial, domótica, armamento, automoción —en la inyección electrónica de combustible, sistemas de frenado y de control de tracción— o en dispositivos médicos.</p>
</div>
<div class="paragraph">
<p>Los <strong>sistema de tiempo real</strong> están muy relacionados con los <strong>sistemas empotrados</strong>.
Estos últimos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Se diseñan para realizar tareas muy específicas. No son sistemas de propósito general sino de propósito específico.</p>
</li>
<li>
<p>Sus sistemas operativos tienen características muy limitadas y no tienen que tener necesariamente una interfaz de usuario.</p>
</li>
<li>
<p>Estos sistemas están tanto en el motor de los automóviles y los robots que los fabrican, como en reproductores de DVD, microondas o dispositivos de red.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Los <strong>sistemas de tiempo real</strong> pueden ser clasificados en <strong>sistemas de tiempo real estricto</strong> y <strong>sistemas de tiempo real flexible</strong>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Los <strong>sistemas de tiempo real estricto</strong>  o <strong>hard real-time</strong> garantizan que las tareas serán realizadas dentro de unos márgenes estrictos de tiempo.</p>
<div class="paragraph">
<p>Para ello, todas las situaciones imprevistas que puedan ocasionar retardos en el funcionamiento del sistema operativo deben estar perfectamente limitadas en tiempo.
Por lo tanto, suelen carecer de memoria virtual y de otras abstracciones que aíslen al desarrollador del funcionamiento real del hardware ya que introducen impredecibilidad.</p>
</div>
<div class="paragraph">
<p>Los sistemas de tiempo real estricto no son compatibles con los sistemas de tiempo compartido.</p>
</div>
</li>
<li>
<p>Los <strong>sistemas de tiempo real flexible</strong>   o <strong>soft real-time</strong> son útiles cuando en un sistema operativo convencional hay tareas que tienen mayor importancia que el resto, por lo que deben ser realizadas con mayor prioridad.</p>
<div class="paragraph">
<p>El tiempo real flexible no sirve cuando se tienen tareas con limitaciones precisas de tiempo, porque no hay manera de garantizar que dichas restricciones se van a cumplir.
Sin embargo si es útil para tareas relacionadas con la multimedia, la realidad virtual, los videojuegos, etc. y es compatible con la memoria virtual y otras características presentes en los sistemas de escritorio.
Por eso la mayor parte de los sistemas de escritorio actuales soportan tareas de tiempo real flexible.</p>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_historia_de_los_sistemas_operativos">3. Historia de los sistemas operativos</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>19 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>La historia de los sistemas operativos se puede dividir en cinco grandes etapas o generaciones, obviamente conectadas con las generaciones de los ordenadores donde funcionaban.</p>
</div>
<div class="sect2">
<h3 id="_historia_primera_generación">3.1. 1ª Generación (1945-55)</h3>
<div class="paragraph">
<p>En la primera generación de ordenadores no se utilizaban sistemas operativos.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Sus principales características son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Computadoras construidas con electrónica de <a href="https://es.wikipedia.org/wiki/V%C3%A1lvula_termoi%C3%B3nica">válvulas de vacío</a>.</p>
</li>
<li>
<p>Sin sistema operativo.</p>
</li>
<li>
<p>Sin lenguajes de programación.
Se programaban directamente en lenguaje máquina.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Algunos ejemplos de ordenadores destacables fueron:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="https://es.wikipedia.org/wiki/ENIAC">ENIAC</a> (1945)</dt>
<dd>
<p>Se le considera el primer ordenador electrónico digital de propósito general, aunque existe cierta polémica sobre este punto.
Lo cierto es que se construyeron otros ordenadores antes que éste pero o no eran de propósito general —como las famosas computadoras <a href="https://es.wikipedia.org/wiki/Colossus">Colossus</a> (1944), que fueron diseñadas para ayudar en <a href="https://es.wikipedia.org/wiki/Criptoan%C3%A1lisis">criptoanálisis</a>— o no eran electrónicos sino electro-mecánicos —como la computadora <a href="https://es.wikipedia.org/wiki/Z3">Z3</a> (1941), que usaba <a href="https://es.wikipedia.org/wiki/Rel%C3%A9">relés</a>—.</p>
<div class="paragraph">
<p>No era un producto comercial sino un proyecto experimental de defensa que principalmente se diseño y utilizó para calcular tablas de tiro de artillería destinadas al Laboratorio de Investigación Balística del Ejército de los Estados Unidos.</p>
</div>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/Z4">Z4</a> (1945) fue el primer ordenador digital comercial, pero era electro-mecánico.</p>
</div>
</dd>
<dt class="hdlist1"><a href="https://es.wikipedia.org/wiki/IBM_701">IBM 701</a> (1953)</dt>
<dd>
<p>Fue el primer <em>mainframe</em> de la serie IBM 700, que a la larga se convertiría en un éxito de ventas.
Utilizaba tubos de vacío y tarjetas perforadas.</p>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El IBM 7090 —versión transistorizada del 709, que utilizaba válvulas de vacío, como todos los de la serie 700— y el posterior 7094, fueron usados por la NASA para los cálculos de control de las misiones de los programas espaciales Mercury y Gemini y durante la primera etapa del programa Apolo.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_historia_segunda_generación">3.2. 2ª Generación (1955-64)</h3>
<div class="paragraph">
<p>En la segunda generación de ordenadores los transistores reemplazan a las válvulas de vacío.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>En lo que respecta a los sistemas operativos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aparecen los monitores del sistema, que se pueden considerar un predecesor de los sistemas operativos.</p>
</li>
<li>
<p>Sistema de procesamiento por lotes.</p>
</li>
<li>
<p>Se comienzan a utilizar lenguajes de programación, como: ensamblador, FORTRAN y COBOL.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/GM-NAA_I/O">GM-NAA I/O</a> (<em>General Motors and North American Aviation Input/Output system</em>) fue el primer sistema operativo.
Fue desarrollado por General Motors Research Laboratory en 1956 para el <em>mainframe</em> <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a> con el fin de automatizar la carga y ejecución de un nuevo trabajo una vez había terminado el anterior.
Para su desarrollo se basaron en un monitor del sistema creado en 1955 por programadores de General Motors para el IBM 701.</p>
</div>
<div id="instalación_ibm_702" class="imageblock">
<div class="content">
<img src="C03-historia/images/instalación_ibm_702.jpg" alt="instalación ibm 702">
</div>
<div class="title">Figura 7. Instalación de un mainframe IBM 702&#8201;&#8212;&#8201;Fuente: <a href="https://commons.wikimedia.org/wiki/File:BRL61-IBM_702.jpg">Wikipedia</a></div>
</div>
</div>
<div class="sect2">
<h3 id="_historia_tercera_generación">3.3. 3ª Generación (1965-1968)</h3>
<div class="paragraph">
<p>En la tercera generación se comenzaron a utilizar los circuitos integrados, que fue una invención de finales de la década de 1950.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>En lo que respecta a los sistemas operativos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aparecen los sistemas operativos multiprogramados.</p>
</li>
<li>
<p>Aparecen más lenguajes de programación.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>El ejemplo más destacado de esta época es el <a href="https://en.wikipedia.org/wiki/OS/360_and_successors">IBM OS/260</a>
Fue un sistema operativo desarrollado por IBM para su <em>mainframe</em> <a href="https://en.wikipedia.org/wiki/IBM_System/360">IBM System/360</a> (S/360) (véase la <a href="#instalación_ibm_system_360">Figura 8</a>).
Su versión DOS/360 (<em>Disk Operating System/360</em>) fue el primer sistema operativo en hacer los discos magnéticos un requisito para poder operar.</p>
</div>
<div id="instalación_ibm_system_360" class="imageblock">
<div class="content">
<img src="C03-historia/images/instalación_ibm_system_360.jpg" alt="instalación ibm system 360">
</div>
<div class="title">Figura 8. Instalación de un mainframe IBM System/360&#8201;&#8212;&#8201;Fuente: <a href="http://www-03.ibm.com/ibm/history/ibm100/us/en/icons/system360/impacts/">IBM</a></div>
</div>
<div class="paragraph">
<p>Se anunció en 1964 pero fue lanzado en 1966, con un año de retraso respecto a la fecha prevista originalmente.
Los motivos fundamentales fueron ciertos problemas de organización interna de la compañía y la falta de experiencia en proyectos de esa envergadura.
Las previsiones iniciales eran de 1 millón de líneas de código y miles de componentes de software.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Algunos autores fechan los inicios de la ingeniería del software en la publicación del libro «The Mythical Man-Month: Essays on Software Engineering», escrito por Frederick Brooks y publicado en 1975.
Frederick Brooks se basó en la experiencia adquirida mientras administraba el desarrollo del IBM OS/360, donde era jefe de proyecto.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_historia_cuarta_generación">3.4. 4ª Generación (1965-1980)</h3>
<div class="paragraph">
<p>La cuarta generación abarca desde mediados de los años 60 hasta finales de la década de los 70.
Respecto a los ordenadores, es el resultado del desarrollo de los microprocesadores.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>En lo que respecta a los sistemas operativos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Aparecen los sistemas operativos de tiempo compartido.</p>
</li>
<li>
<p>Aparecen los terminales, los programas interactivos y las máquinas virtuales.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>A continuación veremos los ejemplos más representativos de esta época.</p>
</div>
<div class="sect3">
<h4 id="_multics">3.4.1. MULTICS</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/Multics">MULTICS</a> fue anunciado en 1964, fruto de la colaboración entre el MIT, General Electrics y Bell Labs, como el primer sistema operativo de propósito general.</p>
</div>
<div id="multics_mainframe" class="imageblock">
<div class="content">
<img src="C03-historia/images/multics_mainframe.jpg" alt="multics mainframe">
</div>
<div class="title">Figura 9. Mainframe GE-6180 con sistema MULTICS, entorno a 1976 en el MIT&#8201;&#8212;&#8201;Fuente: <a href="http://www.multicians.org/multics-stories.html">Multicians</a></div>
</div>
<div class="paragraph">
<p>Fue el primer sistema operativo en proporcionar un sistema de archivos jerárquico, intérprete de comandos implementado como programa de usuario, listas de control de acceso individuales para cada archivo y enlazado dinámico, entre otras características novedosas.</p>
</div>
<div class="paragraph">
<p>Además experimentó con eliminar la separación entre el espacio de direcciones de los procesos y los archivos.
Es decir, como si todos los archivos estuvieran mapeados en memoria, permitiendo a los procesos acceder al contenido de los archivos directamente (véase el <a href="#_archivos_mapeados_en_memoria">Apartado 17.6</a>).</p>
</div>
</div>
<div class="sect3">
<h4 id="_vmcms">3.4.2. VM/CMS</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/VM_(sistema_operativo)">VM/CMS</a> es un sistema de IBM utilizado en los <em>mainframe</em> <a href="https://en.wikipedia.org/wiki/IBM_System/360">IBM System/360</a>, System/370, System/390 y zSeries.
VM es un <a href="https://es.wikipedia.org/wiki/Hipervisor">hipervisor</a> que se encarga de virtualizar el hardware para crear múltiples máquinas virtuales, dando la sensación de que cada una es un <em>mainframe</em> independiente.</p>
</div>
<div class="paragraph">
<p>Como sistema operativo de las maquinas virtuales, una opción común es CMS, un sistema interactivo y monousuario muy ligero, diseñado para operar fundamentalmente en una máquina virtual de VM.
Gracias a VM/CMS, cada usuario tiene la sensación de trabajar en un sistema completamente independiente y seguro.</p>
</div>
<div class="paragraph">
<p>El desarrollo de VM/CMS comenzó en 1965 y la primera versión estuvo disponible a primeros de 1966.
Las versiones actuales se denominan IBM z/VM.</p>
</div>
</div>
<div class="sect3">
<h4 id="_unix">3.4.3. UNIX</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/Unix">UNIX</a> fue desarrollado originalmente por Bell Labs en 1970 para los sistemas <a href="https://es.wikipedia.org/wiki/PDP-11">PDP-11/20</a> (véase la <a href="#dec_pdp11">Figura 10</a>).
La autoría del mismo se le atribuye a un grupo de programadores, liderados por Ken Thompson, que decidieron rehacer el trabajo de MULTICS pero a menor escala; después de que Bell Labs abandonara el proyecto MULTICS en 1969.
Inicialmente se llamó UNICS y fue desarrollado para los sistemas PDP-7.</p>
</div>
<div id="dec_pdp11" class="imageblock">
<div class="content">
<img src="C03-historia/images/dec_pdp11_ken_den.jpg" alt="dec pdp11 ken den">
</div>
<div class="title">Figura 10. Dennis Ritchie (de pie) y Ken Thompson (sentado) frente a un PDP-11 y sus dos terminales <a href="https://en.wikipedia.org/wiki/Teletype_Model_33">Teletype 33</a>&#8201;&#8212;&#8201;Fuente: <a href="https://www.bell-labs.com/usr/dmr/www/picture.html">Dennis Ritchie</a></div>
</div>
<div class="paragraph">
<p>La primer versión de UNIX fue implementada en ensamblador, como era común en la época.
Posteriormente, Dennis Ritchie y Brian Kernighan diseñaron un nuevo lenguaje de programación llamado «C», especialmente pensado para que UNIX fuera escrito con él.
Eso facilitó que UNIX pudiera ser portado a ordenadores diferentes.
Además, gracias al lenguaje C, el código era más conciso y compacto, lo que se tradujo en que se pudieron desarrollar nuevas funcionalidades más rápidamente.</p>
</div>
<div class="paragraph">
<p>AT&amp;T, la compañía matriz de Bell Labs, no podía competir en la industria de los ordenadores, por lo que puso el código fuente de UNIX a disposición de universidades, compañías privadas y del gobierno de los Estados Unidos.
Eso aumento su difusión y dio resultados inesperados.
Por ejemplo, una de las variantes más importantes de UNIX fue <a href="https://es.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a>, desarrollada por la Universidad de California en Berkeley.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>La versión 4.2BSD (<em>Berkeley Software Distribution</em>) de esta variante de UNIX fue la primera que incluyó la interfaz de <em>sockets</em> para facilitar la comunicación entre procesos a través de Internet y otras redes.
Esta interfaz se ha convertido en estándar en prácticamente cualquier sistemas operativo.</p>
</div>
<div class="paragraph">
<p>También implementó y ayudó a difundir el estándar de comunicaciones TCP/IP, base de la actual Internet.
Muchos sistemas operativos actuales, tanto libres como privativos, utilizan código de BSD en su implementaciones de los protocolos TCP/IP y de diversas utilidades de red.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>En la actualidad se considera que hay dos grandes familias de UNIX y las distintas variantes pertenecen a una u otra en función del UNIX del que derivaron originalmente:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La familia derivada de <strong>AT&amp;T UNIX System V</strong>, en la que se incluyen sistemas operativos no libres, tales como: <a href="https://es.wikipedia.org/wiki/SCO_OpenServer">SCO OpenServer</a>, <a href="https://es.wikipedia.org/wiki/Solaris_(sistema_operativo)">Oracle/Sun Microsystems Solaris Operating Environment</a> y <a href="https://es.wikipedia.org/wiki/UnixWare">SCO UnixWare</a>.</p>
</li>
<li>
<p>La familia derivada de <strong>BSD</strong>, en la que se incluyen sistemas libres como: <a href="https://es.wikipedia.org/wiki/FreeBSD">FreeBSD</a>, <a href="https://es.wikipedia.org/wiki/NetBSD">NetBSD</a>, <a href="https://es.wikipedia.org/wiki/OpenBSD">OpenBSD</a>, <a href="https://en.wikipedia.org/wiki/Darwin_(operating_system)">Darwin</a> y <a href="https://es.wikipedia.org/wiki/DragonFly_BSD">DragonFly BSD</a>, entre muchos otros.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/FreeBSD">FreeBSD</a> es el sistema base de algunos sistemas no libres.
Por ejemplo, <a href="https://en.wikipedia.org/wiki/Darwin_(operating_system)">Darwin</a> es el sistema operativo en el que se basan los sistemas operativos de Apple: macOS, IOS, watchOS, tvOS e iPadOS.
A su vez Darwin utiliza múltiples elementos de FreeBSD (véase el <a href="#_mach">Apartado 3.5.8</a>).</p>
</div>
<div class="paragraph">
<p>Otro ejemplo destacable es <a href="https://en.wikipedia.org/wiki/PlayStation_4_system_software">Orbis OS</a> —el sistema operativo de PlayStation 4— que también está basado en FreeBSD.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_vms">3.4.4. VMS</h4>
<div class="paragraph">
<p><a href="https://en.wikipedia.org/wiki/OpenVMS">VMS</a> es un sistema operativo de 32 bits diseñado originalmente por Digital Equipment Corporation (DEC) —ahora propiedad de HP— en 1978 para usarlo en minicomputadoras <a href="https://es.wikipedia.org/wiki/VAX">VAX</a>.
Posteriormente fue portado a sistemas DEC Alpha e Intel Itanium.</p>
</div>
<div id="dec_vax11" class="imageblock">
<div class="content">
<img src="C03-historia/images/dec_vax11.jpg" alt="dec vax11">
</div>
<div class="title">Figura 11. Instalación de VAX 11/780 en 1980&#8201;&#8212;&#8201;Fuente: <a href="http://www.chilton-computing.org.uk/">Science and Technology Facilities Council</a></div>
</div>
<div class="paragraph">
<p>Las siglas VMS vienen de <em>Virtual Memory System</em>, ya que una de sus principales características era explotar el concepto de <strong>memoria virtual</strong>.
Este concepto también es muy utilizando en los sistemas operativos modernos.
Permite que los procesos se ejecuten aislados, unos de otros, en la memoria principal y sin tener que ser cargados completamente, lo que permite que cada uno consuma memos memoria.</p>
</div>
<div class="paragraph">
<p>VMS era un sistema multiusuario y multiprocesador que podía distribuir el trabajo entre varias máquinas, lo que le permitía ser tolerante a fallos.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>VMS es en cierta medida un ancestro de Microsoft Windows NT (véase el <a href="#_windows_nt">Apartado 3.5.6</a>).
Para desarrollar Windows NT, Microsoft contrató a un grupo de desarrolladores de Digital Equipment Corporation.
Muchos aspectos del diseño de Windows NT reflejan la experiencia de DEC en VMS.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_ibm_os400">3.4.5. IBM OS/400</h4>
<div class="paragraph">
<p>El <a href="https://es.wikipedia.org/wiki/OS/400">IBM OS/400</a> es un sistema utilizado en la familia de minicomputadoras <a href="https://es.wikipedia.org/wiki/AS/400">IBM AS/400</a> —llamada iSeries desde 2006—.
Fueron introducidos en el mercado en 1988, pero aún es posible verlos en algunas organizaciones.
En 2008 el sistema operativo IBM OS/400 pasó a llamarse IBM i y siguen publicándose nuevas versiones en la actualidad.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5º_generación_desde_1980">3.5. 5º Generación (desde 1980):</h3>
<div class="paragraph">
<p>Esta última generación abarca desde la década de 1980 hasta la actualidad.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Respecto a los sistemas operativos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Incluye a los sistemas operativos de escritorio y ordenadores personales (PC).</p>
</li>
<li>
<p>Aparecen múltiples conceptos nuevos: monousuario, multitarea, distribuidos, paralelos, tiempo real, etc.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Se puede observar una muestra de la interfaz gráfica de usuario de algunos estos sistemas en el artículo <a href="https://www.webdesignerdepot.com/2009/03/operating-system-interface-design-between-1981-2009/">«Operating System Interface Design Between 1981-2009»</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_cpm">3.5.1. CP/M</h4>
<div class="paragraph">
<p><a href="https://en.wikipedia.org/wiki/CP/M">CP/M</a> (1974) fue el sistema operativo estándar en la primera generación de microcomputadoras. Fue creado por Digital Research, Inc. —fundada por Gary Kildall— para ser el sistema operativo de los microordenadores basados en <a href="https://es.wikipedia.org/wiki/Intel_8080">Intel 8080/85</a> y <a href="https://es.wikipedia.org/wiki/Zilog_Z80">Zilog Z80</a>.</p>
</div>
<div class="paragraph">
<p>Con la elección de MS-DOS por parte de IBM para su <a href="https://es.wikipedia.org/wiki/IBM_PC">IBM PC</a>, CP/M fue perdiendo mercado paulatinamente hasta desaparecer.
Sin embargo, la influencia de CP/M en MS-DOS es indudable, en tanto en cuanto 86-DOS, el predecesor de MS-DOS, estaba basado en las ideas de CP/M.</p>
</div>
</div>
<div class="sect3">
<h4 id="_ms_dos">3.5.2. MS-DOS</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/MS-DOS">MS-DOS</a> fue el sistema operativo estándar en la segunda generación de microcomputadoras.
No era ni multitarea ni multiusuario.
Fue el primer sistema operativo del <a href="https://es.wikipedia.org/wiki/IBM_PC">IBM PC</a> —lanzado en 1981— y durante mucho tiempo fue ampliamente utilizado en toda la plataforma «PC compatible».</p>
</div>
<div class="paragraph">
<p>MS-DOS fue creado por Seattle Computer Products (SCP) con el nombre de <a href="https://es.wikipedia.org/wiki/QDOS">86-DOS</a> en 1979.
Se basaron en ideas de CP/M, pues pretendían ofrecer una versión de CP/M para procesadores <a href="https://es.wikipedia.org/wiki/Intel_8086_y_8088">Intel 8086</a>.
Inicialmente era conocido como QDOS (<em>Quick and Dirty Operating System</em>) pero SCP le cambió el nombre en 1980, cuando comenzaron al licenciarlo.
Posteriormente Microsoft adquirió el sistema y lo vendió a IBM en 1981 con el nombre de MS-DOS.</p>
</div>
<div class="paragraph">
<p>Tanto IBM como Microsoft lanzaron versiones de DOS, aunque originalmente IBM solamente validaba y empaquetaba el software de Microsoft.
Microsoft lanzaba sus versiones bajo el nombre de MS-DOS, mientras IBM las lanzaba bajo el nombre de <a href="https://es.wikipedia.org/wiki/IBM_PC_DOS">IBM PC-DOS</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En <a href="https://www.pcjs.org/">PCjs</a> se pueden probar de forma sencilla sistemas operativos y aplicaciones antiguas del IBM PC.
Solo hace falta acceder con el navegador y elegir la experiencia que más nos llame la atención.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_os2">3.5.3. OS/2</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/OS/2">OS/2</a> fue un sistema operativo creado por Microsoft e IBM para aprovechar las nuevas características de la segunda generación de ordenadores personales de IBM, equipados con procesador <a href="https://es.wikipedia.org/wiki/Intel_80286">Intel 80286</a>.
Pero al final terminó siendo desarrollado en exclusiva por IBM.</p>
</div>
<div class="paragraph">
<p>OS/2 fue pensado como un sucesor con <strong>operación en modo dual</strong> de MS-DOS y de Microsoft Windows 2.0.
Fue anunciado en abril y lanzado en diciembre de 1987 como un sistema operativo en modo texto.
En la versión 1.1, lanzada en noviembre de 1988, se le añadió interfaz gráfica.</p>
</div>
<div id="os_2_1" class="imageblock">
<div class="content">
<img src="C03-historia/images/os_2_1.png" alt="os 2 1">
</div>
<div class="title">Figura 12. Panel de control de Microsoft-IBM OS/2 1.1&#8201;&#8212;&#8201;Fuente: Michal Necasek</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En los sistemas con <strong>operación en modo dual</strong> se distingue entre dos modos de ejecución, de tal forma que solo en el modo en el que se ejecuta el código del sistema operativo se pueden realizar operaciones peligrosas.
En el otro modo y con menos privilegios, se ejecutan las aplicaciones de usuario.
Para más información, véase el <a href="#_operación_en_modo_dual">Apartado 7.2</a></p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>La colaboración entre IBM y Microsoft terminó en 1990, entre el lanzamiento de Windows 3.0 y la de OS/2 1.3.
El aumento de popularidad de Windows llevo a Microsoft a dejar de centrarse en el desarrollo de OS/2, lo que hizo que IBM se preocupara por los continuos retrasos en el desarrollo de OS/2 2.0.
Inicialmente ambas compañías acordaron que IBM tomaría el mantenimiento de OS/2 1.0 y el desarrollo de OS/2 2.0, mientras Microsoft continuaría desarrollando OS/2 3.0, que entonces era conocido como «NT OS/2».
Sin embargo Microsoft finalmente decidió renombrar NT OS/2 como Windows NT, dejando el futuro desarrollo de OS/2 en manos de IBM.</p>
</div>
<div class="paragraph">
<p>OS/2 Warp 3 fue un sistema completo de 32 bits lanzado en 1994.
Le seguiría OS/2 Warp 4, en 1996.
Poco después, IBM anunció que OS/2 desaparecería.</p>
</div>
</div>
<div class="sect3">
<h4 id="_windows_3_x">3.5.4. Windows 3.x</h4>
<div class="paragraph">
<p>La familia <a href="https://es.wikipedia.org/wiki/Windows_3.1x">Windows 3.x</a> de Microsoft Windows fue desarrollada desde 1990 hasta 1994.
Windows 3.0 fue la primera versión de éxito de Windows, permitiendo a Microsoft competir con el <a href="https://es.wikipedia.org/wiki/Macintosh">Macintosh</a> de Apple Computer y el <a href="https://es.wikipedia.org/wiki/Commodore_Amiga">Commodore Amiga</a>.</p>
</div>
<div id="windows_30" class="imageblock">
<div class="content">
<img src="C03-historia/images/windows_30.png" alt="windows 30">
</div>
<div class="title">Figura 13. Administrador de programas de Microsoft Windows 3.0&#8201;&#8212;&#8201;Fuente: <a href="https://guidebookgallery.org/screenshots/win30">Guidebook</a></div>
</div>
<div class="paragraph">
<p>En 1983, Microsoft anunció el desarrollo de Windows, una interfaz gráfica de usuario para su sistema MS-DOS, que se usaba en los IBM PC y compatibles desde 1981.
Windows requería una instalación previa de MS-DOS y era iniciado como un programa más, que podía ser terminado en cualquier momento, devolviendo al usuario a la línea de comandos de MS-DOS.</p>
</div>
<div class="paragraph">
<p>MS-DOS le proporcionaba a Windows controladores de dispositivo para ciertas tareas, como el acceso al CD-ROM o a la interfaz de red.
Sin embargo Windows ejecutaba aplicaciones especificas de Windows, almacenadas en un formato ejecutable mucho más complejo que el de los programas de MS-DOS.
Además, debido a que MS-DOS no aislaba a las aplicaciones del hardware y no se protegía así mismo de los errores en dichas aplicaciones, Windows disponía de controladores de dispositivo propios, así como sus propios sistemas de gestión de procesos y de memoria.
En realidad Windows no se ejecutaba sobre MS-DOS, sino que hacía uso de él.
Por ello puede ser considerado como un sistema operativo.</p>
</div>
</div>
<div class="sect3">
<h4 id="_windows_95_98_me">3.5.5. Windows 95, 98, Me</h4>
<div class="paragraph">
<p>La familia Windows 3.x fue sustituida por una serie de sistemas operativos gráficos híbridos de 16/32 bits.</p>
</div>
<div id="windows_95" class="imageblock">
<div class="content">
<img src="C03-historia/images/windows_95.png" alt="windows 95">
</div>
<div class="title">Figura 14. Escritorio de Microsoft Windows 95&#8201;&#8212;&#8201;Fuente: <a href="http://www.guidebookgallery.org/screenshots/win95">Guidebook</a></div>
</div>
<div class="paragraph">
<p>Windows 95 fue lanzado en 1995.
Fue el primer Windows unido a una versión de MS-DOS específica, aunque este hecho se intentaba mantener oculto.
Entre las características de Windows 95 destacan: mejoras significativas en la interfaz de usuario (véase la <a href="#windows_95">Figura 14</a>), nombres de archivo de hasta 256 caracteres con conservación de mayúsculas y minúsculas —en MS-DOS el límite era de 8 caracteres para el nombre más 3 de extensión— y multitarea expropiativa para las aplicaciones de 32 bits.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Como veremos en el <a href="#_planificación_expropiativa">Apartado 14.1</a>, la planificación expropiativa es una técnica que permite al sistema operativo expulsar de la CPU a los procesos en ciertas circunstancias; como, por ejemplo, que lleven demasiado tiempo utilizando la CPU de forma ininterrumpida.</p>
</div>
<div class="paragraph">
<p>En la familia Windows 3.x la planificación era cooperativa, es decir, los procesos abandonaban la CPU voluntariamente.
Esto ocasionaba problemas con programas que no devolvía la CPU al sistema con la suficiente frecuencia, ya que así el resto de procesos no tenía ocasión de ejecutarse para hacer su trabajo o responder al usuario.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Windows 98 fue lanzado el 25 de junio de 1998.
Le siguió Windows Me, el 14 de septiembre de 2000.
Windows Me fue la última versión de la familia de sistemas operativos híbridos de 16/32 bits que sucedió a la familia Windows 3.x.</p>
</div>
</div>
<div class="sect3">
<h4 id="_windows_nt">3.5.6. Windows NT, 2000, XP, Vista, 7, 8 y 10</h4>
<div class="paragraph">
<p>Windows NT fue un sistema operativo de 32 bits.
El primero de la familia de sistemas operativos Microsoft Windows actuales.</p>
</div>
<div class="paragraph">
<p>Su desarrollo empezó en 1988 con el nombre de OS/2 3.0.
Cuando Windows 3.0 fue lanzado en mayo de 1990, tuvo tanto éxito que Microsoft decidió cambiar la API del aún en desarrollo NT OS/2 —que era como Microsoft lo llamaba entonces— pasando de ser una versión extendida de la API de OS/2 a una versión extendida de la API de Windows 3.0.
Esta decisión causó tensión entre Microsoft e IBM y provocó que finalmente la colaboración terminara.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Una interfaz de programación de aplicaciones o API (del inglés <em>Application Programming Interface</em>) es el conjunto de funciones, procedimientos o métodos que ofrece el sistema operativo para ser utilizado por las aplicaciones.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Como hemos comentado anteriormente, Microsoft contrató a un grupo de desarrolladores de Digital Equipment Corporation para crear Windows NT.
Por lo que muchos de sus elementos reflejan la experiencia anterior de DEC en VMS.</p>
</div>
<div class="paragraph">
<p>Windows NT soportaba varias API de distintos sistemas operativos —por ejemplo Win32, POSIX y OS/2 2.1— que eran implementadas como subsistemas encima de un API nativo no documentado públicamente.
Esta estructura en subsistemas, fue lo que permitió la adopción tardía de la API de Windows 3.0 como API principal, tal y como hemos comentado.</p>
</div>
<div class="paragraph">
<p>La primera versión —Windows NT 3.1— lanzada el 13 de julio de 1993, era un sistema operativo <em>microkernel</em> (véase el <a href="#_mach">Apartado 3.5.8</a> un poco más adelante) multiplataforma que corría sobre procesadores <a href="https://es.wikipedia.org/wiki/IA-32">x86</a>, <a href="https://es.wikipedia.org/wiki/DEC_Alpha">DEC Alpha</a>, <a href="https://es.wikipedia.org/wiki/MIPS_(procesador)">MIPS R4000</a> y <a href="https://es.wikipedia.org/wiki/PowerPC">PowerPC</a>.</p>
</div>
<div class="paragraph">
<p>Windows NT 4.0 —lanzado en 1996— fue la última versión en soportar plataformas distintas a Intel IA-32.
Aunque el desarrollo de Windows 2000 para procesador Alpha continuó un poco más, hasta 1999, cuando Compaq dejó de soportar Windows NT en esa arquitectura.
Además Windows NT 4.0 integró en el núcleo más funciones —por ejemplo, parte del subsistema gráfico— para obtener un rendimiento más próximo al de Windows 95 en ese apartado.</p>
</div>
<div class="paragraph">
<p>Windows 2000 —o Windows NT 5.0— fue lanzado en el 17 de febrero de 2000 y fue el primer sistema operativo de la familia NT al que se le eliminaron las siglas del nombre.
Fue por motivos de marketing, para favorecer la unificación de las dos familias de sistemas operativos Microsoft Windows de entonces —Windows 9x y Windows NT— alrededor de la tecnología NT.</p>
</div>
<div class="paragraph">
<p>Windows XP —o Windows NT 5.1— completó en 2001 el proceso de unificación de las dos familias de sistemas operativos Windows.
Con su aparición forzó la extinción de la familia Windows 9x, al sustituirla con una versión de Windows XP denominada Windows XP Home Edition, específica para la informática doméstica.</p>
</div>
</div>
<div class="sect3">
<h4 id="_gnulinux">3.5.7. GNU/Linux</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/GNU/Linux">GNU/Linux</a> es un sistema operativo libre y, tal vez, el más famoso proyecto de <a href="https://es.wikipedia.org/wiki/Software_libre">software libre</a>.</p>
</div>
<div class="paragraph">
<p>El proyecto GNU se inició en 1983, con el fin de desarrollar un sistema operativo estilo UNIX enteramente libre.
El proyecto incluía la creación de herramientas de desarrollo de software y aplicaciones de usuario.</p>
</div>
<div class="paragraph">
<p>Mucho tiempo después, el estudiante universitario finés Linus Torvalds comenzó a desarrollar el núcleo Linux como hobby, mientras estudiaba en la Universidad de Helsinki.
Torvalds originalmente usaba <a href="https://es.wikipedia.org/wiki/MINIX">Minix</a>, un sistema operativo simplificado escrito por Andrew Tanenbaum para enseñar diseño de sistemas operativos.
Sin embargo, el hecho de que Tanenbaum no diera soporte a las mejoras del sistema operativo que eran propuestas por otros desarrolladores, llevó a Torvalds a escribir un sustituto de MINIX.</p>
</div>
<div class="paragraph">
<p>En 1991, cuando se liberó la primera versión del núcleo Linux, el proyecto GNU había desarrollado todos los componentes necesarios del sistema operativo excepto el núcleo.
Torvalds y otros desarrolladores rápidamente adaptaron Linux para que funcionara con los componentes de GNU, creando un sistema operativo completamente funcional que se denomina GNU/Linux.</p>
</div>
<div class="paragraph">
<p>El núcleo Linux fue licenciado bajo la GNU General Public License (GPL), como el resto del proyecto GNU.
Pero Linux no es parte de dicho proyecto.
El proyecto GNU tiene su propio núcleo, denominado <a href="https://es.wikipedia.org/wiki/GNU_Hurd">GNU/Hurd</a>, que lleva 30 años en desarrollo y parece que aun está muy lejos de estar listo.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>GNU no es el único sistema operativo que utiliza el núcleo Linux.
<a href="https://es.wikipedia.org/wiki/Android">Android</a>, por ejemplo, es un sistema operativo que usa el núcleo Linux pero no es GNU.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_mach">3.5.8. Mach</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/Mach_(n%C3%BAcleo)">Mach</a> es un núcleo de sistema operativo desarrollado en la Universidad Carnegie-Mellon (CMU).
El proyecto en la CMU se desarrolló desde 1985 hasta 1994.</p>
</div>
<div class="paragraph">
<p>Mach explora el concepto que denominamos <strong><em>microkernel</em></strong>.
En los sistemas operativos <strong><em>microkernel</em></strong> solo se implementa en el núcleo del sistema un conjunto mínimo de servicios básicos.
El resto de los servicios proporcionados por el sistema operativo se implementan como procesos con menos privilegios.</p>
</div>
<div class="paragraph">
<p>Por sus ventajas en cuanto a seguridad y fiabilidad, en algún momento se pensó que los <em>microkernel</em> dominarían el universo de los sistema operativos.
Sin embargo, el mayor esfuerzo hasta la fecha para conseguirlo es <a href="https://es.wikipedia.org/wiki/GNU_Hurd">GNU/Hurd</a>, que lleva varias décadas de retraso.
Por fortuna, otros sistemas operativos <em>microkernel</em> han tenido algo más éxito, como es el caso de <a href="https://es.wikipedia.org/wiki/QNX">QNX</a> o <a href="https://en.wikipedia.org/wiki/MINIX_3">MINIX 3</a>.
Mientras que Google parece que lo va a intentar con <a href="https://es.wikipedia.org/wiki/Google_Fuchsia">Google Fuchsia</a>, el posible sustituto de Android.</p>
</div>
<div class="paragraph">
<p>A mediados de los 90, Apple Computers seleccionó <a href="https://es.wikipedia.org/wiki/NEXTSTEP">OpenStep</a> como base para el sucesor de su clásico <a href="https://es.wikipedia.org/wiki/Mac_OS_Classic">Mac OS</a>.
OpenStep es realmente una versión actualizada de NeXTSTEP que era un sistema basado en un núcleo Mach 2.5 con porciones del sistema BSD de la Universidad de Berkeley.
Por tanto, la mezcla de Mach con BSD de OpenStep es la base del sistema operativo <a href="https://es.wikipedia.org/wiki/MacOS">macOS</a> actual de Apple.</p>
</div>
<div id="openstep_42" class="imageblock">
<div class="content">
<img src="C03-historia/images/openstep_42.png" alt="openstep 42">
</div>
<div class="title">Figura 15. Entorno gráfico de OpenStep 4.2&#8201;&#8212;&#8201;Fuente: <a href="https://guidebookgallery.org/screenshots/openstep42">Guidebook</a></div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Para ser exactos, la base del sistema operativo macOS es un sistema operativo libre denominado <a href="https://en.wikipedia.org/wiki/Darwin_(operating_system)">Darwin</a> y desarrollado por Apple .
Se trata de un sistema <a href="https://es.wikipedia.org/wiki/FreeBSD">FreeBSD</a> adaptado para correr sobre el núcleo Mach.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="imageblock">
<div class="content">
<img src="C03-historia/images/historia_sistemas_operativos.svg" alt="historia sistemas operativos">
</div>
<div class="title">Figura 16. Línea de tiempo de la historia de los sistemas operativos.</div>
</div>
</div>
</div>
</div>
</div>
<h1 id="_organización_de_los_sistemas_operativos" class="sect0">Parte II: Organización de los sistemas operativos</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>El estudio de la organización interna de los sistemas operativos requiere del análisis de tres aspectos diferentes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Los componentes del sistema operativo y sus interrelaciones.</p>
</li>
<li>
<p>Los servicios que el sistema operativo proporciona a través del funcionamiento coordinado de dichos componentes.</p>
</li>
<li>
<p>La interfaz de programación que el sistema operativo ofrece a usuarios y programadores como forma de acceso a dichos servicios.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>También veremos como como se categorizan los sistemas operativos según la forma en la que se interconectan sus componentes.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_componentes_del_sistema">4. Componentes del sistema</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>11 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Crear un software tan complejo como un sistema operativo no es sencillo, por ello resulta más práctico dividirlo en piezas más pequeñas especializadas en aspectos concretos de la gestión del sistema.</p>
</div>
<div class="paragraph">
<p>Cada sistema operativo tiene diferentes componentes con distinto nombre.
Lo que veremos en este capítulo es un esquema de los más comunes a la mayoría de sistemas operativos actuales.</p>
</div>
<div class="sect2">
<h3 id="_gestión_de_procesos">4.1. Gestión de procesos</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>La gestión de los procesos es un elemento central de todo sistema operativo:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>El <strong>proceso</strong> es la unidad de trabajo en cualquier sistema operativo moderno.
Es quién realiza las tareas que interesan a los usuarios.
Por eso, es a cada proceso al que se le asigna el tiempo de CPU y el resto de recursos del sistema, como por ejemplo: memoria, archivos o dispositivos de E/S abiertos.</p>
</li>
<li>
<p>Un <strong>proceso</strong> es un programa en ejecución.
Un programa se convierte en proceso cuando las instrucciones del programa son cargadas en la memoria desde el archivo del ejecutable y se le asignan recursos para su ejecución.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Los procesos son entidades activas que necesita recursos —CPU, memoria, archivos, dispositivos E/S—.
Algunos de esos recursos se asignan durante su creación, mientras que otros son solicitados por el proceso durante su ejecución —por ejemplo la memoria, de la que todo proceso necesita cierta cantidad para comenzar pero que luego puede pedir más dinámicamente durante su ejecución—.
Cuando el proceso termina el sistema operativo reclama de estos recursos aquellos que sean reutilizables para otros procesos.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Un <strong>programa</strong> no es un proceso, es una entidad pasiva.
Es el contenido de un archivo en disco con las instrucciones que algún día una CPU ejecutará.
Un programa no puede hacer ningún tipo de trabajo a menos que sus instrucciones sean ejecutadas por una CPU, pero si eso ocurre, ya no sería un programa sino un proceso.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Aunque varios procesos estén asociados al mismo programa no pueden ser considerados el mismo proceso.
La CPU ejecuta las instrucciones de cada proceso una detrás de otra, de manera que para conocer la siguiente instrucción a ejecutar cada proceso tiene un contador de programa que se lo indica a la CPU, así como valores en los registros de la CPU que dependen de la historia pasada del proceso.
Aunque varios procesos ejecuten el mismo programa, la secuencia de instrucciones ejecutadas y el estado del proceso en cada momento seguramente sean diferentes.
Por lo tanto, no son el mismo proceso.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Por el momento estamos considerando que <strong>proceso</strong> y <strong>trabajo</strong> hacen referencia al mismo concepto porque en los sistemas más antiguos (véase el <a href="#_mainframe">Apartado 2.1</a>) la unidad de trabajo se llamaba <strong>trabajo</strong> mientras que en los sistemas modernos se llama <strong>proceso</strong>, de tal forma que podemos considerar al segundo una evolución del primero.</p>
</div>
<div class="paragraph">
<p>Sin embargo, mirándolo exclusivamente desde la perspectiva de los sistemas operativos modernos, son dos conceptos diferentes aunque relacionados.
En un sistema moderno un trabajo puede ser realizado por un solo proceso o mediante la colaboración de varios.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_responsabilidades_de_la_gestión_de_procesos">4.1.1. Responsabilidades de la gestión de procesos</h4>
<div class="paragraph">
<p>El componente de gestión de procesos es el responsable de la siguientes actividades:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Crear y terminar procesos.</p>
</li>
<li>
<p>Suspender y reanudar los procesos.</p>
</li>
<li>
<p>Proporcionar mecanismos para la sincronización de procesos.</p>
</li>
<li>
<p>Proporcionar mecanismos para la comunicación entre procesos.</p>
</li>
<li>
<p>Proporcionar mecanismos para el tratamiento de interbloqueos.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_de_la_memoria_principal">4.2. Gestión de la memoria principal</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>La memoria principal es un recurso fundamental para las operaciones de cualquier sistema operativo moderno.
Esto es así porque generalmente es el único almacenamiento al que la CPU tiene acceso directo.
Para que un programa pueda ser ejecutado debe ser copiado a la memoria principal.
Y para que un proceso tenga acceso a datos almacenados en cualquier otro dispositivo de almacenamiento, primero deben ser copiados a la memoria principal.</p>
</div>
<div class="paragraph">
<p>Para mejorar el aprovechamiento de la CPU y la respuesta al usuario es necesario tener en la memoria varios programas al mismo tiempo.
Puesto que dichos programas deben compartir la memoria durante su ejecución, automáticamente existe la necesidad de que el sistema operativo disponga de un componente de gestión de la memoria principal.</p>
</div>
<div class="sect3">
<h4 id="_responsabilidad_de_la_gestión_de_la_memoria">4.2.1. Responsabilidad de la gestión de la memoria</h4>
<div class="paragraph">
<p>El componente de gestión de la memoria debe asumir las siguientes responsabilidades:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Controlar qué partes de la memoria están actualmente en uso y cuáles no.</p>
</li>
<li>
<p>Decidir que procesos —o partes de procesos— añadir o extraer de la memoria cuando hay o falta espacio en la misma.</p>
</li>
<li>
<p>Asignar y liberar espacio de la memoria principal según sea necesario.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_del_sistema_de_es">4.3. Gestión del sistema de E/S</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>El <strong>sistema de E/S</strong> hace de interfaz con el hardware, oculta las peculiaridades del hardware al resto del sistema.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>El sistema de E/S consta de:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Un componente de gestión de memoria especializado en E/S</strong>, con soporte para servicios de <em>buffering</em>, <em>caching</em> y <em>spooling</em>.
Estos servicios son utilizados por el resto del sistema de E/S.</p>
</li>
<li>
<p><strong>Una interfaz genérica de acceso a los controladores de dispositivo</strong>.
Cada dispositivo es diferente, pero los procesos y el resto de componentes del sistema no deben tener necesidad de conocer sus particularidades a la hora de acceder a ellos.
Es decir, para acceder a cualquier disco duro el sistema ofrece una misma interfaz, impedientemente de su marca y modelo.
Y lo mismo ocurre con las tarjetas de sonido o con los dispositivos de entrada, como teclados y ratones.
Así los programadores pueden acceder a cualquier dispositivo abstrayendo de las particularidades concretas del hardware instalado en cada ordenador.</p>
</li>
<li>
<p><strong>Controladores de dispositivo</strong>, que generalmente son desarrollados por los fabricantes de los dispositivos y son el componente que realmente conoce las peculiaridades específicas del dispositivo.
Por tanto, las peticiones que hacen los procesos a la interfaz de E/S genérica la traslada el sistema a los controladores de dispositivo para que éstos las conviertan en acciones concretas sobre el hardware del dispositivo.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Una característica de los sistemas UNIX es que todos los dispositivos de E/S se representa como un archivo en el sistema de archivos.
Esto se puede comprobar rápidamente visitando el directorio <code>/dev</code> en cualquier sistema GNU/Linux o BSD, ya que es allí donde suelen estar.</p>
</div>
<div class="paragraph">
<p>Así no hace falta diseñar y aprender una interfaz diferente para cada tipo de dispositivo.
Los procesos que quiere utilizar cualquier dispositivo de E/S solo tienen que usar las mismas funciones y llamadas al sistema que emplean para manipular los archivos normales.
Por ejemplo, <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a>, <a href="https://man7.org/linux/man-pages/man2/read.2.html">read()</a>, <a href="https://man7.org/linux/man-pages/man2/write.2.html">write()</a> o <a href="https://man7.org/linux/man-pages/man2/close.2.html">close()</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_buffering">4.3.1. Buffering</h4>
<div class="paragraph">
<p>El <strong>buffering</strong> o uso de memoria intermedia es una estrategia en la que se almacenan los datos de manera temporal en una zona de la memoria, llamada búfer.</p>
</div>
<div class="paragraph">
<p>Consiste en que el controlador indica a un dispositivo que escriba los bloques de datos solicitados en un búfer.
Cuando la escritura del búfer se ha completado, se transfiere su contenido al proceso que hizo la solicitud para que procese los datos.
Mientras lo hace, el controlador indica al dispositivo que copie nuevos datos en el búfer.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, al grabar sonido del dispositivo de sonido del sistema no se entregan las muestras una a una al proceso.
En su lugar se graban varios miles de muestras que se escriben en un búfer.
Cuando el búfer está lleno, se transfieren todas las muestras al proceso de una sola vez y se siguen grabando muestras en el búfer.</p>
</div>
<div class="paragraph">
<p>Lo mismo ocurre al reproducir sonido.
El proceso no entrega las muestras de sonido de una en una al dispositivo, sino que empaqueta varias miles que se copian al búfer de una sola vez.
Entonces el controlador indica al dispositivo que lea las muestras desde ese búfer según lo vaya necesitando.</p>
</div>
</div>
<div class="sect3">
<h4 id="_caching">4.3.2. Caching</h4>
<div class="paragraph">
<p>En el <strong>caching</strong> el sistema mantiene en la memoria principal una copia de datos  leídos o escritos recientemente en los dispositivos de E/S del sistema —por ejemplo, en los discos duros o en las memorias USB—.
Esto mejora la eficiencia del sistema si accede con frecuencia a los mismos datos, puesto que el acceso a la memoria principal es más rápido que el acceso a los dispositivos de E/S.
La memoria principal es de tamaño limitado, por lo que sólo se mantiene copia de los datos utilizados con mayor frecuencia.</p>
</div>
</div>
<div class="sect3">
<h4 id="_spooling">4.3.3. Spooling</h4>
<div class="paragraph">
<p>El <strong>spooling</strong> se utiliza en dispositivos que no admiten el acceso simultáneo de varias aplicaciones a vez, como es el caso de impresoras y unidades de cinta.</p>
</div>
<div class="paragraph">
<p>Cuando varias aplicaciones intentan enviar un trabajo a una impresora, el sistema operativo lo intercepta para copiar los datos enviados a un archivo independiente.
Cuando una aplicación termina de enviar el trabajo, el archivo correspondiente se mete en una cola de donde son extraídos los trabajos para su impresión de uno en uno.
Así no hay acceso simultáneo al dispositivo por parte de varios procesos, mientras que éstos pueden entregar el trabajo y continuar con su trabajo sin esperar a que la impresora esté disponible.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_del_almacenamiento_secundario">4.4. Gestión del almacenamiento secundario</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Dentro de los dispositivos de E/S, los dedicados al almacenamiento secundario —como discos duros, memorias USB o lectores de DVD-ROM— merecen un tratamiento especial.</p>
</div>
<div class="paragraph">
<p>Los programas que se desean ejecutar deben estar en la memoria principal —o almacenamiento primario— pero ésta es demasiado pequeña para alojar todos los datos y todos los programas del sistema.
Además, incluso aunque pudiera ser así, los datos almacenados en la memoria principal se perderían en caso de que ocurriera un fallo de alimentación.
Por eso los ordenadores disponen de un almacenamiento secundario para guardar datos de forma masiva y permanente.</p>
</div>
<div class="paragraph">
<p>El gestor del almacenamiento secundario utiliza el sistema de E/S para acceder a los dispositivos y ofrecer al sistema servicios más complejos.</p>
</div>
<div class="sect3">
<h4 id="_responsabilidades_de_la_gestión_del_almacenamiento_secundario">4.4.1. Responsabilidades de la gestión del almacenamiento secundario</h4>
<div class="paragraph">
<p>El gestor del almacenamiento secundario es el responsable de:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Gestionar el espacio libre en discos duros y resto de dispositivos de almacenamiento secundario.</p>
</li>
<li>
<p>Asignar el espacio de almacenamiento.</p>
</li>
<li>
<p>Planificar el acceso a los dispositivos, de tal forma que se ordenen las operaciones de forma eficiente.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_del_sistema_de_archivos">4.5. Gestión del sistema de archivos</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Los ordenadores pueden almacenar información en diferentes tipos de medios físicos —por ejemplo en discos duros magnéticos, CD/DVD-ROM, memorias USB o SSD— cada uno de los cuales tiene características propias.
El acceso a cada tipo de medio es controlado por un dispositivo —por ejemplo el controlador de disco o la unidad de DVD-ROM— que también tiene características propias.
El sistema de E/S y la gestión del almacenamiento secundario simplifican el acceso a estos dispositivos, pero no lo suficiente como para que sea cómodo usarlos constantemente en cualquier programa.</p>
</div>
<div class="paragraph">
<p>Para simplificar aun más el acceso al almacenamiento, el sistema operativo proporciona una visión lógica uniforme de todos los sistemas de almacenamiento.
Es decir, abstrae las propiedades físicas de los dispositivos de almacenamiento para definir el <strong>archivo</strong>, una unidad de almacenamiento lógico con la que trabajan los procesos para guardar y recuperar datos.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Un <strong>archivo</strong> o fichero es una colección de datos relacionados, identificados por un nombre, que es tratada por el sistema operativo como una unidad de información en el almacenamiento secundario —por ejemplo un programa, una imagen o un documento—.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Los archivos normalmente se organizan en directorios para facilitar su uso y organización.</p>
</div>
<div class="sect3">
<h4 id="_responsabilidades_de_la_gestión_del_sistema_de_archivos">4.5.1. Responsabilidades de la gestión del sistema de archivos</h4>
<div class="paragraph">
<p>El sistema de archivos utiliza al gestor del almacenamiento secundario y al sistema de E/S y es responsable de las siguientes actividades:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Crear y borrar archivos.</p>
</li>
<li>
<p>Crear y borrar directorios para organizar los archivos.</p>
</li>
<li>
<p>Soportar operaciones básicas para la manipulación de archivos y directorios: lectura y escritura de datos, cambio de nombre, cambio de permisos, etc.</p>
</li>
<li>
<p>Mapear en memoria archivos del almacenamiento secundario.</p>
</li>
<li>
<p>Hacer copias de seguridad de los archivos en sistemas de almacenamiento estables y seguros.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_de_red">4.6. Gestión de red</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>El componente de red se responsabiliza de la comunicación con otros sistemas interconectados mediante una red de ordenadores —por ejemplo, en Internet o en la red de área local de una oficina—.</p>
</div>
</div>
<div class="sect2">
<h3 id="_protección_y_seguridad">4.7. Protección y seguridad</h3>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p><strong>Protección</strong> es cualquier mecanismo para controlar el acceso de los procesos y usuarios a los recursos definidos por el sistema.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Son mecanismos necesarios cuando un sistema informático tiene múltiples usuarios y permite la ejecución concurrente de varios procesos, pues así sólo pueden utilizar los recursos aquellos procesos que hayan obtenido la autorización del sistema operativo.</p>
</li>
<li>
<p>Permite mejorar la fiabilidad, al permitir detectar los elementos del sistema que no operan correctamente.
Un recurso desprotegido no puede defenderse contra el uso —o mal uso— de un usuario no autorizado o incompetente.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Ejemplos típicos de mecanismos de protección son el hardware de direccionamiento de memoria, que se utiliza para que los procesos se ejecuten en su propio espacio de direcciones, y el temporizador, que garantiza que ningún proceso toma el control de la CPU por tiempo indefinido.
Además, los registros de los dispositivos de E/S suelen estar protegidos del acceso directo de los usuarios, lo que protege la integridad de los dispositivos.
Mientras que en algunos sistemas se pueden establecer permisos sobre los archivos para garantizar que sólo los procesos con la debida autorización tengan acceso.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Un sistema puede tener la protección adecuada pero estar expuesto a fallos y permitir accesos inapropiados.
Por eso es necesario disponer de mecanismos de <strong>seguridad</strong> que se encarguen de defender el sistema frente a ataques internos y externos.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Eso incluye a virus y gusanos, ataques de <a href="https://es.wikipedia.org/wiki/Ataque_de_denegaci%C3%B3n_de_servicio">denegación de servicio</a>, robo de identidad y uso no autorizado del sistema, entre muchos otros tipos de ataque.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_servicios_del_sistema">5. Servicios del sistema</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>5 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Un sistema operativo proporciona un entorno para la ejecución de programas.
Ese entorno debe proporcionar ciertos servicios a los programas y a los usuarios de esos programas.
Estos servicios son proporcionados gracias al funcionamiento coordinado de los diferentes componentes del sistema.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="C05-servicios/images/organización_sistema.svg" alt="organización sistema">
</div>
<div class="title">Figura 17. Diagrama general de organización de los sistemas operativos.</div>
</div>
<div class="paragraph">
<p>Aunque cada sistema operativo proporciona servicios diferentes, es posible identificar unas pocas clases comunes.</p>
</div>
<div class="sect2">
<h3 id="_servicios_que_garantizan_el_funcionamiento_eficiente_del_sistema">5.1. Servicios que garantizan el funcionamiento eficiente del sistema</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Asignación de recursos</strong>.
Cuando hay múltiples usuarios o múltiples trabajos ejecutándose los recursos deben ser asignados a cada uno de ellos.</p>
<div class="paragraph">
<p>Ejemplos de estos recursos son la CPU —asignada por el planificador de la CPU del gestor de procesos— la memoria principal —asignada por el gestor de memoria— y el almacenamiento de archivos —asignada por el sistema de archivos y el gestor del almacenamiento secundario—.
Esta asignación debe hacerse con el fin de garantizar la máxima eficacia del sistema.</p>
</div>
</li>
<li>
<p><strong>Monitorización</strong>.
Es normal querer hacer seguimiento de los recursos que los usuarios usan y en qué cantidad.
Esto puede ser útil para facturar a los usuarios por el uso de los recursos —por ejemplo, facturar por el tiempo de CPU— para configurar el sistema mejorando el rendimiento o para limitar cuánto de cada recurso puede usar cada usuario como máximo.</p>
</li>
<li>
<p><strong>Protección y seguridad</strong>.
Protección implica asegurar que el acceso a los recursos del sistema
está controlado.
Por ejemplo, que la información almacenada en un sistema multiusuario sólo puede ser accedida por su propietario o que un proceso no pueda interferir con otro o con el sistema operativo.
La seguridad del sistema respecto a los agentes exteriores también es
importante.
Empieza obligando a los usuarios a autenticarse en él para obtener acceso a los recursos del mismo, pero incluye defender de intentos de acceso inválidos a través de la red.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_servicios_útiles_para_el_usuario">5.2. Servicios útiles para el usuario</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Interfaz de usuario</strong>. Los sistemas operativos diseñados para que los usuarios interactúen con ellos deben proporcionar una interfaz de usuario adecuada, que puede ser diferente formas según le propósito del sistema.</p>
</li>
<li>
<p><strong>Operaciones de E/S</strong>. Un programa puede necesitar realizar operaciones de E/S que pueden
involucrar a archivos o a dispositivos de E/S.
Por eficiencia y protección un usuario, normalmente los procesos no puede tener acceso directo a los dispositivos; por lo que el sistema operativo debe proporcionar medios para solicitar estas operaciones a los componentes correspondientes del sistema operativo.</p>
</li>
<li>
<p><strong>Manipulación de sistemas de archivos</strong>. Los programas necesitan leer y escribir archivos y
directorios, crearlos y borrarlos por nombre, buscar un archivo dado y listar información
acerca del mismo.</p>
</li>
<li>
<p><strong>Comunicaciones</strong>. Los procesos necesitan poder intercambiar información entre ellos, tanto si
se ejecutan en el mismo ordenador, como en diferentes equipos unidos por una red.</p>
</li>
<li>
<p><strong>Detección de errores</strong>. El sistema operativo necesita tener conocimiento de los posibles errores y para cada tipo de error debe tomar la acción apropiada para asegurar una computación consiste y segura.
Por ejemplo, pueden haber errores del hardware —como fallos de energía o errores en la
memoria— en la E/S —como errores de paridad o falta de papel en la impresora— y en los
programas de usuario —como desbordamientos aritméticos o accesos ilegales a la memoria—.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_interfaz_de_usuario">5.3. Interfaz de usuario</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>La <strong>interfaz de usuario</strong> es un servicio fundamental para todos los sistemas diseñados para que los usuarios interactúen con ellos directamente, por lo que nos vamos a detener un poco más en él.</p>
</div>
<div class="paragraph">
<p>Las interfaces de usuario pueden ser de diferentes tipos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Interfaz de línea de comandos</strong> o <strong>intérprete de comandos</strong>, que permite que los usuarios introduzcan directamente los comandos que el sistema operativo debe ejecutar.
En algunos sistemas este tipo de interfaz se incluye dentro del núcleo, pero en la mayor parte —como MSDOS y UNIX— se trata de un programa especial denominado <em>shell</em> que se ejecuta cuando un usuario inicia una sesión.</p>
</li>
<li>
<p><strong>Interfaz de proceso por lotes</strong>, en la que los comandos y directivas para controlar dichos comandos se listan en archivos que posteriormente pueden ser ejecutados.
Este tipo de interfaz es la utilizada en sistemas no interactivos, como los antiguos sistemas de procesamiento por lotes y los sistemas multiprogramados.</p>
<div class="paragraph">
<p>También suele estar disponible en los sistemas de tiempo compartido y en los sistemas de escritorio modernos, junto con algún otro tipo de interfaz de usuario.
Por ejemplo, la <em>shell</em> de los sistemas UNIX permite indicar comandos uno a uno —de forma interactiva— pero también permite usar <em>scripts</em> —un archivo con una lista de órdenes para que se ejecuten automáticamente de principio a fin—.</p>
</div>
</li>
<li>
<p><strong>Interfaz gráfica de usuario</strong> o <strong>GUI</strong> (<em>Graphical User Interface</em>) que permite a los usuarios utilizar un sistema de ventanas y menús controlable mediante el ratón.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Puesto que la interfaz de usuario puede variar de un sistema a otro, y de un usuario a otro dentro del mismo sistema, no se suele etiquetar como un componente básico del sistema operativo, sino como un servicio ofrecido por el sistema operativo.</p>
</div>
<div class="paragraph">
<p>A parte de la interfaz de usuario, cualquier sistema operativo moderno incluye una colección de <strong>programas del sistema</strong>.
El papel de estos programas del sistema es proporcionar un entorno conveniente para la ejecución y desarrollo de programas.
Entre los programas del sistema se suelen incluir aplicaciones para manipular archivos y directorios, programas para obtener información sobre el estado del sistema —como la fecha y hora o la memoria y el espacio en disco disponible— herramientas de desarrollo —como intérpretes, compiladores, enlazadores y depuradores— programas de comunicaciones —como clientes de correo electrónico y navegadores web— etc.</p>
</div>
<div class="paragraph">
<p>Además, muchos sistemas operativos disponen de programas que son útiles para resolver los problemas más comunes de los usuarios.
Entre estos programas se suelen incluir: editores de archivos de texto y procesadores de texto, hojas de cálculo, sistemas de base de datos, juegos, etc.
Ha esta colección de aplicaciones se la suele conocer con el término de <strong>utilidades del sistema</strong> o <strong>programas de aplicación</strong>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_interfaz_de_programación_de_aplicaciones">6. Interfaz de programación de aplicaciones</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>15 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Un sistema operativo proporciona un entorno controlado para la ejecución de programas.
Dicho entorno debe proporcionar ciertos servicios que pueden ser accedidos por los programas a través de una <strong>interfaz de programación de aplicaciones</strong> o <strong>API</strong> (<em>Application Programming Interface</em>).</p>
</div>
<div class="sect2">
<h3 id="_interfaces_de_programación_de_aplicaciones">6.1. Interfaces de programación de aplicaciones</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Algunas de las API disponibles para los desarrolladores de aplicaciones son Windows API y POSIX.</p>
</div>
<div class="sect3">
<h4 id="_windows_api">6.1.1. Windows API</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/Win32_API">Windows API</a> es el nombre que recibe la <strong>interfaz de programación de aplicaciones</strong> de Microsoft Windows, con la que prácticamente tienen que interactuar todas las aplicaciones, de una forma u otra.</p>
</div>
<div class="paragraph">
<p>Antiguamente se denominaba Win32 API, pero Microsoft ha querido aglutinar bajo una misma denominación las distintas versiones de la API de Windows que han existido, como Win16 —usada en las versiones de 16 bits de Windows— o Win64 —que es la variante de Win32 adaptada a arquitecturas de 64 bits—.</p>
</div>
<div class="paragraph">
<p>Está compuesta por funciones en C almacenadas, principalmente, en las librerías de enlace dinámico (<a href="https://es.wikipedia.org/wiki/Biblioteca_de_enlace_din%C3%A1mico">DLL</a>): <code>kernel32.dll</code>, <code>user32.dll</code> y <code>gdi32.dll</code>.
Aunque según se ha ido ampliando la API, se han incorporado otras librerías adicionales.</p>
</div>
<div class="paragraph">
<p>Provee un conjunto muy amplio de servicios: E/S a archivos y dispositivos, gestión de procesos, hilos y memoria, manejo de errores, registro de Windows, interfaz a dispositivos gráficos —pantallas e impresoras— gestión de ventanas, comunicaciones en red, etc.</p>
</div>
</div>
<div class="sect3">
<h4 id="_posix">6.1.2. POSIX</h4>
<div class="paragraph">
<p><a href="https://es.wikipedia.org/wiki/POSIX">POSIX</a> (<em>Portable Operating System Interface for Unix</em>) es el nombre de una familia de estándares que definen una <strong>interfaz de programación de aplicaciones</strong> para sistemas operativos.
Esto permite que un mismo programa pueda ser ejecutado en distintos sistemas operativos, siempre que sean compatibles con POSIX.</p>
</div>
<div class="paragraph">
<p>El lenguaje C fue diseñado originalmente para implementar sistemas UNIX y por eso la librería estándar de C tenía mucho parecido con la librería del sistema de UNIX.
Con el tiempo, al ir añadiendo más funcionalidades, la librería del sistema de los sistemas UNIX de los distintos fabricantes fue divergiendo, haciendo muy complicado desarrollar programas que usaran las características más avanzadas y que a la vez pudieran ejecutarse en varios de ellos.
Por eso el <a href="https://es.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers">IEEE</a> desarrollo el estándar POSIX, que define una API común para todos los UNIX y sistemas estilo UNIX modernos —como es el caso de GNU/Linux—.
Así que la práctica totalidad de estos sistemas son compatible POSIX.</p>
</div>
<div class="paragraph">
<p>Por su origen, la API POSIX es un superconjunto de la API de la librería estándar de C.
Por eso en los sistemas POSIX, la librería estándar de C es parte de la librería del sistema, en lugar de dos librerías separadas.</p>
</div>
<div class="paragraph">
<p>Las funciones POSIX están almacenadas, principalmente, en la librería <code>libc</code>.
Aunque algunas características pueden estar en otras librerías, como <code>libm</code> —la librería matemática— o <code>libpthread</code> —la librería de hilos—.</p>
</div>
<div class="paragraph">
<p>Los desarrolladores del sistema a veces añaden funciones no incluidas en el estándar POSIX, con el objeto de soportar algún tipo de funcionalidad avanzada del sistema.
Antes de usarlas debemos tener presente que:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Un programa que solo utilice la API POSIX podrá ejecutarse en cualquier sistema operativo compatible POSIX.</p>
</li>
<li>
<p>Mientras que uno que utilice, por ejemplo, alguna funcionalidad adicional no POSIX de Linux o macOS, solo podrá compilarse y ejecutarse en Linux o en macOS, según el caso.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_llamadas_al_sistema">6.2. Llamadas al sistema</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Para un programa, acceder a los servicios del sistema operativo no es tan sencillo como invocar una función.
Para invocar una función, un programa necesita conocer la dirección en la memoria del punto de entrada de dicha función —es decir, la ubicación de su primera instrucción—.
Sin embargo, el código del núcleo del sistema puede estar en cualquier ubicación de la memoria principal.
Así que las direcciones de los puntos de entrada a las funciones del núcleo son desconocidas.
Además, generalmente, el código y los datos del núcleo están protegidos frente a accesos indebidos (véase el <a href="#_protección_de_la_memoria">Apartado 7.3</a>).
Eso significa que para que un proceso pueda invocar los servicios que necesita hace falta un procedimiento diferente, denominado <strong>llamada al sistema</strong>.</p>
</div>
<div class="sect3">
<h4 id="_invocar_llamadas_al_sistema">6.2.1. Invocar llamadas al sistema</h4>
<div class="paragraph">
<p>Generalmente una llamada al sistema se invoca mediante una instrucción específica en lenguaje ensamblador que genera una <strong>excepción</strong> —que no es más que una interrupción lanzada por la propia CPU al detectar instrucciones especiales o un error al ejecutar una instrucción, como una división por 0 o un acceso indebido a ciertas zonas de la memoria—.
Por ejemplo, en MIPS e Intel x86 se usa la instrucción <code>syscall</code>, que lanza un excepción, haciendo que la CPU salte a una rutina en el código del núcleo del sistema, deteniendo así la ejecución del proceso que la invocó.</p>
</div>
<div class="paragraph">
<p>Al realizar una llamada, es necesario que el sistema sepa qué operación le está pidiendo el proceso.
Esto se suele hacer poniendo un número identificativo de la llamada en un registro concreto de la CPU.
Por ejemplo, en Linux para x86 la llamada al sistema <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a> —que se utiliza para abrir archivos— se identifica con el número 2 o con el 5, según si es en 64 o en 32 bits, respectivamente.
Este número se debe guardar en el registro <code>v0</code> en MIPS o <code>eax</code> en x86, antes de la instrucción <code>syscall</code>.</p>
</div>
<div class="paragraph">
<p>Los números utilizados para identificar cada llamada al sistema dependen del sistema operativo.
Mientras que el registro donde se guarda, la instrucción utilizada y el resto de detalles sobre cómo realizar la llamada, dependen también de la arquitectura de la CPU.</p>
</div>
</div>
<div class="sect3">
<h4 id="_paso_de_argumentos">6.2.2. Paso de argumentos</h4>
<div class="paragraph">
<p>Obviamente una llamada al sistema suele requerir más información que la identidad de la llamada.
Si, por ejemplo, se quiere abrir un archivo, al menos es necesario indicar su nombre, así como si se abre para leer o para escribir.</p>
</div>
<div class="paragraph">
<p>En concreto hay tres métodos para pasar parámetros adicionales al identificador a una llamada al sistema:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Mediante registros de la CPU</strong>.
Consiste en cargar los parámetros de la llamada al sistema en los registros de la CPU antes de realizar la llamada al sistema.
Este método es el más eficiente, pero limita el número de parámetros al número de registros disponibles.</p>
<div class="paragraph">
<p>Es utilizado, por ejemplo, en Linux para MIPS (véase el <a href="#linux_mips_syscall">Ejemplo 1</a>) y en la mayoría de sistemas operativos para x86-64.</p>
</div>
</li>
<li>
<p><strong>Mediante tabla en memoria</strong>
Consiste en copiar los parámetros de la llamada al sistema en una tabla en la memoria principal y luego guardar la dirección de dicha tabla en un registro específico de la CPU, antes de la llamada al sistema.
Así no se limita el número de parámetros que pueden ser pasados en cada llamada al sistema.</p>
<div class="paragraph">
<p>Era utilizado por Microsoft Windows 2000 y anteriores.
También en Linux para x86 32 bits, cuando el número de parámetros es superior a 6.</p>
</div>
</li>
<li>
<p><strong>Mediante la pila del proceso</strong> se insertan los parámetros de la llamada al sistema en la pila del proceso —que también se suele usar para guardar variables locales y, en algunas arquitecturas, los argumentos pasados al llamar a funciones— y el sistema operativo los recupera de allí durante la llamada al sistema.
Al igual que en el caso anterior, tampoco limita el número de parámetros que pueden ser pasados en cada llamada al sistema.</p>
<div class="paragraph">
<p>Es utilizado, por ejemplo, en sistemas BSD y en Windows XP y posteriores para x86 de 32 bits.</p>
</div>
</li>
</ul>
</div>
<div id="linux_mips_syscall" class="exampleblock">
<div class="title">Ejemplo 1. Llamada al sistema en Linux MIPS.</div>
<div class="content">
<div class="paragraph">
<p>Veamos como invocar directamente la llamada al sistema <a href="https://man7.org/linux/man-pages/man2/write.2.html">write()</a> en Linux para MIPS.</p>
</div>
<div class="paragraph">
<p>Esta llamada sirve para escribir datos en un archivo.
Así que necesita tres argumentos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>SIZE</strong>: El número de bytes a escribir.</p>
</li>
<li>
<p><strong>BUFFER</strong>: La dirección de la memoria de la que coger los bytes.</p>
</li>
<li>
<p><strong>FILEDES</strong>: El descriptor que identifica a un archivo abierto donde se van a escribir los datos.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Al terminar devuelve el número de bytes escritos en el archivo, que puede ser inferior a <code>SIZE</code>.</p>
</div>
<div class="paragraph">
<p>El identificador de la llamada al sistema es 4004, según el <a href="https://git.linux-mips.org/cgit/ralf/linux.git/tree/arch/mips/include/uapi/asm/unistd.h">listado de llamadas al sistema</a> para Linux en MIPS.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>  lw      $a0, FILEDES   <i class="conum" data-value="1"></i><b>(1)</b>
  la      $a1, BUFFER    <i class="conum" data-value="1"></i><b>(1)</b>
  lw      $a2, SIZE      <i class="conum" data-value="1"></i><b>(1)</b>
  li      $v0, 40004     <i class="conum" data-value="2"></i><b>(2)</b>
  syscall                <i class="conum" data-value="3"></i><b>(3)</b> <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Cargar cada uno de los 3 argumentos de la llamada al sistema en los registros <code>a0</code>, <code>a1</code> y <code>a2</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Cargar el identificador de la llamada <code>write()</code> en el registro <code>v0</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Invocar la llamada al sistema.
Aunque vemos que es una única instrucción, lo que realmente va a ocurrir es que el sistema operativo va a tomar el control de la CPU para realizar la tarea solicitada.
La siguiente instrucción no comenzará a ejecutarse hasta que el sistema operativo no lo decida, por lo que, desde el punto de vista del programa, va a ser como si <code>syscall</code> fuera una instrucción más lenta de lo normal.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Al ejecutar la siguiente instrucción del código del programa, el registro <code>v0</code> contendrá el número de bytes escritos.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap06/syscall.s">syscalls.s</a> se puede ver un ejemplo completo similar, pero para Linux x86 de 64 bits.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>En cualquier caso, sea cual sea el método utilizado, el sistema operativo es responsable de comprobar de manera estricta la validez de los parámetros enviados en la llamada al sistema antes de realizar cualquier operación, puesto que nunca debe confiar en que los procesos hagan su trabajo correctamente.
A fin de cuentas, una de las funciones del sistema operativo es el control de dichos procesos.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_librería_del_sistema">6.3. Librería del sistema</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Las <strong>llamadas al sistema</strong> proporcionan una interfaz con la que los procesos pueden invocar los servicios que el sistema operativo ofrece.
El problema es que como se hacen mediante instrucciones en lenguaje ensamblador (véase el <a href="#linux_mips_syscall">Ejemplo 1</a>) no son demasiado cómodas de utilizar.
Así que generalmente los programas no las invocan directamente.
En su lugar, lo que hacen es llamar a funciones de la <strong>librería del sistema</strong>, que a su vez son las encargadas de hacer las llamadas al sistema necesarias.</p>
</div>
<div class="paragraph">
<p>Cuando hablamos anteriormente de <a href="https://es.wikipedia.org/wiki/Win32_API">Windows API</a> y del estándar <a href="https://es.wikipedia.org/wiki/POSIX">POSIX</a>, hablábamos de la interfaz de la <strong>librería del sistema</strong> en esos sistemas operativos.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>La <strong>librería del sistema</strong>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Es parte del sistema operativo, por lo que se distribuye con él.</p>
</li>
<li>
<p>Es una colección de clases o funciones que ofrecen los servicios del sistema operativo a los programas, apoyándose en las llamadas al sistema.</p>
<div class="paragraph">
<p>Algunas funciones de la librería del sistema son traducciones literales de llamadas al sistema —por ejemplo, <a href="https://man7.org/linux/man-pages/man2/write.2.html">write()</a> o <a href="https://man7.org/linux/man-pages/man2/close.2.html">close()</a>— mientras que otras pueden ser más complejas, hacer más trabajo o mostrar conceptos más abstractos que los usados por el sistema operativo al nivel de llamadas al sistema.</p>
</div>
</li>
<li>
<p>Constituye la verdadera <strong>interfaz de programación de aplicaciones</strong> del sistema operativo.
Es la forma recomendada de solicitar servicios al sistema operativo.
Invocar directamente las llamadas al sistema debe ser el último recurso.</p>
</li>
<li>
<p>Sus funciones se llaman como cualquier otra.
Al igual que el resto de librerías, se carga dentro de la región de memoria asignada al proceso.
Por lo tanto, la invocación de las funciones de la librería del sistema se realiza como si fueran cualquier otra función del programa.</p>
</li>
<li>
<p>Es muy común que esté implementada en C, lo que permite que tanto los programas en C como en C&#43;&#43; la puedan utilizar directamente.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_librería_estándar">6.4. Librería estándar</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Lenguajes distintos de C y C&#43;&#43; pueden tener difícil usar las funciones de la librería del sistema.
Pero de alguna forma deben poder hacerlo, porque sus programadores necesitan acceso a los servicios que ofrece el sistema operativo.</p>
</div>
<div class="paragraph">
<p>Incluso en C y en C&#43;&#43; puede ser interesante tener acceso a funcionalidades adicionales a las ofrecidas por la API del sistema operativo: estructuras de datos, algoritmos de ordenamiento o búsqueda, funciones para manipular cadenas, funciones matemáticas, etc.
También abstracciones de los servicios del sistema, que encajen mejor con las particularidades del lenguaje de programación en cuestión.
Por ejemplo, utilizando clases y objetos en lenguajes que soportan programación orientada a objetos.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Por eso, junto a cada intérprete o compilador de cada lenguaje de programación suele ir una <strong>librería estándar</strong> que ofrece clases o funciones con las que los programas pueden acceder a los servicios del sistema operativo y realizar las tareas más comunes de forma más sencilla.</p>
</div>
<div class="paragraph">
<p>Estas librerías generalmente no forman parte del sistema operativo, sino de las herramientas de desarrollo de cada lenguaje de programación, y constituyen la <strong>interfaz de programación de aplicaciones</strong> del lenguaje al que acompañan.</p>
</div>
<div class="paragraph">
<p>La <strong>librería estándar</strong> necesita acceder a los servicios del sistema operativo para, a su vez, dar servicio a los programas que la usan.
Es decir, cuando un programa invoca alguna función o método de la librería estándar que lo acompaña, es muy probable que ésta necesite invocar uno o más servicios del sistema operativo para atender la petición convenientemente.
Para ello la <strong>librería estándar</strong> utiliza la <strong>librería del sistema</strong> que acompaña al sistema operativo, que a su vez realiza las <strong>llamadas al sistema</strong> necesarias.</p>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">De archivos a flujos</div>
<div class="paragraph">
<p>Un ejemplo del papel de las <strong>librerías estándar</strong> lo podemos encontrar en el acceso a los archivos.</p>
</div>
<div class="paragraph">
<p>Las llamadas al sistema y la librería del sistema de los sistemas operativos ofrecen funciones básicas para manipular archivos.
Los archivos se abren indicando su ruta y, al hacerlo, el sistema operativo devuelve un identificador del archivo abierto (véase <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a>).
Este identificador se puede usar para leer o escribir en bytes el contenido del archivo.</p>
</div>
<div class="paragraph">
<p>Si embargo en C, C&#43;&#43; y otros lenguajes, todo lo que son flujos de datos se generalizan en el concepto de flujo o <em>stream</em> (véase <a href="https://en.cppreference.com/w/c/io">stdio.h</a> e <a href="https://en.cppreference.com/w/cpp/header/iostream">iostream</a>).
En él. se incluye la entrada de teclado y la salida por pantalla, la impresión de documentos, las conexiones de red —potencialmente— y, obviamente, el acceso a archivos y a dispositivos.</p>
</div>
<div class="paragraph">
<p>Los flujos pueden ser de texto o binarios, lo que implica algunas transformaciones en los datos.
Además van ligados al concepto del <em>buffering</em>, es decir, que los bytes o caracteres escritos en el flujo no se «envían» inmediatamente, sino que se acumulan en la memoria para ser enviados en bloque.</p>
</div>
<div class="paragraph">
<p>Todas estas características adicionales las implementa la <strong>librería estándar</strong>.
Pero por debajo, al final, los datos tiene que ser escritos en un archivo, una impresora o el monitor, recursos que gestiona el sistema operativo.
Por lo tanto, las <strong>librerías estándar</strong> necesitan hacer uso de la <strong>librería del sistema</strong> para comunicarse con el sistema operativo.</p>
</div>
<hr>
<div class="paragraph">
<p>Algo que suele ocurrir al crear mayores abstracciones es que se suele perder control y características específicas.
Por ejemplo, la llamada al sistema <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a> con la que se pueden crear archivos permite asignar permisos o crear archivos temporales.
Sin embargo, con las interfaces de <em>streams</em> de C y C&#43;&#43; no se puede hacer eso, ya que los permisos y la temporalidad son propiedades de los archivos que no son comunes a todas fuentes de flujos de datos.</p>
</div>
<div class="paragraph">
<p>Así que en ocasiones puede ser que nos resulte más útil llamar a las funciones de la <strong>librería del sistema</strong>, que usar las facilidades de la <strong>librería estándar</strong>.
Sin embargo, debemos valorar que así perdemos portabilidad, ya que ahora nuestro programa ya no podrá usarse allí donde haya un compilador o intérprete de nuestro lenguaje, sino solo en sistemas operativos con una <strong>librería del sistema</strong> compatible.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_con_todas_las_piezas_juntas">6.5. Con todas las piezas juntas</h3>
<div class="paragraph">
<p>En la <a href="#api_win32">Figura 18</a> se ilustra el papel de todos los elementos comentados, con el ejemplo de programas en C y Python, ejecutados en Microsoft Windows, que invocan los métodos <a href="https://en.cppreference.com/w/c/io/fopen">fopen()</a> y <code>file()</code> de la librería estándar de estos lenguajes, respectivamente.</p>
</div>
<div id="api_win32" class="imageblock">
<div class="content">
<img src="C06-api/images/interfaz_programación_aplicaciones_win32.svg" alt="interfaz programación aplicaciones win32">
</div>
<div class="title">Figura 18. Elementos de la interfaz de programación de aplicaciones en Microsoft Windows.</div>
</div>
<div class="paragraph">
<p>En ambos casos, la librería estándar llama a la función <a href="https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea">CreateFile()</a> de la librería del sistema de Windows, que finalmente realiza una llamada al sistema que hace que el sistema operativo tome el control, deteniendo la ejecución del proceso que la solicita.
Entonces se realiza la tarea solicitada mediante el funcionamiento coordinado de los diferentes componentes del sistema (véase el <a href="#_componentes_del_sistema">Capítulo 4</a>).</p>
</div>
<div class="paragraph">
<p>El programa en C, puede usar tanto la función <a href="https://en.cppreference.com/w/c/io/fopen">fopen()</a> de su librería estándar como llamar directamente a la función <a href="https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea">CreateFile()</a> de la librería del sistema —marcado en rojo en la <a href="#api_win32">Figura 18</a>—.
Sin embargo, en el programa en Python no tenemos esa facilidad —al menos directamente—.</p>
</div>
<div class="paragraph">
<p>Usar directamente las funciones de la librería del sistema desde programas en C o C&#43;&#43; tiene la ventaja de que permite utilizar todas las características del sistema operativo.
Por ejemplo, utilizar las opciones adicionales de <a href="https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea">CreateFile()</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">HANDLE</span> <span class="n">WINAPI</span> <span class="nf">CreateFile</span><span class="p">(</span>
  <span class="n">LPCTSTR</span> <span class="n">lpFileName</span><span class="p">,</span>                           <i class="conum" data-value="1"></i><b>(1)</b>
  <span class="n">DWORD</span> <span class="n">dwDesiredAccess</span><span class="p">,</span>                        <i class="conum" data-value="2"></i><b>(2)</b>
  <span class="n">DWORD</span> <span class="n">dwShareMode</span><span class="p">,</span>                            <i class="conum" data-value="3"></i><b>(3)</b>
  <span class="n">LPSECURITY_ATTRIBUTES</span> <span class="n">lpSecurityAttributes</span><span class="p">,</span>   <i class="conum" data-value="4"></i><b>(4)</b>
  <span class="n">DWORD</span> <span class="n">dwCreationDisposition</span><span class="p">,</span>                  <i class="conum" data-value="5"></i><b>(5)</b>
  <span class="n">DWORD</span> <span class="n">dwFlagsAndAttributes</span><span class="p">,</span>                   <i class="conum" data-value="6"></i><b>(6)</b>
  <span class="n">HANDLE</span> <span class="n">hTemplateFile</span>                          <i class="conum" data-value="7"></i><b>(7)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Nombre del archivo.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Modo de acceso: lectura o escritura.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Modo en el que se compartirá el archivo con otros procesos que accedan al mismo tiempo.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Permisos del archivo, en caso de crearlo.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Acción en caso de que el archivo exista o no: siempre crear, solo abrir, truncar si existe, etc.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Atributos del archivo, en caso de crearlo.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Archivo abierto del que copiar los atributos para copiarlo en éste,
en caso de crearlo.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>que <a href="https://en.cppreference.com/w/c/io/fopen">fopen()</a> no posee:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">FILE</span><span class="o">*</span> <span class="nf">fopen</span><span class="p">(</span>
  <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">path</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
  <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">mode</span>  <i class="conum" data-value="2"></i><b>(2)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Nombre del archivo.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Modo de acceso: lectura o escritura.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Sin embargo, debemos tener en cuenta que se pierde portabilidad pues <a href="https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea">CreateFile()</a> solo está disponible en Microsoft Window, mientras que <a href="https://en.cppreference.com/w/c/io/fopen">fopen()</a> viene con la librería estándar de cualquier compilador de C.</p>
</div>
<div class="paragraph">
<p>En la <a href="#api_posix">Figura 19</a> se puede observar un ejemplo similar en <a href="https://es.wikipedia.org/wiki/GNU/Linux">GNU/Linux</a> —un sistema compatible <a href="https://es.wikipedia.org/wiki/POSIX">POSIX</a>— pero en esta ocasión con programas en C y C&#43;&#43;.
En este caso la llamada al sistema es <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a> y tanto <a href="https://en.cppreference.com/w/c/io/fopen">fopen()</a> en C como <a href="https://en.cppreference.com/w/cpp/io/basic_ofstream/open">std::ofstream::open()</a>1 en C&#43;&#43; la utilizan.
Además, ambos lenguajes pueden invocar directamente la librería del sistema —marcado en rojo en la <a href="#api_posix">Figura 19</a>— si necesitan alguna característica adicional de la función <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a>.</p>
</div>
<div id="api_posix" class="imageblock">
<div class="content">
<img src="C06-api/images/interfaz_programación_aplicaciones_posix.svg" alt="interfaz programación aplicaciones posix">
</div>
<div class="title">Figura 19. Elementos de la interfaz de programación de aplicaciones en GNU/Linux.</div>
</div>
<div class="paragraph">
<p>La única diferencia es que en <a href="#api_posix">Figura 19</a> las funciones <a href="https://en.cppreference.com/w/c/io/fopen">fopen()</a> y <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a> están realmente en la misma librería, porque en los sistemas POSIX la librería del sistema y la librería estándar de C pueden ser la misma, dado que el estándar POSIX se diseñó como un superconjunto de la librería estándar de C.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_operación_del_sistema_operativo">7. Operación del sistema operativo</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>16 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Dado que el sistema operativo y los procesos de usuarios comparten los recursos del sistema informático, necesitamos estar seguros de que un error en un programa sólo afecte al proceso que lo ejecuta —por ejemplo, que un proceso no puede modificar la memoria de otro proceso o la del núcleo del sistema—.
Por eso es necesario establecer mecanismos de protección frente a los errores en los programas que se ejecutan en el sistema.</p>
</div>
<div class="sect2">
<h3 id="_software_controlado_mediante_interrupciones">7.1. Software controlado mediante interrupciones</h3>
<div class="paragraph">
<p>Antes de entender como funcionan estos mecanismos de protección debemos entender que los sistemas operativos modernos pertenecen a un tipo de software que se dice que está controlado mediante interrupciones.</p>
</div>
<div class="paragraph">
<p>Los sucesos que requieren la atención del sistema casi siempre se indican mediante una interrupción:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando un proceso comete un error —como una división por cero o un acceso a memoria no válido— o un programa solicita un servicio al sistema operativo a través de una llamada al sistema lo que se genera es una excepción.
Esta excepción despierta al sistema operativo para que haga lo que sea más conveniente.</p>
</li>
<li>
<p>Cuando un proceso necesita un servicio lo que hace es lanzar una llamada al sistema, que no es más que ejecutar una instrucción que lanza una excepción.
Esta excepción despierta al sistema operativo para que atienda la petición.</p>
</li>
<li>
<p>Cuando los dispositivos de E/S requieren la atención del sistema operativo —por ejemplo, porque se ha completado una transferencia de datos— se genera una interrupción que despierta al sistema operativo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Esto funciona así porque el sistema operativo configura la CPU durante el arranque para que si ocurre cualquier interrupción o excepción la ejecución, salte a rutinas en el código del núcleo, con el objeto de darles el tratamiento adecuado.</p>
</div>
<div class="paragraph">
<p>Si ningún proceso realiza una acción ilegal o pide un servicio, ni ningún dispositivo de E/S pide la atención del sistema, el sistema operativo permanece inactivo esperado a que algo ocurra.</p>
</div>
<div class="paragraph">
<p>Teniendo todo esto en cuenta podremos entender mejor como funciona el modo dual.</p>
</div>
</div>
<div class="sect2">
<h3 id="_operación_en_modo_dual">7.2. Operación en modo dual</h3>
<div class="paragraph">
<p>Para proteger el sistema de programas con errores es necesario poder distinguir entre la ejecución de código del sistema operativo y del código de los programas de usuario, de tal forma que el código de los programas de usuario esté más limitado en lo que puede hacer que el del sistema operativo.</p>
</div>
<div class="paragraph">
<p>El método que utilizan la mayor parte de los sistemas operativos consiste en utilizar algún tipo de soporte en la CPU que permita diferenciar entre varios modos de ejecución y restringir la utilización de las instrucciones peligrosas —llamadas <strong>instrucciones privilegiadas</strong>— para que sólo puedan ser utilizadas en el modo en el que se ejecuta el código del sistema operativo.</p>
</div>
<div class="sect3">
<h4 id="_modos_de_operación">7.2.1. Modos de operación</h4>
<div class="paragraph">
<p>Así que como mínimo son necesarios dos modos de operación diferentes:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>En el <strong>modo usuario</strong>, en el que se ejecuta el código de los procesos de los usuarios.
Si se hace un intento de ejecutar una instrucción privilegiada en este modo, el hardware la trata como ilegal y genera una excepción que es interceptada por el sistema operativo, en lugar de ejecutar la instrucción.</p>
</li>
<li>
<p>En el <strong>modo privilegiado</strong> —también denominado <strong>modo supervisor</strong>, <strong>modo del sistema</strong> o <strong>modo kernel</strong>— se ejecuta el código de las tareas del sistema operativo.
La CPU es la encargada de garantizar que las instrucciones privilegiadas sólo pueden ser ejecutadas en este modo.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>El modo actual de operación puede venir indicado por un <strong>bit de modo</strong> en alguno de los registros de configuración de la CPU, de tal forma que, si por ejemplo, el bit está a 0, la CPU considera que el código en ejecución opera en modo privilegiado, mientras que si el bit está a 1, el código en ejecución opera en modo usuario.</p>
</div>
<div class="paragraph">
<p>Comúnmente en el grupo de las <strong>instrucciones privilegiadas</strong> se suelen incluir:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La instrucción para conmutar al modo usuario desde el modo privilegiado.</p>
</li>
<li>
<p>Las instrucciones para acceder a dispositivos de E/S.</p>
</li>
<li>
<p>Las instrucciones necesarias para la gestión de las interrupciones.
Por ejemplo, para desactivarlas —evitando que se lancen—, activarlas y configurarlas.</p>
</li>
</ul>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Niveles de privilegio en procesadores x86</div>
<div class="paragraph">
<p>Aunque para operar en modo dual solo se necesita que la CPU admita los dos modos descritos, existen procesadores que soportan más, con la idea de tener mayor control sobre el nivel de privilegio en el que se ejecuta cada componente del sistema.</p>
</div>
<div class="paragraph">
<p>Es el caso de la arquitectura Intel x86, que soporta 4 modos de operación.
El modo 0 es para el software más confiable y el que necesita más privilegios, que generalmente es el núcleo.
Mientras que el modo 3 se utiliza para el software menos confiable y que necesita más supervisión, que normalmente son los procesos de usuario.</p>
</div>
<div class="paragraph">
<p>La idea detrás de tener los modos 1 y 2 es usarlos para controladores de dispositivo o procesos que dan servicio al resto del sistema.
Así estos componentes pueden tener mayores privilegios que los procesos de usuario —por ejemplo, los controladores de dispositivo necesitan acceso directo al hardware— pero al mismo tiempo serían supervisados y no podrían afectar al núcleo, que se ejecuta en el modo 0.</p>
</div>
<div class="paragraph">
<p>Sin embargo, los sistemas operativos con mayor cuota de mercado —incluyendo Microsoft Windows, macOS, Linux y Android— solo utilizan los modos 0 y 3.
Los motivos son que los desarrolladores de sistemas no encuentran realmente ninguna ventaja en utilizar más modos y que complica portar el sistema operativo a procesadores donde solo se soporten dos.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
En procesadores x86 recientes, que vienen con instrucciones específicas para facilitar la ejecución de máquinas virtuales, se ha incorporado un modo -1, para que el núcleo del sistema operativo virtualizado se ejecute en el modo 0 mientras es supervisado desde el modo -1 por el núcleo del sistema operativo anfitrión.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Para más información, véase <a href="https://es.wikipedia.org/wiki/Anillo_(seguridad_inform%C3%A1tica)">«Anillo (seguridad informática)&#8201;&#8212;&#8201;Wikipedia»</a>.</p>
</div>
<hr>
<div class="paragraph">
<p>En los procesadores x86 es importante no confundir los <strong>modos real</strong> y <strong>protegido</strong> con el modo dual y los niveles de privilegio de los que estamos hablando.</p>
</div>
<div class="paragraph">
<p>Por compatibilidad hacia atrás, los procesadores x86 se inician en modo real, donde se comportan como una CPU <a href="https://es.wikipedia.org/wiki/Intel_8086_y_8088">Intel 8086</a>.
En este modo, por ejemplo, solo tienen acceso al primer mega de memoria RAM —ya que los procesadores <a href="https://es.wikipedia.org/wiki/Intel_8086_y_8088">Intel 8086</a> solo tenían 20 bits para direcciones de memoria—.</p>
</div>
<div class="paragraph">
<p>Cuando un sistema operativo moderno arranca, lo primero que hace es iniciar el modo protegido, en el que se activan todas las características de la CPU.
Entra otras, el direccionamiento de 32 o 64 bits —según el procesador que sea— y la posibilidad de usar los 4 niveles de privilegio, de los que hemos hablado, para que el núcleo pueda supervisar al resto de componentes.</p>
</div>
<div class="paragraph">
<p>Para más información, véase <a href="https://es.wikipedia.org/wiki/Modo_protegido">«Modo protegido&#8201;&#8212;&#8201;Wikipedia»</a>.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ejecución_de_instrucciones">7.2.2. Ejecución de instrucciones</h4>
<div class="paragraph">
<p>A continuación podemos ver el ciclo de vida de la ejecución de instrucciones en un sistema con modo dual de operación:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Inicialmente, al arrancar el ordenador, la CPU se inicia en el modo privilegiado —es decir, en nuestro ejemplo, con el bit de modo a 0—.
En este modo se carga el núcleo del sistema operativo e inicia su ejecución.</p>
</li>
<li>
<p>El núcleo del sistema operativo debe cambiar al modo usuario —poniendo el bit de modo a 1— antes de ceder la CPU a un proceso de usuario.
Esto ocurre cuando es necesario que un proceso de usuario continúe o inicie su ejecución (véase el <a href="#_el_asignador">Apartado 14.2</a>).
Así se asegura que el código de los procesos de usuario siempre se ejecuten en modo usuario, con menos privilegios.</p>
</li>
<li>
<p>La CPU conmuta a modo privilegiado cuando ocurre una interrupción o una excepción —poniendo el bit de modo a 0— antes de comenzar el código del sistema operativo que se encargará de tratarlas.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="paragraph">
<p>Esto último es muy importante.
Como ya hemos comentado, los sistemas operativos están controlados mediante interrupciones.
Al activarse el modo privilegiado cada vez que ocurre una interrupción, podemos estar seguros de que las tareas del sistema operativo se ejecutarán siempre en modo privilegiado.</p>
</div>
<div class="paragraph">
<p>Cuando se dispone de la protección del modo dual, el hardware se encarga de detectar los errores de ejecución y de notificarlo al sistema operativo mediante excepciones, siendo responsabilidad de este último realizar un tratamiento adecuado de los mismos.
Por lo general, si un programa falla de alguna forma —como por ejemplo, intentando utilizar una instrucción ilegal o de acceder a una zona de memoria inválida— el sistema operativo lo hace terminar.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_protección_de_la_memoria">7.3. Protección de la memoria</h3>
<div class="paragraph">
<p>La memoria principal debe acomodar tanto el sistema operativo como a los diferentes procesos de los usuarios.
Por eso la memoria normalmente se divide en dos partes:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>La primera parte sirve para albergar el núcleo del sistema operativo.</p>
<div class="paragraph">
<p>El sistema operativo puede estar localizado tanto en la parte baja como en la parte alta de la memoria.
El factor determinante en la elección es la localización del vector de interrupciones, que es una tabla en la memoria que define las direcciones a las que saltará la CPU en caso de que ocurra una interrupción o una excepción.</p>
</div>
<div class="paragraph">
<p>Puesto que en la mayor parte de las arquitecturas éste reside en la parte baja de la memoria, normalmente el sistema operativo también se aloja en la parte baja.</p>
</div>
</li>
<li>
<p>La segunda parte alberga los procesos de usuario.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Sin embargo, en los sistemas operativos modernos, los procesos no tienen acceso libre a toda memoria física, con el objeto de proteger a los procesos en ejecución y al sistema operativo de posibles errores en cualquiera de ellos:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>El sistema operativo proporciona a cada proceso una «vista» privada de la memoria RAM; similar a la que tendrían si cada uno de ellos se estuviera ejecutando en solitario (véase la <a href="#protección_memoria">Figura 20</a>).</p>
</li>
<li>
<p>A esa «vista» que tiene cada proceso de la memoria es a lo que se denomina <strong>espacio de direcciones virtual</strong> del proceso.
Está formada por el conjunto de todas las direcciones que puede generar la CPU para un proceso dado.
Por ejemplo, en una CPU de 32 bits el espacio de direcciones virtual tiene 4GB, desde la dirección 0x00000000 a 0xFFFFFFFF.</p>
</li>
<li>
<p>En los accesos a la memoria principal durante la ejecución del proceso, estas <strong>direcciones virtuales</strong> son convertidas por la CPU en direcciones físicas, antes de ser enviadas a la memoria principal.
Por tanto las <strong>direcciones físicas</strong> son las direcciones reales que ve la memoria.
Mientras que el <strong>espacio de direcciones físico</strong> es el conjunto de direcciones físicas que corresponden a todas las direcciones virtuales de un espacio de direcciones virtual dado.</p>
</li>
</ul>
</div>
</div>
</div>
<div id="protección_memoria" class="imageblock">
<div class="content">
<img src="C07-modo_dual/images/protección_memoria.svg" alt="protección memoria">
</div>
<div class="title">Figura 20. Mapeo de la memoria física en el espacio de direcciones virtual de un proceso.</div>
</div>
<div class="paragraph">
<p>La conversión de una dirección virtual en una física, la realiza en tiempo de ejecución un componente de la CPU denominado MMU (<em>Memory-Management Unit</em>).</p>
</div>
<div class="paragraph">
<p>Las ventajas de usar esta técnica, desde el punto de vista de la protección de la memoria son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Permite el aislamiento de los procesos, creando para cada uno la ilusión de que toda la memoria es para él y evitando que un proceso pueda acceder a la memoria de otros procesos.</p>
</li>
<li>
<p>Permite marcar modos de acceso autorizados en las diferentes regiones de la memoria —como por ejemplo lectura, escritura y ejecución— evitando que el código ejecutado en modo usuario tenga acceso a zonas a las que no debería tenerlo.
El acceso a la memoria en un modo no autorizado se considera una instrucción privilegiada, por lo que ese tipo de acceso desde el modo usuario siempre genera una excepción.
Por ejemplo, si se intenta ejecutar instrucciones en una zona de memoria no marcada con el permiso de ejecución.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_el_temporizador">7.4. El temporizador</h3>
<div class="paragraph">
<p>El <strong>temporizador</strong> se configura por el sistema operativo durante el arranque del sistema para interrumpir a la CPU a intervalos regulares.
Así, cuando el temporizador interrumpe, el control se transfiere automáticamente al núcleo del sistema.
Entonces éste puede:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Conceder más tiempo al proceso en ejecución.</p>
</li>
<li>
<p>Detenerlo y darle más tiempo de CPU en el futuro</p>
</li>
<li>
<p>Tratar la interrupción como un error y terminar el programa.</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>El temporizador se utiliza para asegurar que ningún proceso acapara la CPU indefinidamente.
Por ejemplo, un programa mal desarrollado que entra en un bucle infinito, del que no sale jamás.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Obviamente, las instrucciones que pueden modificar el contenido del temporizador son instrucciones privilegiadas.</p>
</div>
</div>
<div class="sect2">
<h3 id="_maquinas_virtuales">7.5. Maquinas virtuales</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Utilizando las técnicas comentadas anteriormente, el sistema operativo crea a los procesos la ilusión de que se ejecutan en su propio procesador y memoria principal, aunque realmente los comparten.
Aun así, los procesos saben que hay un sistema operativo que los supervisa, porque le deben solicitar a él los distintos recursos a través de las llamadas al sistema.</p>
</div>
<div class="paragraph">
<p>Una máquina virtual también es un proceso en un sistema operativo una máquina real —también llamado sistema operativo anfitrión—.
Se utilizan la mismas técnicas para crear la ilusión de que se ejecuta en su propia máquina.
Sin embargo, en lugar de llamadas al sistema, el software que gestiona la máquina virtual ofrece una interfaz de hardware virtual.
Es decir:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>El sistema operativo de la máquina virtual intenta acceder al hardware, ya que presupone que se ejecuta en una máquina real.</p>
</li>
<li>
<p>El sistema operativo anfitrión intercepta estos intentos —ya que son instrucciones privilegiadas, prohibidas para los procesos en el modo usuario— y, en lugar de detener el proceso, comunica el suceso al software de gestión de la máquina virtual.</p>
</li>
<li>
<p>El software de gestión de la máquina virtual identifica a qué dispositivo y que intenta hacer el sistema operativo de la máquina virtual en él —para lo que generalmente se utilizan máquinas de estado que simulan el comportamiento del hardware real— y lo transforma en peticiones al sistema operativo anfitrión.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Por ejemplo, los intentos del sistema operativo virtual de acceder a los discos duros del hardware virtual, son convertidos en operaciones sobre un archivo, en un sistema de archivos real que contiene la imagen en disco de la máquina virtual.</p>
</div>
</div>
<div class="sect2">
<h3 id="_arranque_del_sistema">7.6. Arranque del sistema</h3>
<div class="paragraph">
<p>Desde el momento en que el ordenador se pone en marcha hasta que el sistema operativo inicia
su ejecución se realizan una serie de operaciones.
Estos son los pasos más comunes en el arranque de un sistema:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Llega a la CPU una señal de RESET motivada por el encendido del sistema o por un reinicio.</p>
</li>
<li>
<p>La CPU inicializa el contador de programa a una dirección predefinida de la memoria.
En esa dirección está el <em>bootstrap</em> inicial.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>El <em>bootstrap</em> es el programa que se encarga en primera instancia del arranque.
Debe estar almacenado en una memoria no volátil —ROM o Flash— por que la RAM está en un estado indeterminado en el momento del arranque.</p>
</div>
<div class="paragraph">
<p>En los PC el <em>bootstrap</em> forma parte del <em>firmware</em> —sea BIOS o UEFI— de las placas madres.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El término <em>firmware</em> viene de que por sus características se sitúa en algún lugar entre el hardware y el software.
Concretamente es un componente de software instalado en un dispositivo hardware para encargase de su control a bajo nivel.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_tareas_del_bootstrap">7.6.1. Tareas del bootstrap</h4>
<div class="paragraph">
<p>El <em>bootstrap</em> debe realizar diversas tareas:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Diagnostico de la máquina</strong> —o <em>Power-on Self-Test</em> (POST)—.
El <em>bootstrap</em> se detiene en este punto si el sistema no supera el diagnostico.</p>
</li>
<li>
<p><strong>Inicializar el sistema</strong>.
Por ejemplo, configurar los registros de la CPU, inicializar los dispositivos y contenido de la memoria, etc.</p>
</li>
<li>
<p><strong>Iniciar el sistema operativo</strong>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Al iniciar el sistema operativo hay que considerar que puede estar en diferentes ubicaciones según el tipo de dispositivo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>En <strong>consolas de videojuegos, móviles y otros dispositivos empotrados</strong> se almacena el sistema operativo en alguna forma de memoria de sólo lectura —ROM o Flash—.
Como la ejecución en esas memorias es más lenta que en la RAM, muchas veces el <em>bootstrap</em> suele copiar el sistema a la RAM durante el arranque, antes de iniciarlo.</p>
</li>
<li>
<p>En <strong>sistemas operativos de gran tamaño</strong> —incluidos los de propósito general— el sistema se almacena en disco.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En los sistemas mas antiguos, el <em>bootstrap</em> lee de una posición fija del disco —generalmente el bloque 0— el gestor de arranque, lo copia en la memoria y lo ejecuta.
Esto es lo que ocurre en los PC más antiguos que utilizan BIOS y particiones MBR.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>También se llama MBR a ese bloque 0 del disco donde está el gestor de arranque.
De hecho MBR son las siglas de <em>Master Boot Record</em> o <a href="https://es.wikipedia.org/wiki/Registro_de_arranque_principal">registro de arranque principal</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Aunque en ocasiones el código de ese bloque inicial de arranque sabe cargar e iniciar el sistema operativo completo, es común que sólo sepa donde está el resto del gestor de arranque en el disco, para cargarlo y ejecutarlo.
No debemos olvidar que el código cargado por el <em>bootstrap</em> debe caber en un sólo bloque del disco, que generalmente tiene solo 512 bytes.</p>
</div>
<div class="paragraph">
<p>En los PC más modernos que utilizan UEFI y particiones GPT, la UEFI tiene la capacidad de leer el sistema de archivo en las particiones para buscar directamente los archivos del gestor de arranque completo.
Una vez el <em>bootstrap</em> los encuentra, los carga y ejecuta.</p>
</div>
<div class="paragraph">
<p>En ambos casos, el gestor de arranque completo es el programa que sabe como iniciar el sistema operativo así que: explora el sistema de ficheros en busca del núcleo del sistema, lo carga e inicia su ejecución.</p>
</div>
<div class="paragraph">
<p>A partir de esto punto cada sistema operativo prosigue de forma diferente.
A modo de ejemplo, veremos como prosigue el arranque en sistemas UNIX en modo texto.</p>
</div>
</div>
<div class="sect3">
<h4 id="_arranque_de_sistemas_unix">7.6.2. Arranque de sistemas UNIX</h4>
<div class="paragraph">
<p>Al iniciarse el núcleo del sistema, este realiza una serie de tareas:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Configura el sistema para crear un entorno adecuado para la ejecución de los procesos: configuración de interrupciones, configuración de los modos de ejecución —privilegiado y usuario— y de la gestión de la memoria; inicialización de dispositivos y controladores; montaje del sistema de ficheros raíz; creación del proceso inactivo —que se ejecutará cuando no haya nada que hacer— etc.</p>
</li>
<li>
<p>Crea el proceso <strong>init</strong> —que por ser el primero tiene PID 1— a partir de la carga del programa <code>init</code> almacenado en el sistema de ficheros raíz.
En los sistemas GNU/Linux actuales el proceso <strong>init</strong> más común es <a href="https://es.wikipedia.org/wiki/Systemd">systemd</a>.</p>
</li>
<li>
<p>El planificador de la CPU toma el control de la gestión de la CPU y el núcleo queda dormido.
Puesto que la función del planificador es asignar procesos a la CPU y solo hay uno, el proceso <strong>init</strong>, éste es escogido y comienza su ejecución.</p>
</li>
<li>
<p>El proceso <strong>init</strong> lanza los <em>scripts</em> encargados de configurar los servicios —también llamados demonios— del sistema.
Por ejemplo, para el registro de eventos del sistema, gestión de dispositivos, particiones, impresoras, entre otros.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>El proceso <strong>init</strong> también configura el entorno de usuario.
Configura las terminales del sistema, inicia un proceso <strong>login</strong> conectado a cada una y se duerme a la espera.
Estos procesos <strong>login</strong> son monitorizados por <strong>init</strong> para reiniciarlos en caso de que mueran.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Aunque, por lo general, un sistema de escritorio tiene una única pareja de teclado y monitor y, por lo tanto, una única terminal real; el sistema suele esta configurado para crear varios terminales virtuales entre los que el usuario puede conmutar usando las combinaciones de teclas adecuadas.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Los procesos <strong>login</strong> se encargan de autenticar a los usuarios y de iniciar y configurar su sesión:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Muestran una pantalla de inicio de sesión donde se solicita el nombre del usuario y su contraseña.</p>
</li>
<li>
<p>Autentican al usuario comprobando las credenciales proporcionadas por el mismo.</p>
</li>
<li>
<p>Si la autenticación es positiva, el proceso <strong>login</strong> cambia su identidad actual —generalmente de <em>root</em> o administrador del sistema— por la del usuario autenticado, configura la sesión y sustituye su programa actual por el del intérprete de comandos que tiene configurado ese usuario (véase el <a href="#procesos_posix_api">Apartado 9.7.3.2</a>).</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>El interprete de comandos completa la configuración del entorno en base a sus ficheros de configuración, muestra el <a href="https://es.wikipedia.org/wiki/Prompt">prompt</a> y queda a la espera del primer comando del usuario.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_sistemas_operativos_por_su_estructura">8. Sistemas operativos por su estructura</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>9 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Ya hemos discutido anteriormente acerca de los componentes más comunes en un sistema operativo (véase el <a href="#_componentes_del_sistema">Capítulo 4</a>).
En esta sección comentaremos cómo se clasifican los distintos sistemas operativos según la organización e interconexión de sus componentes.</p>
</div>
<div class="sect2">
<h3 id="_estructura_sencilla">8.1. Estructura sencilla</h3>
<div class="paragraph">
<p></p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Los sistemas con <strong>estructura sencilla</strong> se caracterizan por:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>No tener una estructura bien definida.
Los componentes no están bien separados y las interfaces entre ellos no están bien definidas.</p>
</li>
<li>
<p>Son sistemas <strong>monolíticos</strong>, dado que gran parte de la funcionalidad del sistema se implementa en el núcleo.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ms_dos_2">8.1.1. MS-DOS</h4>
<div class="paragraph">
<p>Por ejemplo, en el <a href="https://es.wikipedia.org/wiki/MS-DOS">MS-DOS</a> los programas de aplicación podían acceder directamente a toda la memoria y a cualquier dispositivo.
Disponiendo de esa libertad un programa erróneo cualquiera podía corromper el sistema completo.</p>
</div>
<div id="estructura_msdos" class="imageblock">
<div class="content">
<img src="C08-estructura/images/estructura_msdos.svg" alt="estructura msdos">
</div>
<div class="title">Figura 21. Esquema de la estructura de MS-DOS.</div>
</div>
<div class="paragraph">
<p>Como el <a href="https://es.wikipedia.org/wiki/Intel_8086_y_8088">Intel 8086</a> para el que fue escrito MS-DOS no proporcionaba un modo dual de operación, los diseñadores del sistema no tuvieron más opción que dejar accesible el hardware a los programas de usuario.</p>
</div>
</div>
<div class="sect3">
<h4 id="_unix_2">8.1.2. UNIX</h4>
<div class="paragraph">
<p>Otro ejemplo es el de <a href="https://es.wikipedia.org/wiki/Unix">UNIX original</a>, donde si había una separación clara entre procesos de usuario y código del sistema, pero juntaba un montón de funcionalidad en el núcleo del sistema.</p>
</div>
<div id="estructura_unix" class="imageblock">
<div class="content">
<img src="C08-estructura/images/estructura_unix.svg" alt="estructura unix">
</div>
<div class="title">Figura 22. Esquema de la estructura de UNIX.</div>
</div>
<div class="paragraph">
<p>El núcleo proporciona la planificación de CPU, la gestión de la memoria, el soporte de los sistemas de archivos y muchas otras funcionalidades del sistema operativo.
En general se trata de una enorme cantidad de funcionalidad que es difícil de implementar y mantener, si no se compartimenta adecuadamente.</p>
</div>
<div class="paragraph">
<p>Tanto MS_DOS como UNIX eran originalmente sistemas pequeños y simples, limitados por las funcionalidades del hardware de su época, que fueron creciendo más allá de las previsiones originales.
Lo cierto es que con mejor soporte del hardware se puede dividir el sistema operativo en piezas más pequeñas y apropiadas que las del MS-DOS y el UNIX original.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_estructura_en_capas">8.2. Estructura en capas</h3>
<div class="paragraph">
<p></p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Los sistemas con <strong>estructura en capas</strong> se caracterizan por:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La funcionalidad se divide en capas, de tal forma que una capa solo utiliza funciones y servicios de la capa inmediatamente inferior y lo hace a través de una interfaz bien definida.</p>
</li>
<li>
<p>Como en la programación orientada a objetos, cada capa oculta a la capa superior los detalles de su implementación.
Por ejemplo, las estructuras de datos internas que usa y las operaciones o el hardware de la capa inferior que utiliza.</p>
</li>
<li>
<p>Escalan mejor que los sistemas con <strong>estructura sencilla</strong> porque las capas hacen que el código esté mejor compartimentado.
Por ejemplo, al corregir un <em>bug</em> o añadir una nueva funcionalidad solo hay que preocuparse de su efecto en la capa a la que afecta y no en todo el código del núcleo —siempre que no se altere la interfaz de la capa con el exterior—.</p>
</li>
<li>
<p>Ser menos eficiente que la de los sistemas de <strong>estructura sencilla</strong>.
En cada capa los argumentos son transformados y los datos necesarios deben de ser transferidos al invocar operaciones en la capa inferior, por lo que cada una añade cierto nivel de sobrecarga al funcionamiento del sistema.</p>
</li>
<li>
<p>También son sistemas <strong>monolíticos</strong>, dado que gran parte de la funcionalidad del sistema se implementa en el núcleo, aunque ahora el núcleo esté compartimentado en capas.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Un ejemplo de este tipo de sistemas operativos es el <a href="https://es.wikipedia.org/wiki/OS/2">OS/2</a>.</p>
</div>
<div id="estructura_os2" class="imageblock">
<div class="content">
<img src="C08-estructura/images/estructura_os2.svg" alt="estructura os2">
</div>
<div class="title">Figura 23. Esquema de la estructura de IBM OS/2.</div>
</div>
<div class="sect3">
<h4 id="_dificultades_con_el_diseño">8.2.1. Dificultades con el diseño</h4>
<div class="paragraph">
<p>Es importante tener en cuenta que diseñar un sistema con <strong>estructura en capas</strong> no es tan sencillo como pudiera parecer.
La definición de las capas y sus funcionalidades debe ser planificada cuidadosamente debido a la restricción, comentada anteriormente, de que un capa sólo puede utilizar los servicios de las capas inferiores.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, el planificador de la CPU suele tener información de los procesos que están en la memoria.
Parte de esa información puede ser almacenada en el disco para aumentar la memoria principal disponible.
Esto nos debería llevar a pensar que la gestión del almacenamiento secundario debe ir en una capa inferior a la del planificador de la CPU, para que así el segundo pueda pedir al primero que guarde los datos en disco.</p>
</div>
<div class="paragraph">
<p>Sin embargo, el planificador de la CPU debe asignar la CPU a otro proceso cuando el proceso que actualmente la ocupa solicita alguna operación de E/S —lo típico en multiprogramación—.
Como es la gestión del almacenamiento secundario el que debe pedir una operación al planificador de la CPU, ahora el primero debe estar sobre el segundo.</p>
</div>
<div class="paragraph">
<p>La solución a esta dependencia circular es hacer que ambos componentes estén en la misma capa.
Este tipo de dependencias no son raras, ocurre en muchos otros casos, ya que los componentes del sistema operativo suelen depender mucho unos de otros.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Al final, la solución de compromiso es tender hacia sistemas con muy pocas capas donde cada una tiene mucha funcionalidad.
Esto limita mucho las ventajas de esta técnica porque no permite compartimentar el núcleo tanto como sería deseable.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_microkernel">8.3. Microkernel</h3>
<div class="paragraph">
<p>
</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Los sistemas con <strong>estructura microkernel</strong> se caracterizan por:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Eliminar todos los componentes no esenciales del núcleo e implementarlos como procesos a nivel de usuario.</p>
</li>
<li>
<p>Un núcleo <strong>microkernel</strong> proporciona funciones mínimas de gestión de procesos y de memoria y algún mecanismo de comunicación entre procesos.
Sin embargo, hay que tener en cuenta que hay poco consenso a este respecto, por lo que algunos <strong>microkernel</strong> reales incluyen en el núcleo algunas funcionales adicionales.</p>
</li>
<li>
<p>El mecanismo de comunicación permite a los procesos de los usuarios solicitar servicios a los componentes del sistema.
También sirve para que los componentes del sistema se comuniquen entre sí y se pidan servicio.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Dado que los componentes del sistema están aislados unos de otros —ya que se implementan como procesos de usuario— el mecanismo de comunicación entre procesos es la única forma que tienen los procesos de los usuarios y los componentes, de solicitarles un servicio.</p>
</div>
<div id="estructura_minix3" class="imageblock">
<div class="content">
<img src="C08-estructura/images/estructura_minix3.svg" alt="estructura minix3">
</div>
<div class="title">Figura 24. Esquema de la estructura microkernel de MINIX 3.</div>
</div>
<div class="paragraph">
<p>Generalmente esta comunicación se implementa mediante paso de mensajes (véase el <a href="#_comunicación_entre_procesos">Apartado 9.8.2</a>).</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Entre los beneficios de estos sistemas operativos se incluyen:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Facilidad a la hora de añadir nuevas funcionalidades</strong>.
Los nuevos servicios son añadidos como aplicaciones de nivel de usuario, por lo que no es necesario hacer modificaciones en el núcleo.
Desarrollar en el modo privilegiado siempre es más peligrosos que en el modo usuario porque los errores pueden ser catastróficos: bloqueo o caída del sistema, corrupción de datos, etc.</p>
</li>
<li>
<p><strong>Facilidad a la hora de portar el sistema a otras plataformas</strong>.
Puesto que el núcleo es muy pequeño, resulta muy sencillo de portar a otras plataformas.</p>
</li>
<li>
<p><strong>Más seguridad y fiabilidad</strong>.
Puesto que la mayor parte de los servicios se ejecutan a nivel de usuario en procesos separados, un servicio que falla no puede afectar a otros ni puede ser utilizado para ganar acceso a otros servicios o al núcleo.
Además se pueden implementar estrategias para mejorar la tolerancia a fallos, como reiniciar un servicio que ha fallado, como si fuera un programa cualquiera.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_rendimiento">8.3.1. Rendimiento</h4>
<div class="paragraph">
<p>El mayor inconveniente es el pobre rendimiento que puede tener, causado por la sobrecarga que añade el mecanismo de comunicación.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, <a href="https://es.wikipedia.org/wiki/Windows_NT">Microsoft Windows NT</a> nació con una estructura de <strong>microkernel</strong> en capas donde una parte importante de los servicios eran proporcionados por unos procesos de usuario llamados subsistemas.</p>
</div>
<div class="paragraph">
<p>El sistema operativo podía mostrar diferentes personalidades o <em>entornos operativos</em> —básicamente de OS/2, POSIX y MSDOS— a través del uso de subsistemas ambientales, que también se ejecutaban como procesos de usuario.
Las aplicaciones de Microsoft Windows NT se comunicaban con estos subsistemas utilizando un mecanismo de comunicación denominado <a href="https://en.wikipedia.org/wiki/Local_Inter-Process_Communication">LPC</a> (<em>Local Inter-Process Communication</em>).</p>
</div>
<div class="paragraph">
<p>Con esta estructura, la pérdida de rendimiento respecto a Microsoft Windows 95 era tan importante —especialmente en lo relativo a operaciones gráficas— que los diseñadores se vieron obligados a mover más servicios al espacio del núcleo en la versión 4.0.
El resultado es que los Windows sucesores a Windows NT 4.0 tienen una arquitectura más monolítica que microkernel, ya que aunque muchos servicios siguen siendo proporcionados por procesos de usuario, esto sólo ocurre con aquellos donde el rendimiento no es un factor crítico.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Microsoft Windows XP tiene 280 llamadas al sistema a las que hay que sumar las más de 650 llamadas del subsistema gráfico, que también se aloja en el núcleo desde Microsoft Windows NT 4.0.
Mientras que Microsoft Windows NT 3.51 tenía algo menos de 200 llamadas al sistema.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Sin embargo varios sistemas operativos siguen utilizando núcleos <strong>microkernel</strong>, como <a href="https://es.wikipedia.org/wiki/QNX">QNX</a> o <a href="https://en.wikipedia.org/wiki/MINIX_3">MINIX 3</a>.
Ambos son sistemas operativos de tiempo real, que basan en la estructura de <strong>microkernel</strong> su estabilidad como sistema para tareas críticas.</p>
</div>
<div class="paragraph">
<p>En la <a href="#estructura_minix3">Figura 24</a>, por ejemplo, se puede observar un esquema de <a href="https://en.wikipedia.org/wiki/MINIX_3">MINIX 3</a>.
El núcleo es muy pequeño —apenas tiene 5000 líneas de código— por lo que la mayor parte de la funcionalidad reside en los procesos de servicios y de controladores de dispositivo.</p>
</div>
<div class="paragraph">
<p><a href="https://en.wikipedia.org/wiki/MINIX_3">MINIX 3</a> es un sistema compatible POSIX.
Así que soporta las llamadas al sistema definidas por este estándar, pero éstas se convierten en mensajes enviados al servidor correspondiente con la petición, y no en llamadas directas al núcleo.
Para que un servidor pueda atender una petición, quizás tenga que enviar peticiones a otros servidores o controladores de dispositivo.
Incluso pueden tener que hacer llamadas al núcleo, para solicitar alguna operación privilegiada que no se puede implementar en el modo usuario.
Por ejemplo, operaciones de E/S —fundamentales para los controladores de dispositivo— o el acceso a tablas del núcleo —como la tabla de procesos—.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Es este trasiego de mensaje con peticiones y respuestas —y la correspondiente conmutación de procesos en la CPU para ejecutar el proceso que atiende cada mensaje— para resolver una petición de un proceso de usuario, lo que teóricamente justica el menor rendimiento de los sistemas <strong>microkernel</strong>.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_estructura_modular">8.4. Estructura modular</h3>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Los sistemas con <strong>estructura modular</strong> se caracterizan por:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Dividir el núcleo en módulos, cada uno de los cuales implementa funciones y servicios concretos y se comunican entre sí a través de una interfaz bien definida.</p>
</li>
<li>
<p>Como en la programación orientada a objetos, cada módulo oculta al resto los detalles de su implementación.</p>
</li>
<li>
<p>Todos los módulos pueden llamar a funciones de la interfaz de cualquier otro módulo, a diferencia de los sistemas operativos con <strong>estructura en capas</strong>, donde una capa solo podía usar a la inmediatamente inferior.</p>
</li>
<li>
<p>También son sistemas <strong>monolíticos</strong>, dado que gran parte de la funcionalidad del sistema se implementa en el núcleo, aunque ahora el núcleo esté compartimentado en módulos.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Estos núcleos suelen disponer de un pequeño conjunto de componentes fundamentales que se cargan durante el arranque.
Posteriormente pueden cargar módulos adicionales, tanto durante la inicialización del sistema como en tiempo de ejecución.</p>
</div>
<div id="estructura_linux" class="imageblock">
<div class="content">
<img src="C08-estructura/images/estructura_linux.svg" alt="estructura linux">
</div>
<div class="title">Figura 25. Esquema de la estructura del núcleo Linux.</div>
</div>
<div class="paragraph">
<p>En este aspecto se asemejan a los núcleos <strong>microkernel</strong>, ya que el módulo principal sólo tiene funciones básicas.
Sin embargo los núcleos modulares:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Son más eficientes</strong> al no necesitar un mecanismo de comunicación, puesto que los componentes se cargan en la memoria destinada al núcleo, por lo que pueden llamarse directamente.</p>
</li>
<li>
<p><strong>Son menos seguros y fiables</strong>, puesto que gran parte de su funcionalidad se ofrece desde el modo privilegiado.
Un error en cualquier componente puede comprometer o hacer caer el sistema.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Este tipo de estructura es la utilizada en los UNIX modernos, como <a href="https://es.wikipedia.org/wiki/Solaris_(sistema_operativo)">Oracle/Sun Microsystems Solaris</a>, <a href="https://es.wikipedia.org/wiki/FreeBSD">FreeBSD</a>, <a href="https://es.wikipedia.org/wiki/GNU/Linux">Linux</a> (véase la <a href="#estructura_linux">Figura 25</a>) y <a href="https://es.wikipedia.org/wiki/MacOS">macOS</a>.</p>
</div>
</div>
</div>
</div>
<h1 id="_gestión_de_procesos_2" class="sect0">Parte III: Gestión de procesos</h1>
<div class="sect1">
<h2 id="_procesos">9. Procesos</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>39 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Los primeros sistemas informáticos solo permitían que un programa se ejecutara cada vez.
Dicho programa tenía control completo sobre el sistema y acceso a todos los recursos del mismo.
Por el contrario, los sistemas <strong>multitarea</strong> actuales permiten que múltiples programas sean cargados y ejecutados concurrentemente.</p>
</div>
<div class="paragraph">
<p>Obviamente esta evolución implica un control más fino y la compartimentación de los diversos programas, para que no interfieran unos con otros.
Esto, a su vez, conduce a la aparición de la noción de <strong>proceso</strong>, que no es sino la unidad de trabajo en un sistema operativo moderno de tiempo compartido.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Por simplicidad, en este capítulo utilizaremos los términos <strong>trabajo</strong> y <strong>proceso</strong> de forma indistinta.
A fin de cuentas tanto los <strong>trabajos</strong> en los antiguos <em>mainframes</em> como los <strong>procesos</strong> en los sistemas modernos son la unidad de trabajo en sus respectivos sistemas y el origen de toda actividad en la CPU.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Por último, antes de continuar, es importante señalar que en un sistema operativo hay varios tipos de procesos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Procesos del sistema</strong>.
Ejecutan el código del sistema operativo contenido en los <strong>programas del sistema</strong>, que generalmente sirven para hacer tareas del sistema operativo que es mejor mantener fuera del núcleo.</p>
</li>
<li>
<p><strong>Procesos de usuario</strong>
Ejecutan el código contenido en los <em>programas de aplicación</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Sin embargo, en lo que resta de capítulo, no estableceremos ninguna distinción entre ellos.
En lo que respecta a la gestión de estos procesos en el sistema, no hay ninguna diferencia.</p>
</div>
<div class="sect2">
<h3 id="_el_proceso">9.1. El proceso</h3>
<div class="paragraph">
<p>Como ya hemos comentado con anterioridad, un <strong>proceso</strong> es un programa en ejecución (véase el <a href="#_gestión_de_procesos">Apartado 4.1</a> para una definición más completa).
Sin embargo, los procesos no solo están compuestos por el código del programa, sino que también son importantes otros elementos:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Segmento de código</dt>
<dd>
<p>Contiene las instrucciones ejecutables del programa.
También es conocido como segmento <strong>text</strong> o <strong>.text</strong>.</p>
</dd>
<dt class="hdlist1">Segmento de datos</dt>
<dd>
<p>Contiene las variables globales y estáticas del programa que se inicializan con un valor predefinido.
También es conocido como segmento <strong>.data</strong>.</p>
</dd>
<dt class="hdlist1">Segmento BSS</dt>
<dd>
<p>Contiene las variables globales y estáticas del programa inicializadas a 0 o sin inicialización explícita   .
También es conocido como segmento <strong>.bss</strong>.</p>
</dd>
<dt class="hdlist1">Pila</dt>
<dd>
<p>Contiene datos temporales, como los parámetros y direcciones de retorno de las funciones y las variables locales.</p>
</dd>
<dt class="hdlist1">Montón</dt>
<dd>
<p>Contiene el espacio de la memoria que se asigna dinámicamente durante la ejecución del proceso.
También es conocido como <strong>heap</strong>.</p>
</dd>
<dt class="hdlist1">Información sobre el estado actual de ejecución</dt>
<dd>
<p>Como el <strong>contador de programa</strong>, los valores de los <strong>registros de la CPU</strong>, el <strong>estado</strong> del proceso y más (véase el <a href="#_bloque_de_control_de_proceso">Apartado 9.3</a>).</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="paragraph">
<p>Los <strong>segmentos de código</strong>, <strong>datos</strong> y <strong>BSS</strong> por lo general son secciones dentro del archivo ejecutable que contiene el programa.
El resto de elementos los crea el sistema operativo al cargar el programa y crear el proceso.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Como vimos en el <a href="#_gestión_de_procesos">Apartado 4.1</a> varios procesos pueden estar asociados al mismo programa pero no por eso dejan de ser distintos procesos.
Todos tendrá una copia del mismo segmento de código, pero diferente: contador de programas, valores en los registros de la CPU, pila, segmento de datos, montón y demás propiedades.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>En la <a href="#proceso_en_memoria">Figura 26</a> se puede observar la disposición de algunos de estos elementos de un proceso en la memoria.</p>
</div>
<div id="proceso_en_memoria" class="imageblock">
<div class="content">
<img src="C09-procesos/images/proceso_en_memoria.svg" alt="proceso en memoria">
</div>
<div class="title">Figura 26. Anatomía de un proceso en memoria.</div>
</div>
</div>
<div class="sect2">
<h3 id="_estados_de_los_procesos">9.2. Estados de los procesos</h3>
<div class="paragraph">
<p>Cada proceso tiene un <strong>estado</strong> que cambia a lo largo de su ejecución y que está definido, parcialmente, por la actividad que realiza actualmente el propio proceso.</p>
</div>
<div id="diagrama_estado_proceso" class="imageblock">
<div class="content">
<img src="C09-procesos/images/diagrama_estado_proceso.svg" alt="diagrama estado proceso">
</div>
<div class="title">Figura 27. Diagrama de estado de un proceso.</div>
</div>
<div class="paragraph">
<p>Los estados por los que puede pasar un procesos varían de un sistema operativo a otro, aunque los siguientes son comunes a todos ellos:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Nuevo</dt>
<dd>
<p>El proceso está en proceso de creación.
Este estado existe porque la creación de un proceso no es algo instantáneo.
Necesita de varias operaciones que pueden tarda tiempo en realizarse, como: reservar memoria libre, cargar el programa en la memoria, inicializar estructuras de datos y configurar el entorno de ejecución.</p>
</dd>
<dt class="hdlist1">Ejecutando</dt>
<dd>
<p>El proceso está siendo ejecutado en la CPU.
Para eso tiene que haber sido escogido por el planificador de la CPU de entre todos los procesos en estado <strong>preparado</strong>.
Sólo puede haber un proceso en este estado por CPU en el sistema.</p>
</dd>
<dt class="hdlist1">Esperando</dt>
<dd>
<p>El proceso está esperando por algún <strong>evento</strong> como, por ejemplo, que termine una operación de E/S solicitada previamente o que otro proceso termine su ejecución.
Múltiples procesos pueden estar en este estado de espera.</p>
</dd>
<dt class="hdlist1">Preparado</dt>
<dd>
<p>El proceso está esperando a poder usar la CPU.
Múltiples procesos pueden estar en este estado.</p>
</dd>
<dt class="hdlist1">Terminado</dt>
<dd>
<p>El proceso ha finalizado su ejecución y espera a que el sistema operativo recupere los recursos que le fueron asignados.
Como en el caso del estado <strong>nuevo</strong>, este estado existe porque terminar un proceso no es algo instantáneo.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>El diagrama de estados de los procesos, con las transiciones posibles entre ellos, se muestra en la <a href="#diagrama_estado_proceso">Figura 27</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_bloque_de_control_de_proceso">9.3. Bloque de control de proceso</h3>
<div class="paragraph">
<p>El <strong>bloque de control de proceso</strong> o <strong>PCB</strong> (<em>Process Control Block</em>) es una estructura de datos que representa a cada proceso en el sistema operativo y que guarda información sobre su estado de actividad actual.</p>
</div>
<div class="paragraph">
<p>En el sistema hay un PCB por proceso y sirve de almacén para cualquier información que puede variar de un proceso a otro:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Estado del proceso</strong>.
El estado actual del proceso de la lista que hemos visto anteriormente.
Por ejemplo: nuevo, preparado, esperando, etc.</p>
</li>
<li>
<p><strong>Contador de programa</strong>.
Indica la dirección de la próxima instrucción del proceso que debe ser ejecutada por la CPU.
Obviamente, durante el estado <strong>ejecutando</strong> el contador de programa está en el registro correspondiente de la CPU.
Su valor se guarda en el PCB al salir el proceso de la CPU para que comience ejecutarse en ella otro proceso.</p>
</li>
<li>
<p><strong>Registros de la CPU</strong>.
El valor de los registros de la CPU también forma parte del estado de actividad del proceso.
Como en el caso del <strong>contador de programa</strong>, durante el estado <strong>ejecutando</strong> los valores están en los registros de la CPU, pero se guardan en el PCB cuando el proceso sale de la CPU para que se ejecute otro proceso.</p>
</li>
<li>
<p><strong>Información de planificación de la CPU</strong>.
Incluye la información requerida por el planificador de la CPU.
Por ejemplo la prioridad del proceso, punteros a las colas de planificación donde está el proceso, punteros al PCB del proceso padre y de los procesos hijos, etc.</p>
</li>
<li>
<p><strong>Información de gestión de la memoria</strong>.
Incluye la información requerida para la gestión de la memoria.
Por ejemplo los valores de los registros base y límite que definen el área de la memoria física que ocupa el proceso —en el caso de se use asignación de memoria contigua (véase el <a href="#_asignación_de_memoria_contigua">Apartado 15.3</a> o la dirección a la tabla de páginas —en el caso de que se use paginación (véase el <a href="#_paginación">Capítulo 16</a>)—.</p>
</li>
<li>
<p><strong>Información de registro</strong>.
Aquí se incluye la cantidad de CPU usada, límites de tiempo en el uso de la CPU, estadísticas de la cuenta del usuario al que pertenece el proceso, estadísticas de la ejecución del proceso, etc.</p>
</li>
<li>
<p><strong>Información de estado de la E/S</strong>.
Incluye la lista de dispositivos de E/S reservados por el proceso, la lista de archivos abiertos, etc.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_colas_de_planificación">9.4. Colas de planificación</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>En los sistemas operativos hay diferentes <strong>colas de planificación</strong> para los procesos en distintos <strong>estados</strong>.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Cola de trabajo</dt>
<dd>
<p>Contiene a todos los trabajos en el sistema, de manera que cuando entran en el sistema van a esta cola, a la espera de ser escogidos para ser cargados en la memoria y ejecutados.
Esta cola existía en los <strong>sistemas multiprogramados</strong> pero no existe en los sistemas operativos modernos.</p>
</dd>
<dt class="hdlist1">Cola de preparados</dt>
<dd>
<p>Contiene a los procesos que están en estado <strong>preparado</strong>.
Es decir, procesos cargados en la memoria principal que esperan para usar la CPU.
La cola de preparados es generalmente una lista enlazada de PCB, donde cada uno incluye un puntero al PCB del siguiente proceso en la cola.</p>
</dd>
<dt class="hdlist1">Colas de espera</dt>
<dd>
<p>Contienen a los procesos que están en estado <strong>*esperando</strong>.
Es decir, que esperan por un evento concreto, como por ejemplo la finalización de una petición de E/S.
Estas colas también suelen ser implementadas como listas enlazadas de PCB y suele haber una por evento, de manera que cuando ocurre algún evento todos los procesos en la cola asociada pasan automáticamente al estado <strong>preparado</strong> y a la <strong>cola de preparados</strong>.</p>
</dd>
<dt class="hdlist1">Colas de dispositivo</dt>
<dd>
<p>Son un caso particular de cola de espera.
Cada dispositivo de E/S tiene asociada una <strong>cola de dispositivo</strong> que contiene los procesos que están <strong>esperando</strong> por ese dispositivo en particular.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Una manera habitual de representar la planificación de procesos es a través de un diagrama de colas como el de la <a href="#colas_de_planificación_procesos">Figura 28</a>.</p>
</div>
<div id="colas_de_planificación_procesos" class="imageblock">
<div class="content">
<img src="C09-procesos/images/colas_planificación_procesos.svg" alt="colas planificación procesos">
</div>
<div class="title">Figura 28. Diagrama de colas de la planificación de procesos.</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Analizándolo podemos tener una idea clara del flujo típico de los procesos dentro del sistema:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Un nuevo proceso llega al sistema</strong>.
Una vez pasa del estado <strong>nuevo</strong> a <strong>preparado</strong> es colocado en la <strong>cola de preparados</strong>.
Allí espera hasta que es seleccionado por el <strong>planificado de la CPU</strong> para su ejecución y se le asigna la CPU.
Mientras se ejecuta pueden ocurrir varias cosas:</p>
<div class="ulist">
<ul>
<li>
<p><strong>El proceso solicita una operación de E/S</strong> por lo que abandona la CPU y es colocado en la <em>cola de dispositivo</em> correspondiente en estado <strong>esperando</strong>.
No debemos olvidar que aunque en nuestro diagrama no exista más que una de estas colas, en un sistema operativo real suele haber una para cada dispositivo.</p>
</li>
<li>
<p><strong>El proceso puede querer esperar por un evento</strong>.
Por ejemplo, puede crear otro proceso y esperar a que termine.
En ese caso el proceso hijo es creado, mientras el proceso padre abandona la CPU y es colocado en una <strong>cola de espera</strong> en estado <strong>esperando</strong> hasta que el proceso hijo termine.
La terminación del proceso hijo es el evento que espera el proceso padre para salir de la <strong>cola de espera</strong> y entrar en la <strong>cola de preparados</strong> para continuar su ejecución en la CPU cuando sea posible.</p>
</li>
<li>
<p><strong>El proceso puede ser sacado forzosamente de la CPU</strong>, como resultado de la interrupción del temporizador, que permite determinar cuando un proceso lleva demasiado tiempo ejecutándose, así que es colocado en la <strong>cola de preparados</strong> en estado <strong>preparado</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Cuando las esperas concluyen, los procesos vuelven a la cola de preparado</strong>, pasando del estado de espera al de preparado.</p>
</li>
<li>
<p><strong>Los procesos repiten este ciclo hasta que terminan</strong>.
En ese momento son eliminados de todas las colas mientras el PCB y los recursos asignados son recuperados por parte del sistema operativo para poder usarlos con otros procesos.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_de_procesos">9.5. Planificación de procesos</h3>
<div class="paragraph">
<p>Durante su ejecución, los procesos se mueven entre las diversas colas de planificación a criterio del sistema operativo.
Este proceso de selección debe ser realizado por el <strong>planificador</strong> adecuado:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>El <strong>planificador de largo plazo</strong> Do <strong>planificador de trabajos</strong>— selecciona los trabajos desde la cola de trabajos en el almacenamiento secundario —dónde están todos almacenados— y los carga en memoria.</p>
<div class="paragraph">
<p>Este planificador se usaba en los sistemas multiprogramados, donde había cola de trabajo.
Los sistemas de tiempo compartido posteriores y los sistemas modernos, carecen de planificador de trabajos, porque los programas se cargan directamente en memoria para ser ejecutados, cuando el usuario lo solicita.</p>
</div>
</li>
<li>
<p>El <strong>planificador de corto plazo</strong> o <strong>planificador de CPU</strong> selecciona uno de los procesos en la cola de preparados y lo asigna a la CPU.
Obviamente este planificador es invocado cuando un proceso en ejecución abandona la CPU, dejándola disponible para otro proceso.</p>
</li>
<li>
<p>El <strong>planificador de medio plazo</strong>  era utilizado en algunos sistemas para sacar procesos de la memoria cuando escasea y reintroducirlos posteriormente cuando vuelve a haber suficiente memoria libre.
A este esquema se le denomina <strong>intercambio</strong> —o <strong><em>swapping</em></strong>.</p>
<div class="paragraph">
<p>Esto era útil en sistemas antiguos donde un proceso tenía que estar cargado completamente en la memoria para poder ejecutarse.
Así que si faltaba memoria, se podía suspender un proceso completo, preservar el contenido de su memoria en disco y liberar la memoria ocupada para usarla con otros procesos.</p>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En los sistemas de propósito general modernos no se utiliza <strong>planificador de medio plazo</strong> porque utilizan técnicas de <strong>memoria virtual</strong> (véase el <a href="#_memoria_virtual">Apartado 17.1</a>), que permite mover parte de la memoria de los procesos al disco para liberar memoria, sin tener que suspender su ejecución.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_cambio_de_contexto">9.6. Cambio de contexto</h3>
<div class="paragraph">
<p>El <strong>cambio de contexto</strong> es la tarea de asignar la CPU un proceso distinto al que la tiene asignada en el momento actual.
Esto implica salvar el estado del viejo proceso en su PCB y cargar en la CPU el estado del nuevo.
Entre la información que debe ser preservada en el PCB se incluyen:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>El <strong>contador de programa</strong>.</p>
</li>
<li>
<p>Los <strong>registros de la CPU</strong>.</p>
</li>
<li>
<p>El <strong>estado del proceso</strong>.</p>
</li>
<li>
<p>La <strong>información de gestión de la memoria</strong>.
Por ejemplo, la información necesaria para configurar el espacio de direcciones del proceso.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El cambio de contexto es sobrecarga pura, puesto que no hace ningún trabajo útil mientras se conmuta.
Su velocidad depende de aspectos tales como: el número de registros, la velocidad de la memoria y la existencia de instrucciones especiales</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Algunas CPU disponen de instrucciones especiales para salvar y cargar todos los registros de manera eficiente.
Esto reduce el tiempo que la CPU está ocupada en los cambios de contexto.</p>
</div>
<div class="paragraph">
<p>Otra opción es el uso de <a href="https://en.wikipedia.org/wiki/Register_file">juegos de registros</a>, como es el caso de los procesadores <a href="https://es.wikipedia.org/wiki/UltraSPARC">Sun UltraSPARC</a> e <a href="https://es.wikipedia.org/wiki/Intel_Itanium">Intel Itanium</a>.
Con ellos el juegos de registros actual de la CPU se mapea sobre un banco de registros mucho más extenso.
Al hacer cambio de contexto, se mapea el juego de registros a otros registros diferentes del banco.
Esto permite que la CPU almacene de forma eficiente el valor de los registros de más de un proceso, sin que en cada cambio de contexto sea necesario copiarlos al PCB del proceso en la memoria principal.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_operaciones_sobre_los_procesos">9.7. Operaciones sobre los procesos</h3>
<div class="paragraph">
<p>En general es necesario que los procesos pueden ser creados y eliminados dinámicamente, por lo que los sistemas operativos deben proporcionar servicios para la creación y terminación de los mismos.</p>
</div>
<div class="sect3">
<h4 id="_creación_de_procesos">9.7.1. Creación de procesos</h4>
<div class="paragraph">
<p>Un proceso —denominado <strong>padre</strong>— puede crear múltiples procesos —los <strong>hijos</strong>— utilizando una llamada al sistema específica para la creación de procesos.
Cada proceso creado se identifica de manera unívoca mediante un <strong>identificador de proceso</strong> o <strong>PID</strong> (<em>Process Identifier</em>), que normalmente es un número entero.</p>
</div>
<div class="paragraph">
<p>Por ejemplo en sistemas POSIX un programa puede crear otro proceso así:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">pid_t</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>mientras que en Windows API es así:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">PROCESS_INFORMATION</span> <span class="n">pi</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
<span class="k">if</span> <span class="p">(</span> <span class="n">CreateProcess</span><span class="p">(</span> <span class="s">"C:</span><span class="se">\\</span><span class="s">Windows</span><span class="se">\\</span><span class="s">System32</span><span class="se">\\</span><span class="s">charmap.exe"</span><span class="p">,</span> <span class="cm">/* ... */</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">pi</span> <span class="p">))</span> <i class="conum" data-value="1"></i><b>(1)</b>
<span class="p">{</span>
    <span class="n">DWORD</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">pi</span><span class="p">.</span><span class="n">dwhProcessId</span><span class="p">;</span> <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="n">HANDLE</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">pi</span><span class="p">.</span><span class="n">hProcess</span><span class="p">;</span> <i class="conum" data-value="3"></i><b>(3)</b>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> devuelve <code>TRUE</code> si el proceso se creó con éxito.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/ns-processthreadsapi-process_information">PROCESS_INFORMATION</a> contiene el <strong>identificador de proceso</strong> del nuevo proceso, si <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> ha tenido éxito.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/ns-processthreadsapi-process_information">PROCESS_INFORMATION</a> también contiene el manejador del proceso —o <em>handle</em> en inglés— que sirve para obtener y manipular el nuevo proceso.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>En ambos casos <code>pid</code> identifica al nuevo proceso en el sistema.
Sin embargo, mientras que los sistemas POSIX ese identificador se puede usar en otras llamadas al sistema para indicar futuras operaciones sobre el proceso, en Windows lo que se utiliza es el manejador <code>hProcess</code> devuelto en <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/ns-processthreadsapi-process_information">PROCESS_INFORMATION</a>.</p>
</div>
<div class="paragraph">
<p>Obviamente, cada proceso puede obtener del sistema su propio identificador de procesos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="cm">/* POSIX API */</span>
<span class="n">pid_t</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">getpid</span><span class="p">();</span>

<span class="cm">/* Windows API */</span>
<span class="n">HANDE</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">GetCurrentProcess</span><span class="p">();</span>
<span class="n">DWORD</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">GetProcessId</span><span class="p">(</span> <span class="n">handle</span> <span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>o el de su padre:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="cm">/* POSIX API */</span>
<span class="n">pid_t</span> <span class="n">parent</span> <span class="o">=</span> <span class="n">getppid</span><span class="p">();</span></code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_árbol_de_procesos">Árbol de procesos</h5>
<div class="paragraph">
<p>Puesto que cada nuevo proceso puede a su vez crear otros procesos, al final se acaba obteniendo un <strong>árbol de procesos</strong>.
En los sistemas POSIX es muy sencillo de ver ejecutando el comando <a href="https://man7.org/linux/man-pages/man1/pstree.1.html">pstree</a>.</p>
</div>
<div class="paragraph">
<p>En estos sistemas el proceso <strong>init</strong> es el proceso padre raíz de todos los procesos de usuario.
Su PID siempre es 1 ya que es el primer proceso creado por el sistema operativo al terminar la inicialización del núcleo.
Por lo tanto, es el responsable de crear todos los otros procesos que son necesarios para el funcionamiento del sistema.</p>
</div>
</div>
<div class="sect4">
<h5 id="_cómo_obtienen_los_procesos_hilos_los_recursos_que_necesitan">Cómo obtienen los procesos hilos los recursos que necesitan</h5>
<div class="paragraph">
<p>Hay varios aspectos en la creación de los procesos que pueden variar de un sistema operativo a otro.
Uno de ellos es cómo obtienen los procesos hilos los recursos que necesitan para hacer su trabajo.</p>
</div>
<div class="paragraph">
<p>Fundamentalmente existen dos alternativas:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Que cada proceso hijo puede solicitar y obtener los recursos directamente del sistema operativo, compitiendo por los recursos del sistema en las mismas condiciones que el resto de procesos en ejecución.
Esta es la opción más común en los sistemas de propósito general actuales, como Microsoft Windows, Android, Linux, macOS, BSD y muchos otros.</p>
</li>
<li>
<p>Que los proceso hijo solo puedan aspirar a obtener un subconjunto de los recursos de su padre.
Esto es interesante en sistemas diseñados para ser muy robustos, ya que evita que un proceso pueda sobrecargar el sistema creando múltiples procesos que consuman demasiada memoria o tiempo de CPU.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>En este último caso, el proceso padre puede estar obligado a repartir sus recursos entre los procesos hijo. O pueda que el sistema les permita compartir algunos de esos recursos —como memoria o archivos— con algunos de sus hijos.</p>
</div>
</div>
<div class="sect4">
<h5 id="_cómo_pasar_parámetros_de_inicialización_a_los_procesos_hijo">Cómo pasar parámetros de inicialización a los procesos hijo</h5>
<div class="paragraph">
<p>Generalmente, el proceso padre suele disponer de algún mecanismo para pasar parámetros de inicialización a sus procesos hijo.</p>
</div>
<div class="sect5">
<h6 id="_argumentos_de_línea_de_comandos">Argumentos de línea de comandos</h6>
<div class="paragraph">
<p>Por ejemplo, en Windows API un proceso puede usar el segundo argumento de <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> para indicar al proceso hijo opciones y argumentos de línea de comandos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">HANDLE</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">CreateProcess</span><span class="p">(</span><span class="s">"C:</span><span class="se">\\</span><span class="s">holamundo.exe"</span><span class="p">,</span> <span class="s">"/v /s foo.txt bar.png"</span><span class="p">,</span> <span class="cm">/* ... */</span> <span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Si el proceso hijo está programado en C o C&#43;&#43;, podrá acceder a los argumentos <code>/v</code>, <code>/s</code>, <code>foo.txt</code> y <code>bar.png</code> a través de los argumentos <code>argc</code> y <code>argv</code> de la función <a href="https://en.cppreference.com/w/c/language/main_function">main()</a> del programa:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">int</span> <span class="nf">main</span> <span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="cm">/* . . . */</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>de forma que <code>argv[0]</code> contendrá <code>/v</code>, <code>argv[2]</code> contendrá <code>/s</code> y así sucesivamente.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>Obviamente, en otros lenguajes de programación se accede de manera diferente a estos argumentos de línea de comandos.</p>
</div>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_variables_de_entorno">Variables de entorno</h6>
<div class="paragraph">
<p>Otra forma de pasar parámetros a un proceso hijo es usando las <strong>variables de entorno</strong>, que no son sino variables dinámicas que se pueden crear, leer y modificar durante la ejecución del proceso.</p>
</div>
<div class="paragraph">
<p>Las <strong>variables de entorno</strong> se gestionan con funciones específicas ofrecidas por la API del sistema operativo:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Tabla 1. Funciones de la API para gestionar variables de entorno.</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">POSIX API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Windows API</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Leer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man3/getenv.3.html">getenv()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-getenvironmentvariable">GetEnvironmentVariable()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Leer todos</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man7/environ.7.html">environ</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/processenv/nf-processenv-getenvironmentstrings">GetEnvironmentStrings()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crear / modificar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man3/setenv.3.html">setenv()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-setenvironmentvariable">SetEnvironmentVariable()</a></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>por ejemplo, en sistemas POSIX un programa leer la variable de entorno <code>PATH</code> así:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">char</span><span class="o">*</span> <span class="n">path</span> <span class="o">=</span> <span class="n">getenv</span><span class="p">(</span><span class="s">"PATH"</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>mientras que en Windows API es así:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">DWORD</span> <span class="n">buffSize</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">;</span>
<span class="n">TCHAR</span> <span class="n">path</span><span class="p">[</span><span class="n">buffSize</span><span class="p">];</span>
<span class="n">GetEnvironmentVariable</span><span class="p">(</span><span class="s">"PATH"</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">buffSize</span><span class="p">);</span> <i class="conum" data-value="1"></i><b>(1)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>El valor de la variable de entorno <code>PATH</code> se copia en <code>path</code>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Usando <a href="https://man7.org/linux/man-pages/man3/setenv.3.html">setenv()</a> o <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-setenvironmentvariable">SetEnvironmentVariable()</a> de forma similar, cualquier proceso puede crear variables de entorno que serán accesibles a sus procesos hijos, porque por defecto los nuevos procesos heredan un duplicado de las variables de entorno de su proceso padre.
Así se pueden pasar parámetros de configuración para alterar el comportamiento de los procesos hijo.</p>
</div>
<div class="paragraph">
<p>Todas las variantes de sistemas UNIX, así como MS-DOS y todas las versiones de Microsoft Windows soportan variables de entorno.</p>
</div>
</div>
<div class="sect5">
<h6 id="_herencia_de_recursos">Herencia de recursos</h6>
<div class="paragraph">
<p>En algunos sistemas operativos los procesos hijos pueden heredar cierto tipo de recursos del proceso padre, lo que también puede servir para inicializar y alterar el comportamiento del proceso hijo.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, en los sistemas POSIX todos los archivos abiertos por un proceso son heredados en el mismo estado por sus hijos.
Lo interesante es que en estos sistemas muchos recursos se gestionan como archivos.
Algunos ejemplo podrían ser: dispositivos de E/S, memoria compartida, tuberías, <em>sockets</em> y otros mecanismos de comunicación.</p>
</div>
<div class="paragraph">
<p>En POSIX todo proceso tiene, por defecto, tres archivos abiertos que corresponden a tres dispositivos de E/S especiales:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Entrada estándar</strong>, de dónde los procesos leen la entrada del teclado de la terminal.</p>
</li>
<li>
<p><strong>Salida estándar</strong>, donde el proceso escribe para mostrar texto en la pantalla de la terminar.</p>
</li>
<li>
<p><strong>Salida de error</strong>, usada para mostrar errores en la pantalla de la terminal.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Debido a la herencia de los archivos abiertos del proceso padre, todo proceso hijo tiene acceso a estos tres mismos dispositivos.
Y a su vez también la tendrán sus hijos y los hijos de estos.
De esta manera, todo proceso tiene acceso a los dispositivos de E/S de la terminal donde se ejecuta.
Pero también permite a un proceso controlar el destino de la E/S de un proceso hijo —y de los hijos de este—.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, si antes de crear el proceso hijo sustituye el dispositivo de salida estándar por un archivo real, todo lo que el hijo intente mostrar por pantalla se guardará en dicho archivo, en lugar de mostrarse.
Mientras que si lo hace con el dispositivo de entrada estándar, todo lo que pretenda leer de teclado realmente lo leerá de un archivo que el padre puede haber preparado, como si de algún tipo de control remoto se tratara.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Esta misma idea se puede extender a procesos que ofrecen servicios, ya sea a otros procesos del mismo sistema o a redes de ordenadores, como Internet.</p>
</div>
<div class="paragraph">
<p>Cada conexión con un cliente es como archivo abierto, por lo que los hijos del proceso heredan las conexiones.
Así que es común la estrategia de crear un hijo por conexión para que la atienda en nombre del padre, mientras este se encarga de recibir nuevas conexiones.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>En Microsoft Windows existe un mecanismo similar pero no por defecto.
La función <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> de Windows API permite indicar si se quiere que el nuevo proceso herede los recursos abiertos.
Y también tiene ajustes específicos para la entrada y salida estándar y la salida de error del nuevo proceso.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_qué_ocurre_con_la_ejecución_del_padre">Qué ocurre con la ejecución del padre</h5>
<div class="paragraph">
<p>Se suelen contemplar dos posibilidades en términos de la ejecución del padre:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Que el padre continúe ejecutándose al mismo tiempo que el hijo.
Es lo más común en los sistemas multitarea actuales.</p>
</li>
<li>
<p>Que le padre quede detenido a la espera que de algunos o todos sus hijos terminen.
Era lo más frecuente en sistemas monotarea, como <a href="https://es.wikipedia.org/wiki/MS-DOS">MS-DOS</a>.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_cómo_se_construye_el_espacio_de_dirección_de_los_procesos_hijo">Cómo se construye el espacio de dirección de los procesos hijo</h5>
<div class="paragraph">
<p>En general hay dos posibilidades:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Que el espacio de direcciones del proceso hijo sea un duplicado del que tiene el padre.
Es decir, que inicialmente el hijo tenga el mismo código y datos que el padre.
Es lo que hace <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> en los sistemas POSIX.</p>
</li>
<li>
<p>Que el espacio de direcciones del proceso hijo se cree desde cero y se cargue en él un nuevo programa.
Es lo que hace <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> en Windows.
Por eso siempre hay que indicarle el nombre del programa que se quiere ejecutar en el nuevo proceso.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Esto lo veremos con más detalle en el <a href="#_ejemplos_de_operaciones_con_procesos">Apartado 9.7.3</a>.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_terminación_de_procesos">9.7.2. Terminación de procesos</h4>
<div class="paragraph">
<p>Un proceso termina cuando se lo indica al sistema operativo con la llamada al sistema <strong>exit</strong>.
En ese momento puede devolver un valor de estado a su padre.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Esto ocurre en C y C&#43;&#43; incluso si el programa termina usando la sentencia <code>return</code> en <a href="https://en.cppreference.com/w/c/language/main_function">main()</a>.
Lo que ocurre es que es el código, introducido por el compilador, que llamó a <a href="https://en.cppreference.com/w/c/language/main_function">main()</a> es el que llama a <strong>exit</strong> usando el valor devuelto por <a href="https://en.cppreference.com/w/c/language/main_function">main()</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>El proceso padre puede esperar a que el hijo termine y recuperar ese valor a través de la llamada al sistema <strong>wait</strong>.
Cuando un proceso termina, todos los recursos son liberados, incluyendo: la memoria física y virtual, archivos y dispositivos abiertos, búferes de E/S, etc.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Tabla 2. Funciones de la API para salir, esperar y terminar procesos.</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">POSIX API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Windows API</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Salir</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://www.man7.org/linux/man-pages/man3/exit.3.html">exit()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-exitprocess">ExitProcess()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Esperar (un hijo concreto)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/waitpid.2.html">waitpid()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/synchapi/nf-synchapi-waitforsingleobject">WaitForSingleObject()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Esperar (múltiples hijos)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/wait.2.html">wait()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/synchapi/nf-synchapi-waitformultipleobjects">WaitForMultipleObject()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Terminar otro proceso</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/kill.2.html">kill()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-terminateprocess">TerminateProcess()</a></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>En todo caso un proceso puede provocar la terminación de otro proceso a través de una llamada al sistema.
Por ejemplo, en sistemas POSIX se usa un mecanismo llamado <strong>señales</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">kill</span><span class="p">(</span><span class="n">pid</span><span class="p">,</span> <span class="n">SIGTERM</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>mientras que en Windows API:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">TerminateProcess</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Habitualmente el proceso que invoca estas funciones es el proceso padre, ya que puede que sea el único con permisos para hacerlo.</p>
</div>
<div class="paragraph">
<p>Los motivos para terminar un procesos hijo pueden ser:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>El hijo ha excedido el uso de algunos de los recursos reservados</strong>.
Obviamente esto tiene sentido cuando los hijos utilizan un subconjunto de los recursos asignados al padre.</p>
</li>
<li>
<p><strong>La tarea asignada al hijo ya no es necesaria</strong>.
Por ejemplo, se creó para comprimir un archivo pero el usuario ha pedido cancelar la operación.</p>
</li>
<li>
<p><strong>El padre termina y el sistema operativo está diseñado para no permitir que el hijo pueda seguir ejecutándose si no tiene un padre</strong>.
En esos sistemas, la terminación de un proceso provoca que el sistema operativo inicie lo que se denomina una <strong>terminación en cascada</strong>, en la que termina todos los procesos que cuelgan de dicho proceso.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En sistemas UNIX y estilo UNIX, si un proceso muere a sus hijos no terminan sino que se les reasigna como padre el proceso <strong>init</strong>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_ejemplos_de_operaciones_con_procesos">9.7.3. Ejemplos de operaciones con procesos</h4>
<div class="paragraph">
<p>En C estándar la función <a href="https://en.cppreference.com/w/c/program/system">system()</a> de la librería estándar permite ejecutar otro proceso, con sus argumentos, esperar a que termine y obtener el valor de estado con el que finalizó el proceso.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">int</span> <span class="n">status</span> <span class="o">=</span> <span class="n">system</span><span class="p">(</span><span class="s">"holamundo -v foo.txt"</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Esta función es portable.
Está disponible en cualquier sistema donde haya un compilador de C estándar, pero sus funcionalidades son bastante limitadas.
Por ejemplo, no permite que el programa padre continúe su ejecución mientras se ejecuta el hijo, aunque el sistema sea multitarea y ese sea el comportamiento por defecto.
Tampoco facilita el control de los recursos que son heredados por el proceso hijo o hacer redirecciones de los dispositivos de E/S estándar.</p>
</div>
<div class="paragraph">
<p>Como hemos comentado anteriormente, para acceder a todas las funcionalidades ofrecidas por los sistemas operativos, muchas veces es necesario utilizar directamente la librería del sistema.</p>
</div>
<div class="sect4">
<h5 id="_windows_api_2">Windows API</h5>
<div class="paragraph">
<p>En Windows la librería del sistema ofrece la función <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a>.
A diferencia de <a href="https://en.cppreference.com/w/c/program/system">system()</a>, recibe muchísimos argumentos, ya que permite configurar bastantes aspectos de la creación de un nuevo proceso.</p>
</div>
<div class="paragraph">
<p>En el <a href="#ejemplo_createprocess">Ejemplo 2</a> se puede ver como se usa <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> para ejecutar un programa y esperar a que termine, de forma similar a como lo hace <a href="https://en.cppreference.com/w/c/program/system">system()</a>.</p>
</div>
<div id="ejemplo_createprocess" class="exampleblock">
<div class="title">Ejemplo 2. Crear un proceso usando Windows API</div>
<div class="content">
<div class="paragraph">
<p>El código fuente completo de este ejemplo está disponible en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap09/createprocess.c">createprocess.c</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">STARTUPINFO</span> <span class="n">si</span> <span class="o">=</span> <span class="p">{</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">STARTUPINFO</span><span class="p">)</span> <span class="p">};</span> <i class="conum" data-value="1"></i><b>(1)</b>
<span class="n">PROCESS_INFORMATION</span> <span class="n">pi</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span> <i class="conum" data-value="2"></i><b>(2)</b>

<span class="c1">// Crear procesos hijo y comprobar si no se creó con éxito.</span>
<span class="k">if</span><span class="p">(</span> <span class="o">!</span> <span class="n">CreateProcess</span><span class="p">(</span> <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="nb">NULL</span><span class="p">,</span> <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="s">"C:</span><span class="se">\\</span><span class="s">Windows</span><span class="se">\\</span><span class="s">System32</span><span class="se">\\</span><span class="s">charmap.exe"</span><span class="p">,</span>  <i class="conum" data-value="4"></i><b>(4)</b> <i class="conum" data-value="5"></i><b>(5)</b>
    <span class="nb">NULL</span><span class="p">,</span>
    <span class="nb">NULL</span><span class="p">,</span>
    <span class="n">FALSE</span><span class="p">,</span> <i class="conum" data-value="6"></i><b>(6)</b>
    <span class="mi">0</span><span class="p">,</span>
    <span class="nb">NULL</span><span class="p">,</span>  <i class="conum" data-value="7"></i><b>(7)</b>
    <span class="nb">NULL</span><span class="p">,</span>  <i class="conum" data-value="8"></i><b>(8)</b>
    <span class="o">&amp;</span><span class="n">si</span><span class="p">,</span>
    <span class="o">&amp;</span><span class="n">pi</span> <span class="p">))</span>
<span class="p">{</span>
    <span class="n">fprintf</span><span class="p">(</span> <span class="n">stderr</span><span class="p">,</span> <span class="s">"Error (%d) al crear el proceso.</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">GetLastError</span><span class="p">()</span> <span class="p">);</span> <i class="conum" data-value="9"></i><b>(9)</b>
    <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] El PID del nuevo proceso hijo es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">pi</span><span class="p">.</span><span class="n">dwProcessId</span> <span class="p">);</span>

<span class="c1">// Esperar hasta que el hijo termine.</span>
<span class="n">WaitForSingleObject</span><span class="p">(</span> <span class="n">pi</span><span class="p">.</span><span class="n">hProcess</span><span class="p">,</span> <span class="n">INFINITE</span> <span class="p">);</span> <i class="conum" data-value="10"></i><b>(10)</b>

<span class="n">DWORD</span> <span class="n">dwExitCode</span><span class="p">;</span>
<span class="n">GetExitCodeProcess</span><span class="p">(</span> <span class="n">pi</span><span class="p">.</span><span class="n">hProcess</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">dwExitCode</span> <span class="p">);</span> <i class="conum" data-value="11"></i><b>(11)</b>
<span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] El valor de salida del proceso hijo es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">dwExitCode</span> <span class="p">);</span>

<span class="c1">// Cerrar los manejadores del proceso y del hilo principal del proceso.</span>
<span class="n">CloseHandle</span><span class="p">(</span> <span class="n">pi</span><span class="p">.</span><span class="n">hProcess</span> <span class="p">);</span> <i class="conum" data-value="12"></i><b>(12)</b>
<span class="n">CloseHandle</span><span class="p">(</span> <span class="n">pi</span><span class="p">.</span><span class="n">hThread</span> <span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/ns-processthreadsapi-startupinfoa">STARTUPINFO</a> sirve para pasar a <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> parámetros adicionales sobre el inicio de la aplicación, como configurar la redirección de la E/S estándar o características de la primera ventana creada por la aplicación —en aplicaciones con interfaz gráfica—.
Si no se va a usar, debe inicializarse a 0, excepto el primer campo que debe contener el tamaño de la estructura.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/ns-processthreadsapi-process_information">PROCESS_INFORMATION</a> sirve para devuelve el manejador y el <strong>identificador de proceso</strong> del nuevo proceso.
Es común inicializar la estructura a 0.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> devuelve <code>TRUE</code> o <code>FALSE</code>, en función de si ha tenido éxito o no, respectivamente.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>El primer argumento —<code>lpApplicationName</code>— se usa para pasar la ruta del ejecutable, mientras que los argumentos de línea de comando generalmente se pasan por el segundo —<code>lpCommandLine</code>—.
Si en <code>lpApplicationName</code> se indica NULL, se puede pasar todo junto por <code>lpCommandLine</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>En <code>lpCommandLine</code> indicamos la ruta al ejecutable y los argumentos de la línea de comandos, si hicieran falta.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Con <code>bInheritHandles</code> a <code>FALSE</code> señalamos que no queremos que el proceso hijo herede ningún manejador abierto del proceso padre.
Estos manejadores son recursos a los que el padre tiene acceso y, si fuera necesario, el hijo también podría tenerlo.
Los manejadores pueden representar, por ejemplo, archivos abiertos, tuberías, <em>sockets</em> u otros mecanismos de comunicación, procesos o archivos mapeados en memoria, entre muchos otros tipos de recursos.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Con <code>NULL</code> en <code>lpEnvironment</code> indicamos que el hijo herede el conjunto de variables de entorno directamente del padre.
La otra opción es indicar un nuevo conjunto de variables de entorno.</td>
</tr>
<tr>
<td><i class="conum" data-value="8"></i><b>8</b></td>
<td><code>lpCurrentDirectory</code> sirve para indicar el directorio del trabajo del proceso hijo.
Es decir, el directorio respecto al que se resolverán las rutas de archivo relativas.
Con <code>NULL</code> indicamos que utilice las misma ruta que el proceso padre.</td>
</tr>
<tr>
<td><i class="conum" data-value="9"></i><b>9</b></td>
<td>Si <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> falla, devuelve <code>FALSE</code>.
Llamando a <a href="https://docs.microsoft.com/en-us/windows/win32/api/errhandlingapi/nf-errhandlingapi-getlasterror">GetLastError()</a> obtiene el código que identifica el motivo del error de la última función utilizada de Windows API.</td>
</tr>
<tr>
<td><i class="conum" data-value="10"></i><b>10</b></td>
<td>Usando <a href="https://docs.microsoft.com/en-us/windows/win32/api/synchapi/nf-synchapi-waitforsingleobject">WaitForSingleObject()</a> hacemos que el proceso padre se quede en estado <strong>esperando</strong> —sin que pueda seguir ejecutándose— hasta que el proceso hijo termine.</td>
</tr>
<tr>
<td><i class="conum" data-value="11"></i><b>11</b></td>
<td>Cuando el proceso a terminado, el padre puede conocer su valor de salida.
Es decir, el valor usado para terminar en la sentencia <code>return</code> de <a href="https://en.cppreference.com/w/c/language/main_function">main()</a> o al llamar a  <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-exitprocess">ExitProcess()</a> en el programa del proceso hijo.
Como convención, el hijo indica con un 0 que terminó con éxito, mientras que con un valor distinto indica que tuvo algún tipo de problema.</td>
</tr>
<tr>
<td><i class="conum" data-value="12"></i><b>12</b></td>
<td>Cuando ya no hace falta obtener información del procesos hijo o manipularlo, es necesario cerrar los manejadores devueltos por <a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a>.
Así el sistema operativo sabe que las estructuras de datos relacionadas con el proceso hijo ya no son necesarias, por lo que pueden liberarse.</td>
</tr>
</table>
</div>
</div>
</div>
<div class="paragraph">
<p><a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa">CreateProcess()</a> siempre necesita la ruta a un ejecutable —sea en el primer o en el segundo argumento de la función— porque se utiliza para crear un proceso completamente limpio y ejecutar en él un nuevo programa.</p>
</div>
</div>
<div class="sect4">
<h5 id="procesos_posix_api">POSIX API</h5>
<div class="paragraph">
<p>Por el contrario, en los sistemas POSIX se utiliza una estrategia muy diferente.
Los nuevos procesos se crean con la llamada <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>, que se encargar de crearlo como una copia del proceso padre.</p>
</div>
<div class="exampleblock">
<div class="title">Ejemplo 3. Crear un proceso en sistemas POSIX</div>
<div class="content">
<div class="paragraph">
<p>El código fuente completo de este ejemplo está disponible en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap09/fork.c">fork.c</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">pid_t</span> <span class="n">pid</span> <span class="o">=</span> <span class="n">getpid</span><span class="p">();</span> <i class="conum" data-value="7"></i><b>(7)</b>

<span class="c1">// Crear un proceso hijo</span>
<span class="n">pid_t</span> <span class="n">child</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span> <i class="conum" data-value="1"></i><b>(1)</b>

<span class="k">if</span> <span class="p">(</span><span class="n">child</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <i class="conum" data-value="2"></i><b>(2)</b>
<span class="p">{</span>
    <span class="c1">// Aquí solo entra el proceso hijo</span>
    <span class="n">puts</span><span class="p">(</span> <span class="s">"[HIJO] ¡Soy el proceso hijo!"</span> <span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[HIJO] El valor de mi variable 'child' es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">child</span> <span class="p">);</span> <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[HIJO] Este es mi PID: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">getpid</span><span class="p">()</span> <span class="p">);</span> <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[HIJO] El valor de mi variable 'pid' es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">pid</span> <span class="p">);</span> <i class="conum" data-value="7"></i><b>(7)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[HIJO] El PID de mi padre es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">getppid</span><span class="p">()</span> <span class="p">);</span> <i class="conum" data-value="7"></i><b>(7)</b>

    <span class="n">puts</span><span class="p">(</span> <span class="s">"[HIJO] Durmiendo 10 segundos..."</span> <span class="p">);</span>
    <span class="n">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>

    <span class="kt">int</span> <span class="n">status</span> <span class="o">=</span> <span class="mi">42</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[HIJO] Salgo con %d ¡Adios!</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">status</span> <span class="p">);</span>
    <span class="k">return</span> <span class="n">status</span><span class="p">;</span> <i class="conum" data-value="9"></i><b>(9)</b>
<span class="p">}</span>
<span class="k">else</span> <span class="nf">if</span> <span class="p">(</span><span class="n">child</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>  <i class="conum" data-value="3"></i><b>(3)</b> <i class="conum" data-value="4"></i><b>(4)</b>
<span class="p">{</span>
    <span class="c1">// Aquí solo entra el proceso padre</span>
    <span class="n">puts</span><span class="p">(</span> <span class="s">"[PADRE] ¡Soy el proceso padre!"</span> <span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] El valor de mi variable 'child' es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">child</span> <span class="p">);</span>  <i class="conum" data-value="3"></i><b>(3)</b> <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] Este es mi PID: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">getpid</span><span class="p">()</span> <span class="p">);</span> <i class="conum" data-value="7"></i><b>(7)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] El valor de mi variable 'pid' es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">pid</span> <span class="p">);</span> <i class="conum" data-value="7"></i><b>(7)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] El PID de mi padre es: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">getppid</span><span class="p">()</span> <span class="p">);</span>

    <span class="n">puts</span><span class="p">(</span> <span class="s">"[PADRE] Voy a esperar a que mi hijo termine..."</span> <span class="p">);</span>

    <span class="kt">int</span> <span class="n">status</span><span class="p">;</span>
    <span class="n">wait</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">status</span> <span class="p">);</span>  <i class="conum" data-value="8"></i><b>(8)</b> <i class="conum" data-value="9"></i><b>(9)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] El valor de salida de mi hijo fue: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">WEXITSTATUS</span><span class="p">(</span><span class="n">status</span><span class="p">)</span> <span class="p">);</span> <i class="conum" data-value="9"></i><b>(9)</b>

    <span class="n">puts</span><span class="p">(</span> <span class="s">"[PADRE] ¡Adios!"</span> <span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">else</span> <span class="p">{</span> <i class="conum" data-value="5"></i><b>(5)</b>
    <span class="c1">// Aquí solo entra el padre si no pudo crear el hijo</span>
    <span class="n">fprintf</span><span class="p">(</span> <span class="n">stderr</span><span class="p">,</span> <span class="s">"Error (%d) al crear el procesos: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">errno</span><span class="p">,</span> <span class="n">strerror</span><span class="p">(</span><span class="n">errno</span><span class="p">)</span> <span class="p">);</span> <i class="conum" data-value="6"></i><b>(6)</b>
    <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>El proceso llama a <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> pero al retornar de la llamada vuelven dos procesos: el proceso padre, que es el que llamó originalmente a <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>, y el proceso hijo.
Como el proceso hijo es una copia del padre, tiene el mismo código, las mismas variables y los mismos recursos que tenía el padre en el momento de llamar a <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>.
La única diferencia es el valor devuelto por <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>, que guardamos en <code>child</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Los dos procesos ejecutan el mismo programa, así que ambos llegan a la línea detrás del <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>.
Como queremos que cada proceso haga cosas diferentes, necesitamos que cada uno vaya a ramas distintas del código.
Eso se hace comprobando el valor de <code>child</code>, porque si vale 0 es que el proceso que actualmente ejecuta el programa es el hijo.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Si, por el contrario, el valor de <code>child</code> es mayor de 0, el proceso que ejecuta el programa es el padre y el valor de <code>child</code> es el PID del proceso hijo creado.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Así que el valor de <code>child</code> en el padre coincide con el devuelto por <a href="https://man7.org/linux/man-pages/man2/getpid.2.html">getpid()</a> en el hijo.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Finalmente, si el valor devuelto por <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> es negativo, es que ocurrió un error y el proceso hijo no llegó a crearse.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>En los sistemas POSIX es común que las llamadas al sistema devuelvan un valor negativo para indicar un error.
El motivo del error se puede conocer a través de la variable global <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a>, que siempre guarda el código de identificación del error en la última función invocada de la API POSIX.
La función <a href="https://man7.org/linux/man-pages/man3/strerror.3.html">strerror()</a> permite obtener un texto descriptivo de cualquier valor de <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a>, lo que siempre resulta útil para crear mensajes de error que ayuden a determinar dónde estuvo el problema.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>A modo de ejemplo hemos guardado el PID del proceso en la variable <code>pid</code>, antes de la llamada a <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>.
Como el proceso hijo es una copia del proceso padre, la variable existe en ambos pero en el proceso hijo su valor coincide con lo devuelto por <a href="https://man7.org/linux/man-pages/man2/getppid.2.html">getppid()</a> mientras que en el proceso padre con lo devuelto por <a href="https://man7.org/linux/man-pages/man2/getpid.2.html">getpid()</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="8"></i><b>8</b></td>
<td><a href="https://man7.org/linux/man-pages/man2/wait.2.html">wait()</a> hace que el proceso padre interrumpa su ejecución hasta que algún hijo termine y devuelve el estado de salida en <code>status</code>.
<div class="paragraph">
<p>Debemos asegurarnos de llamar a <a href="https://man7.org/linux/man-pages/man2/wait.2.html">wait()</a> o <a href="https://man7.org/linux/man-pages/man2/waitpid.2.html">waitpid()</a> una vez por cada proceso hijo, en algún momento, porque así es como el sistema sabe que el padre ya no tiene más interés en el proceso y puede liberar su PCB, dónde se guarda el estado de salida.
No hacerlo genera <strong>procesos zombi</strong>(proceso, zombi o <em>defunct</em>.</p>
</div></td>
</tr>
<tr>
<td><i class="conum" data-value="9"></i><b>9</b></td>
<td>El valor de salida de proceso hijo lo obtiene el proceso a través del estado de salida devuelto por <a href="https://man7.org/linux/man-pages/man2/wait.2.html">wait()</a>.
Pero ese estado contienen más información sobre la causa por la que el proceso terminó.
Para recuperar el valor de salida se usa la macro <code>WEXITSTATUS</code> sobre el estado de salida.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Lo siguiente es un posible resultado de ejecutar el programa anterior en una terminal de Linux,
numerado con las anotaciones realizadas al código:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./fork
[PADRE] ¡Soy el proceso padre!
[PADRE] El valor de mi variable 'child' es: 2360 <i class="conum" data-value="4"></i><b>(4)</b>
[PADRE] Este es mi PID: 2359 <i class="conum" data-value="7"></i><b>(7)</b>
[PADRE] El valor de mi variable 'pid' es: 2359 <i class="conum" data-value="7"></i><b>(7)</b>
[HIJO] ¡Soy el proceso hijo!
[PADRE] El PID de mi padre es: 1857
[PADRE] Voy a esperar a que mi hijo termine...
[HIJO] El valor de mi variable 'child' es: 0 <i class="conum" data-value="2"></i><b>(2)</b>
[HIJO] Este es mi PID: 2360
[HIJO] El valor de mi variable 'pid' es: 2359 <i class="conum" data-value="7"></i><b>(7)</b>
[HIJO] El PID de mi padre es: 2359 <i class="conum" data-value="7"></i><b>(7)</b>
[HIJO] Durmiendo 10 segundos...
[HIJO] Salgo con 42 ¡Adios! <i class="conum" data-value="9"></i><b>(9)</b>
[PADRE] El valor de salida de mi hijo fue: 42 <i class="conum" data-value="9"></i><b>(9)</b>
[PADRE] ¡Adios!</pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Aunque pueda parecer algo complejo, esta estrategia facilita la comunicación entre procesos.
Es muy sencillo lanzar otro proceso para hacer una tarea en paralelo que tendrá automáticamente una copia de los datos del proceso original.</p>
</div>
<div class="paragraph">
<p>Como se trata de una copia, las nuevas variables o la modificación de variables existentes que realice cualquiera de los procesos, no serán visibles para el otro.
Es decir, después del <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> ambos procesos son complemente independientes.
Pero como el proceso hijo hereda el acceso a todo tipo de recursos abiertos por el proceso padre, como: archivos, tuberías, <em>sockets</em> o regiones de memoria compartida, entre muchos otros recursos; es muy sencillo crear un canal de comunicación entre ambos procesos, si fuera necesario.</p>
</div>
<div class="paragraph">
<p>Sin embargo, <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> no proporciona una funcionalidad similar a la de <a href="https://en.cppreference.com/w/c/program/system">system()</a>.
No sirve para crear otro proceso con un programa diferente.
Para eso necesitamos <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a>, una familia de funciones cuyo propósito es cagar un nuevo programa en el proceso que la invoca.</p>
</div>
<div class="exampleblock">
<div class="title">Ejemplo 4. Ejecutar otro programa en un proceso nuevo en sistemas POSIX</div>
<div class="content">
<div class="paragraph">
<p>El código fuente completo de este ejemplo está disponible en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap09/fork-exec.c">fork-exec.c</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="c1">// Crear un proceso hijo</span>
<span class="n">pid_t</span> <span class="n">child</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span> <i class="conum" data-value="1"></i><b>(1)</b>

<span class="k">if</span> <span class="p">(</span><span class="n">child</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// Aquí solo entra el proceso hijo</span>
    <span class="n">puts</span><span class="p">(</span> <span class="s">"[HIJO] ¡Soy el proceso hijo!"</span> <span class="p">);</span>
    <span class="n">puts</span><span class="p">(</span> <span class="s">"[HIJO] Voy a ejecutar el comando 'ls'"</span> <span class="p">);</span>

    <span class="cm">/* Hacer otras cosas necesarias antes de ejecutar el programa... */</span> <i class="conum" data-value="4"></i><b>(4)</b>

    <span class="n">execl</span><span class="p">(</span> <span class="s">"/bin/ls"</span><span class="p">,</span> <span class="s">"ls"</span><span class="p">,</span> <span class="s">"-l"</span><span class="p">,</span> <span class="nb">NULL</span> <span class="p">);</span>   <i class="conum" data-value="2"></i><b>(2)</b> <i class="conum" data-value="3"></i><b>(3)</b> <i class="conum" data-value="5"></i><b>(5)</b>

    <span class="n">fprintf</span><span class="p">(</span> <span class="n">stderr</span><span class="p">,</span> <span class="s">"Error (%d) al ejecuta el programa: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">errno</span><span class="p">,</span> <span class="n">strerror</span><span class="p">(</span><span class="n">errno</span><span class="p">)</span> <span class="p">);</span> <i class="conum" data-value="6"></i><b>(6)</b>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span> <i class="conum" data-value="7"></i><b>(7)</b>
<span class="p">}</span>
<span class="k">else</span> <span class="nf">if</span> <span class="p">(</span><span class="n">child</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// Aquí solo entra el proceso padre</span>
    <span class="n">puts</span><span class="p">(</span> <span class="s">"[PADRE] ¡Soy el proceso padre!"</span> <span class="p">);</span>
    <span class="n">puts</span><span class="p">(</span> <span class="s">"[PADRE] Voy a esperar a que mi hijo termine..."</span> <span class="p">);</span>

    <span class="kt">int</span> <span class="n">status</span><span class="p">;</span>
    <span class="n">wait</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">status</span> <span class="p">);</span> <i class="conum" data-value="8"></i><b>(8)</b>
    <span class="n">printf</span><span class="p">(</span> <span class="s">"[PADRE] El valor de salida de mi hijo fue: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">WEXITSTATUS</span><span class="p">(</span><span class="n">status</span><span class="p">)</span> <span class="p">);</span>

    <span class="n">puts</span><span class="p">(</span> <span class="s">"[PADRE] ¡Adios!"</span> <span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">else</span> <span class="p">{</span>
    <span class="c1">// Aquí solo entra el padre si no pudo crear el hijo</span>
    <span class="n">fprintf</span><span class="p">(</span> <span class="n">stderr</span><span class="p">,</span> <span class="s">"Error (%d) al crear el procesos: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">errno</span><span class="p">,</span> <span class="n">strerror</span><span class="p">(</span><span class="n">errno</span><span class="p">)</span> <span class="p">);</span>
    <span class="k">return</span> <span class="mi">3</span><span class="p">;</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Primero creamos un proceso hijo, donde ejecutaremos el nuevo programa.
Si nos diera por llamar directamente a una función de la familia <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a>, nuestro programa sería sustituido y no tendríamos ningún control sobre lo que pase después.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>En la rama de código que se va a ejecutar en el hijo —gracias a la comprobación del valor devuelto por <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>— ejecutamos al función de la familia <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> que más nos interese.
Esta función no crea otro proceso, sino que carga el programa indicado en el proceso hijo, sustituyendo así a nuestro programa.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Todas las funciones de la familia <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> reciben como primer argumento la ruta al ejecutable, pero en <code>execlp()</code> en particular, a continuación se indican los argumentos de línea de comandos, tal y como queremos que los reciba el programa en el argumento <code>argv</code> de su <a href="https://en.cppreference.com/w/c/language/main_function">main()</a>.
Es decir, que el programa del comando <code>/bin/ls</code> recibirá <code>ls</code> y <code>-l</code> en <code>argv[0]</code> y <code>argv[1]</code>, respectivamente.
El <code>NULL</code> del final indica cuando no hay más argumentos de línea de comandos para pasar.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Antes de ejecutar la función <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> se pueden hacer cosas para configurar adecuadamente el proceso donde se ejecutará el nuevo programa.
Por ejemplo, cambiar las variables de entorno, redirigir la E/S estándar, cambiar el usuario al que pertenece el proceso —si originalmente se ejecuta con un usuario con ese privilegio— o cerrar archivos abiertos del procesos padre que ha heredado el proceso hijo y que, obviamente, no queremos que se queden abiertos para programas diferentes al nuestro.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Las funciones <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> no retornan si tienen éxito, porque el programa actual es sustituido por el indicado, que comenzará a ejecutarse de su <a href="https://en.cppreference.com/w/c/language/main_function">main()</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Si la función <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> retorna es porque falló y, como es común, el motivo del error está disponible en <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a>.
Un motivo de fallo muy típico es que el ejecutable indicado no exista.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Si la función <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> la ejecución del proceso hijo continuará, hasta salir de <a href="https://en.cppreference.com/w/c/language/main_function">main()</a> pero, generalmente, el proceso ya no es útil si no puede ejecutar el programa que le hemos indicado.
Por eso es importante asegurarnos de que el proceso hijo termina, si <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> falla.</td>
</tr>
<tr>
<td><i class="conum" data-value="8"></i><b>8</b></td>
<td>Mientras todo lo anterior ocurre en el proceso hijo, el proceso padre espera.
Cuando el proceso hijo termine, el padre podrá obtener su estado de salir para saber si tuvo éxito o no.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Lo siguiente es un posible resultado de ejecutar el programa anterior en una terminal de Linux,
numerado con las anotaciones realizadas al código:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./fork-exec
[PADRE] ¡Soy el proceso padre!
[PADRE] Voy a esperar a que mi hijo termine...
[HIJO] ¡Soy el proceso hijo!
[HIJO] Voy a ejecutar el comando 'ls'
total 628 <i class="conum" data-value="2"></i><b>(2)</b>
-rwxr--r-- 1 jesus jesus 72640 Sep 16 13:41 fifo-client
-rwxr--r-- 1 jesus jesus 72784 Sep 16 13:41 fifo-server
-rwxr--r-- 1 jesus jesus 20056 Sep 16 13:41 fork
-rwxr-xr-x 1 jesus jesus 19896 Sep 18 13:24 fork-exec
-rwxr--r-- 1 jesus jesus 80744 Sep 16 13:41 mmap
-rwxr--r-- 1 jesus jesus 45712 Sep 16 13:41 pipe
-rwxr--r-- 1 jesus jesus 87024 Sep 16 13:41 shared-memory
-rwxr--r-- 1 jesus jesus 77696 Sep 16 13:41 shared-memory-sync
-rwxr--r-- 1 jesus jesus 19608 Sep 16 13:41 softstack-c
-rwxr--r-- 1 jesus jesus 39328 Sep 16 13:41 softstack-cpp
-rwxr--r-- 1 jesus jesus  9920 Sep 16 13:41 syscall
-rwxr--r-- 1 jesus jesus 40712 Sep 16 13:41 threads-mutex-pthread
-rwxr--r-- 1 jesus jesus 39944 Sep 16 13:41 threads-pthread
[PADRE] El valor de salida de mi hijo fue: 0 <i class="conum" data-value="8"></i><b>(8)</b>
[PADRE] ¡Adios!</pre>
</div>
</div>
<div class="paragraph">
<p>Veamos qué ocurre si línea de la función <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> fuera:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">execl</span><span class="p">(</span> <span class="s">"/bin/ls"</span><span class="p">,</span> <span class="s">"ls"</span><span class="p">,</span> <span class="s">"-l"</span><span class="p">,</span> <span class="s">"/foo"</span><span class="p">,</span> <span class="nb">NULL</span> <span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>para intentar ver el contenido del directorio <code>/foo</code>, que no existe:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./fork-exec
[PADRE] ¡Soy el proceso padre!
[PADRE] Voy a esperar a que mi hijo termine...
[HIJO] ¡Soy el proceso hijo!
[HIJO] Voy a ejecutar el comando 'ls'
ls: cannot access '/foo': No such file or directory <i class="conum" data-value="1"></i><b>(1)</b>
[PADRE] El valor de salida de mi hijo fue: 2 <i class="conum" data-value="2"></i><b>(2)</b>
[PADRE] ¡Adios!</pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>El comando <code>ls</code> se ejecuta pero falla porque el directorio indicado no existe.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Por eso el programa, al terminar el proceso, no devuelve 0 sino 2 y es ese el valor que recibe el proceso padre.
Esto le permite saber al proceso padre que el comando <code>ls</code> no tuvo éxito.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Y finalmente cambiemos la línea de la función <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> así:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">execl</span><span class="p">(</span> <span class="s">"/noexists"</span><span class="p">,</span> <span class="s">"ls"</span><span class="p">,</span> <span class="s">"-l"</span><span class="p">,</span> <span class="nb">NULL</span> <span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>para que intente ejecutar un programa que no existe:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./fork-exec
[PADRE] ¡Soy el proceso padre!
[PADRE] Voy a esperar a que mi hijo termine...
[HIJO] ¡Soy el proceso hijo!
[HIJO] Voy a ejecutar el comando 'ls'
Error (2) al ejecuta el programa: No such file or directory <i class="conum" data-value="1"></i><b>(1)</b>
[PADRE] El valor de salida de mi hijo fue: 255 <i class="conum" data-value="2"></i><b>(2)</b>
[PADRE] ¡Adios!</pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> falla y se muestra el mensaje de error con el motivo.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>El proceso hijo termina con -1 y así llega ese valor al proceso padre.
Al utilizar un valor de salida diferente a los que usa el programa que intenta ejecutar, el padre distingue las terminaciones causadas por errores al llamar a <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> de los errores del propio programa.</td>
</tr>
</table>
</div>
</div>
</div>
<div class="paragraph">
<p>Todas las funciones <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> hacen lo mismo.
Primero liberan la memoria reservada en el proceso, después cargan el nuevo programa y finalmente inicia la ejecución del programa desde su punto de entrada.
La diferencia entre las distintas funciones está en los argumentos que aceptan.
Esa diferencia se puede conocer fijándonos en las letras al final del nombre de cada función:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Sin 'p'</strong>, como <code>execl()</code> o <code>execv()</code>, el primer argumento de la función es la ruta hasta el ejecutable del programa que se quiere ejecutar.</p>
</li>
<li>
<p><strong>Con 'p'</strong>, como <code>execlp()</code> o <code>execvp()</code>, la función busca el ejecutable como lo hace la <em>shell</em>.
Es decir, si el primer argumento no contiene ninguna '/' se toma como el nombre del ejecutable y se busca en los directorios listados en la variable de entorno <code>PATH</code>.
Si el primero argumento contienen alguna '/', se considera una ruta y se busca directamente el ejecutable en ella.</p>
</li>
<li>
<p><strong>Con 'l'</strong>, como <code>execl()</code> o <code>execlp()</code>, los argumentos de línea de comandos para pasar al programa se indican directamente como argumentos diferentes de la función —por ejemplo <code>execl("/bin/ls", "ls", "-l", "-a" NULL)</code>— lo que es ideal cuando el número de argumentos es fijo.
La lista de argumentos debe terminar en <code>NULL</code>.</p>
</li>
<li>
<p><strong>Con 'v'</strong>, como <code>execv()</code> o <code>execvp()</code>, los argumentos de la línea de comandos para pasar al programa se indican en un <em>array</em> de punteros a cadenas terminadas en '\0', lo que resulta muy práctico si el número de argumentos es desconocido en el momento de compilar.
El último elemento del <em>array</em> debe apuntar a <code>NULL</code>.
Por ejemplo:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span> <span class="s">"ls"</span><span class="p">,</span> <span class="s">"-l"</span><span class="p">,</span> <span class="s">"-a"</span><span class="p">,</span> <span class="nb">NULL</span> <span class="p">};</span>
<span class="n">execv</span><span class="p">(</span><span class="s">"/bin/ls"</span><span class="p">,</span> <span class="n">argv</span><span class="p">);</span></code></pre>
</div>
</div>
</li>
<li>
<p><strong>Con 'e'</strong>, como <code>execvpe()</code> o <code>execle()</code>, la función admite un argumento adicional para indicar el conjunto de variables de entorno con el que se ejecutará el nuevo programa.
Con las otras funciones <a href="https://man7.org/linux/man-pages/man3/exec.3.html">exec()</a> se conservan las variables de entorno actuales en el proceso que llama a la función.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_procesos_cooperativos">9.8. Procesos cooperativos</h3>
<div class="paragraph">
<p>Desde el punto de vista de la cooperación podemos clasificar los procesos en dos grupos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>procesos independientes</strong>, que no afectan o pueden ser afectados por otros procesos del sistema. Cualquier proceso que no comparte datos —temporales o persistentes— con otros procesos es independiente.</p>
</li>
<li>
<p>Los <strong>procesos cooperativos</strong>, que pueden afectar o ser afectados por otros procesos ejecutados en el sistema.
Los procesos que comparten datos, sea cual sea la forma en la que lo hacen, siempre son cooperativos.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_motivaciones_para_la_colaboración_entre_procesos">9.8.1. Motivaciones para la colaboración entre procesos</h4>
<div class="paragraph">
<p>Hay diversos motivos para proporcionar un entorno que permita la cooperación de los procesos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Compartición de información</strong>.
Dado que varios usuarios pueden estar interesados en los mismos bloques de información —por ejemplo, en un archivo compartido— el sistema operativo debe proporcionar un entorno que permita el acceso concurrente a este tipo de recursos.</p>
</li>
<li>
<p><strong>Velocidad de cómputo</strong>.
Para que una tarea se ejecute más rápido se puede partir en subtareas que se ejecuten en paralelo.
Es importante destacar que la mejora en la velocidad sólo es posible si el sistema tiene varios componentes de procesamiento como procesadores —si se quiere acelerar la ejecución en la CPU— o canales E/S —si se quieren acelerar las operaciones de E/S —.</p>
</li>
<li>
<p><strong>Modularidad</strong>.
Podemos querer crear nuestro software de forma modular, dividiendo las funciones del programa en procesos separados que se comunican entre sí.</p>
</li>
<li>
<p><strong>Conveniencia</strong>.
Incluso un usuario individual puede querer hacer varias tareas al mismo tiempo.
Por ejemplo, editar, imprimir y compilar al mismo tiempo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Las ejecución simultánea de procesos cooperativos requiere mecanismos tanto para comunicar unos con otros como para sincronizar sus acciones (véase el <a href="#_sincronización">Capítulo 13</a>).</p>
</div>
</div>
<div class="sect3">
<h4 id="_comunicación_entre_procesos">9.8.2. Comunicación entre procesos</h4>
<div class="paragraph">
<p>Para comunicar procesos cooperativos existen diversas aproximaciones, que en general se pueden encajar en alguna de las siguientes estrategias:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Memoria compartida</dt>
<dd>
<p>Método de comunicación en el que los procesos utilizan regiones compartidas de la memoria principal para compartir información.</p>
</dd>
<dt class="hdlist1">Paso de mensajes</dt>
<dd>
<p>Método en el que los procesos utilizan funciones del sistema operativo para enviarse mensajes entre ellos, compartiendo información y sincronizando acciones, sin necesidad de compartir memoria.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>En la <a href="#modelos_de_comunicación">Figura 29</a> se puede un esquema comparativo entre ambos modelos de comunicación.
Veremos cada uno en detalle en el <a href="#_memoria_compartida">Capítulo 11</a> y el <a href="#_comunicación_mediante_de_paso_de_mensajes">Capítulo 10</a>, respectivamente.</p>
</div>
<div id="modelos_de_comunicación" class="imageblock">
<div class="content">
<img src="C09-procesos/images/modelos_comunicación.svg" alt="modelos comunicación">
</div>
<div class="title">Figura 29. Modelos de comunicación.</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_comunicación_mediante_de_paso_de_mensajes">10. Comunicación mediante de paso de mensajes</h2>
<div class="sectionbody">
<div class="exampleblock right">
<div class="content">
<div class="paragraph">
<div class="title">Tiempo estimado de lectura</div>
<p>32 minutos</p>
</div>
</div>
</div>
<div class="paragraph">
<p>El <strong>paso de mensajes</strong> es un mecanismo que permite a los procesos compartir información y sincronizar sus acciones sin necesidad de compartir recursos —compartir memoria, archivos, etc.—</p>
</div>
<div class="paragraph">
<p>Esto lo hace especialmente útil en entornos distribuidos, dónde los procesos a comunicar residen en ordenadores diferentes conectados a una red, por lo que tiene muy difícil —o incluso imposible— compartir memoria u otros recursos para comunicarse.
En este caso, el sistema operativo es el encargado de codificar los mensajes y enviarlos a través de la red para hacerlos llegar a su destinatario.
La web —donde un navegador se conecta a un servidor web para obtener contenido— y el resto de servicios de Internet son ejemplos de sistemas de paso de mensajes.</p>
</div>
<div class="paragraph">
<p>El sistema de paso de mensajes debe ser proporcionado por el sistema operativo que, a diferencia de cuando se usa memoria compartida, se encarga de la sincronización —ya que no existen riesgos en el envío y recepción de mensajes al mismo tiempo— y de establecer el formato que deben tener los datos del mensaje.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En alguna fuentes se sigue haciendo referencia al término <strong>IPC</strong> (<em>Interprocess Communication</em>) —o <strong>comunicación entre procesos</strong>— para identificarlo exclusivamente con <strong>sistemas de paso de mensajes</strong>.
Sin embargo, la <strong>memoria compartida</strong> y otras técnicas también sirven para «comunicar procesos», por lo que es más adecuado usar el término <strong>IPC</strong> para englobar todas las técnicas conocidas de comunicación entre procesos.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Los sistemas de paso de mensaje de cualquier sistema operativo debe proporcionar al menos dos llamadas al sistema similares a:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>send( message )</strong> para mandar mensajes a otro proceso.</p>
</li>
<li>
<p><strong>receive( &amp;message )</strong> para recibir mensajes de otro proceso y copiarlo en <em>message</em>.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Vamos a hablar de funciones de un sistema de paso de mensajes hipotético.
Meros ejemplos para ilustrar la diferentes alternativas.
Esto no significa que en los sistemas operativos reales las funciones se llamen así y tengan esos mismos argumentos.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Para que estas llamadas puede enviar y recibir mensajes entre dos procesos es necesario que haya un <strong>enlace de comunicaciones</strong> entre ambos.
No trataremos aquí la implementación física del enlace —que por ejemplo puede ser mediante memoria compartida, un bus hardware o una red de ordenadores— sino de su implementación lógica, es decir, las características de la interfaz que usan las aplicaciones para comunicarse con sus correspondientes operaciones de envío y recepción.</p>
</div>
<div class="sect2">
<h3 id="_tamaño_del_mensaje">10.1. Tamaño del mensaje</h3>
<div class="paragraph">
<p>Los diseñadores del sistema operativo deben escoger entre implementar un sistema de paso de mensajes con mensajes de tamaño fijo o mensajes de tamaño variable:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Mensajes de tamaño fijo</strong>.
La implementación del sistema operativo es muy sencilla pero el uso de la interfaz por parte de las aplicaciones es mucho más compleja.</p>
<div class="paragraph">
<p>Por ejemplo, para comunicar procesos en un mismo ordenador cada enlace puede tener un búfer de tamaño fijo donde se copia el mensaje enviado y de donde se extrae el mensaje al recibirlo.
Esto es muy sencillo de implementar en el sistema operativo.
Sin embargo, si el desarrollador de la aplicación quiere enviar algo de mayor tamaño que el tamaño del mensaje, debe trocearlo en varios mensajes para enviarlo y reconstruirlo al recibirlo.</p>
</div>
</li>
<li>
<p><strong>Mensajes de tamaño variable</strong>.
La implementación del sistema operativo es más compleja, ya que ahora tiene que gestionar la memoria para almacenar mensajes de tamaño variable hasta que son recibidos.
Sin embargo, la programación de aplicaciones es más simple puesto que el programador puede mandar mensajes de cualquier tamaño sin ninguna preocupación</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_comunicación_orientada_a_flujos">10.1.1. Comunicación orientada a flujos</h4>
<div class="paragraph">
<p>En algunos sistemas con <strong>mensajes de tamaño variable</strong> no se preserva la separación entre mensajes al recibirlos.
Es decir, que los procesos leen un número arbitrario de bytes, donde puede haber parte de un mensaje o varios mensajes al mismo tiempo.
Por ejemplo, en esos sistemas el transmisor puede mandar tres mensajes de 16000, 3200 y 100 bytes, pero el receptor leer la secuencia de bytes en bloques de 512 bytes.</p>
</div>
<div class="paragraph">
<p>A esto se lo denomina <strong>comunicación orientada a flujos</strong> o <strong><em>(streams)</em></strong>
Si usamos este tipo de sistema pero es importante conservar la separación entre los mensajes recibido, será nuestra responsabilidad escoger un formato de mensaje adecuado que permita al receptor recuperar dónde comienza y termina un mensaje dentro de la secuencia de bytes.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_referenciación">10.2. Referenciación</h3>
<div class="paragraph">
<p>Los procesos que se quiera comunicar debe tener una forma de señalarse el uno al otro.
Para ello el diseñador del sistema puede elegir que el sistema de paso de mensajes se con comunicación directa o la indirecta.</p>
</div>
<div class="sect3">
<h4 id="_comunicación_directa">10.2.1. Comunicación directa</h4>
<div class="paragraph">
<p>En la <strong>comunicación directa</strong> cada proceso debe nombrar explícitamente al proceso destinatario o receptor de la información.
Por ejemplo, ahora las llamadas al sistema básicas podrían ser así:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>send( A, message )</strong> para mandar un mensaje al proceso identificado como «A».</p>
</li>
<li>
<p><strong>receive( A, &amp;message )</strong> para recibir un mensaje del proceso identificado como «A», copiándolo en «<em>message</em>».</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>De hecho el ejemplo anterior corresponde a un caso de <strong>comunicación directa</strong> con <strong>direccionamiento simétrico</strong> pero existe una variante de ese mismo esquema denominado <strong>direccionamiento asimétrico</strong> donde el receptor puede recibir mensajes de cualquier proceso, de forma que al volver de la llamada recibe el mensaje y la identidad del remitente.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>send( A, message )</strong> para mandar un mensaje al proceso identificado como «A»</p>
</li>
<li>
<p><strong>receive( &amp;pid, &amp;message )</strong> para recibir un mensaje de cualquier proceso, recibiendo en «<em>message</em>» la una copia del <em>message</em> y en «pid» la identidad del remitente.</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>En resumen:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>En el <strong>direccionamiento simétrico</strong> tanto el proceso que envía como el que reciben tienen que identificar al otro para comunicarse.</p>
</li>
<li>
<p>En el <strong>direccionamiento asimétrico</strong> sólo el proceso que envía identifica a que recibe, mientras que este último no tiene que nombrar al remitente.
Es el sistema operativo el que informa de quién es el remitente del mensaje que se ha recibido.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Un <strong>enlace de comunicaciones</strong> según este esquema tiene las siguientes características:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Un enlace se establece automáticamente entre cada par de procesos que quieren comunicarse.
Por tanto, los procesos sólo necesitan conocer a la identidad de los otros para comunicarse.</p>
</li>
<li>
<p>Cada enlace se asocia exactamente a dos procesos.</p>
</li>
<li>
<p>Entre cada par de procesos sólo hay un enlace.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>La principal desventaja de este tipo de comunicación es que si cambia el identificador de un proceso hay que actualizar todas las referencias en todos los procesos que se comunican con el.
En general cualquier técnica que requiera que los identificadores de los procesos sean establecidos explícitamente en el código de los programas no es deseable, puesto que en muchos sistemas los identificadores de los procesos cambian de una ejecución a otra.
Por lo tanto, lo mejor sería disponer de una solución con un nivel adicional de indirección que evite que los procesos usen sus identificadores para comunicarse.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Colas de mensajes en Windows API</div>
<div class="paragraph">
<p>En Windows API un hilo puede enviar mensajes a otro hilo usando <a href="https://docs.microsoft.com/en-us/windows/win32/api/winuser/nf-winuser-postthreadmessagea">PostThreadMessage()</a>.
Como aun no hemos visto el concepto de hilo, podemos asumir que es equivalente al de proceso.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">BOOL</span> <span class="nf">PostThreadMessage</span><span class="p">(</span>
    <span class="n">DWORD</span>  <span class="n">idThread</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">UINT</span>   <span class="n">Msg</span><span class="p">,</span> <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="n">WPARAM</span> <span class="n">wParam</span><span class="p">,</span> <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="n">LPARAM</span> <span class="n">lParam</span> <i class="conum" data-value="3"></i><b>(3)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Identificador del hilo.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Un número entero que identifica el mensaje</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Parámetros del mensaje de tipo entero.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Como se puede observar, en las colas de mensajes de Windows API el <strong>tamaño del mensaje es fijo</strong> y con un estructura muy bien definida: un identificador del mensaje y dos enteros que sirven de parámetros opcionales del mensaje.</p>
</div>
<div class="paragraph">
<p>Para recibir el mensaje el proceso llama a <a href="https://docs.microsoft.com/en-us/windows/win32/api/winuser/nf-winuser-getmessagea">GetMessage()</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">BOOL</span> <span class="nf">GetMessage</span><span class="p">(</span>
    <span class="n">LPMSG</span> <span class="n">lpMsg</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">HWND</span>  <span class="n">hWnd</span><span class="p">,</span>
    <span class="n">UINT</span>  <span class="n">wMsgFilterMin</span><span class="p">,</span>
    <span class="n">UINT</span>  <span class="n">wMsgFilterMax</span>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Puntero a una estructura <a href="https://docs.microsoft.com/en-us/windows/win32/api/winuser/ns-winuser-msg">MSG</a> que a la vuelta contendrá el identificador y los parámetros del mensaje recibido, entre otra información.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Como se puede observar, no se indica de qué hilo o proceso se quiere recibir el mensaje, por lo que se trata de un caso de <strong>comunicación directa asimétrica</strong>.
De hecho, si se quiere conocer la identidad del remitente, este tendría que poner su identificador en alguno de los parámetros del mensaje.</p>
</div>
<div class="paragraph">
<p>El sistema de colas de mensajes de Windows API es una pieza fundamental del entorno gráfico de Microsoft Windows.
Sin embargo, podemos definir nuestros propios mensaje privados para comunicar unos hilos o procesos con otros.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_comunicación_indirecta">10.2.2. Comunicación indirecta</h4>
<div class="paragraph">
<p>En la <strong>comunicación indirecta</strong> los mensajes son enviados a <strong>buzones</strong>, <strong><em>maillox</em></strong> o <strong>puertos</strong> que son objetos dónde los procesos pueden dejar y recoger mensajes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>send( P, message )</strong> para mandar un mensaje al puerto «P»</p>
</li>
<li>
<p><strong>receive( P, &amp;message )</strong> para recibir un mensaje del puerto «P».</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Un <strong>enlace de comunicaciones</strong> según este esquema tiene las siguientes características:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Un enlace se establece entre un par de procesos solo si ambos comparten un mismo puerto, dado que cada enlace corresponde con un puerto.</p>
</li>
<li>
<p>Un enlace puede estar asociado a más de dos procesos, puesto que múltiples procesos pueden compartir el mismo puerto</p>
</li>
<li>
<p>Entre cada par de procesos en comunicación pueden haber varios enlaces, cada uno de los
cuales corresponde a un puerto.</p>
</li>
</ul>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Colas de mensajes en sistemas POSIX</div>
<div class="paragraph">
<p>El estándar POSIX también define un <a href="https://www.man7.org/linux/man-pages/man7/mq_overview.7.html">sistema de colas de mensajes</a> pero es bastante diferente a la solución en Windows API.</p>
</div>
<div class="paragraph">
<p>Para usarlo, lo primero es abrir o crear —si aun no existe— la cola de mensajes llamando a <a href="https://man7.org/linux/man-pages/man3/mq_open.3.html">mq_open()</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">mqd_t</span> <span class="n">mqueue</span> <span class="o">=</span> <span class="n">mq_open</span><span class="p">(</span>
    <span class="s">"/foo-mqueue"</span><span class="p">,</span>      <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">O_CREAT</span> <span class="o">|</span> <span class="n">O_RDWR</span><span class="p">,</span>   <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="mo">0644</span><span class="p">,</span>               <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="nb">NULL</span>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Nombre que identifica la cola de mensajes.
Como con los archivos, para que varios procesos puedan acceder a la misma cola, deben indicar el mismo nombre.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Valores que indican diferentes opciones a la hora de abrir la cola de mensajes.
Por ejemplo, usando <code>O_RDWR</code> se indica abrir para enviar o recibir y con <code>O_CREAT</code> se indica que la cola debe crearse si no existe previamente.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Indica los permisos de la cola de mensajes al crearla nueva, de forma similar a los permisos que se aplican a los archivos.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>El valor devuelto por <a href="https://man7.org/linux/man-pages/man3/mq_open.3.html">mq_open()</a> es el descriptor de la cola de mensajes.
Como otros descriptores, se hereda de padres a hijos al usar <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a>.</p>
</div>
<div class="paragraph">
<p>Este descriptor se utiliza como primer argumento en funciones posteriores para indicar sobre qué cola queremos realizar la correspondiente operación.
Por ejemplo, para enviar un mensaje se utiliza <a href="https://man7.org/linux/man-pages/man3/mq_send.3.html">mq_send()</a> así:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">int</span> <span class="nf">mq_send</span><span class="p">(</span>
    <span class="n">mqueue</span><span class="p">,</span>                 <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="k">sizeof</span><span class="p">(</span><span class="n">message</span><span class="p">),</span>        <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="mi">0</span>                       <i class="conum" data-value="4"></i><b>(4)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Descriptor de la cola a la que enviar el mensaje.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Puntero a la dirección de memoria donde está el mensaje.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Tamaño del mensaje en bytes.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Prioridad del mensaje.
Los mensaje con mayor prioridad se entregarán antes.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Mientras que para recibir un mensaje se utiliza <a href="https://man7.org/linux/man-pages/man3/mq_receive.3.html">mq_receive()</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">msg_prio</span><span class="p">;</span>

<span class="kt">int</span> <span class="nf">mq_receive</span><span class="p">(</span>
    <span class="n">mqueue</span><span class="p">,</span>                 <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="k">sizeof</span><span class="p">(</span><span class="n">message</span><span class="p">),</span>        <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="o">&amp;</span><span class="n">msg_prio</span>               <i class="conum" data-value="4"></i><b>(4)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Descriptor de la cola de la que recibir el mensaje.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Puntero a la dirección de memoria donde guardar el mensaje al recibirlo.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Tamaño máximo de espacio reservado en <code>message</code> para guardar el mensaje.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Puntero a variable entera dónde devolver la prioridad del mensaje recibido.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Como los mensajes no se dirigen directamente a los procesos sino a estas entidades llamadas colas de mensajes, se trata de un caso de <strong>comunicación indirecta</strong>.
Además, el <strong>tamaño de los mensajes es variable</strong>, aunque limitado por defecto a 8 KiB si no se configura de otra manera.</p>
</div>
<div class="paragraph">
<p>Si varios procesos intentan recibir de una misma cola de mensajes al mismo tiempo, queda en manos del sistema operativo decidir cuál recibirá el siguiente mensaje que llegue.
Por lo general es el primero en ser escogido por el planificador de la CPU para seguir ejecutándose.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_recepción_concurrente">Recepción concurrente</h5>
<div class="paragraph">
<p>Este tipo de comunicación da lugar a algunas situaciones que deben ser resueltas durante el diseño.</p>
</div>
<div class="paragraph">
<p>¿Qué ocurre, por ejemplo, si los procesos A, B y C comparten el puerto P; A manda un mensaje y B y C invocan <code>receive()</code> en el puerto P al mismo tiempo?.
La respuesta correcta dependerá de la elección de los los diseñadores del sistema:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>No permitir que cada enlace de comunicación —y por tanto cada puerto— esté asociado a más de dos procesos.</p>
</li>
<li>
<p>No permitir que más de un proceso puedan ejecutar <code>receive()</code> al mismo tiempo.
Por ejemplo, en algunos sistemas solo el proceso que crea el puerto tiene permisos para recibir de él.
Los sistemas que optan por esta solución suelen disponer de algún mecanismo para que un proceso pueda transferir el permiso de recibir a otros procesos.</p>
</li>
<li>
<p>Permitir que el sistema operativo escoja arbitrariamente quién recibe el mensaje si dos o más procesos ejecutan <code>receive()</code> al mismo tiempo.
La elección puede ser aleatoria, mediante algún algoritmo, por ejemplo, por turnos o el siguiente proceso en obtener la CPU, a criterio del planificador de la CPU.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_buffering_2">10.3. Buffering</h3>
<div class="paragraph">
<p></p>
</div>
<div class="paragraph">
<p>Los mensajes intercambiados por enlace de comunicación se almacenan en una cola temporal, a la espera de ser enviados o, tras recibirlos, a la espera de que los reclame el proceso.</p>
</div>
<div class="paragraph">
<p>Básicamente hay tres formas de implementar dicha cola:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Con <strong>capacidad cero</strong> o <strong>sin buffering</strong> la cola tiene una capacidad máxima de 0 mensajes, por lo que no puede haber ningún mensaje esperando en el enlace.
En este caso el proceso transmisor se bloquea en espera hasta que el receptor recibe el mensaje.</p>
</li>
<li>
<p>Con <strong>buffering automático</strong>, dónde existe dos opciones:</p>
<div class="ulist">
<ul>
<li>
<p>Con <strong>capacidad limitada</strong> la cola tiene una capacidad máxima de \$N\$ mensaje, por lo que si la cola se llena el proceso transmisor se bloquea a la espera de que haya espacio en la cola.
Obviamente, mientras la cola no se llene en transmisor puede seguir metiendo mensajes sin bloquearse.</p>
</li>
<li>
<p>Con <strong>capacidad ilimitada</strong> la cola es de longitud potencialmente infinita, lo que permite que el transmisor nunca espere.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Las colas de longitud infinita son imposibles, puesto que los recursos son limitados.
En realidad este término hace referencia a colas de longitud variable cuyo máximo viene determinado por la memoria principal disponible, que suele ser lo suficientemente grande como para que podamos considerar que las colas son infinitas.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Buffering en las colas de mensajes POSIX</div>
<div class="paragraph">
<p>Las colas de mensajes en sistemas POSIX tienen capacidad limitada.
Los límites se configuran al crear la cola, a través del último argumento de <a href="https://man7.org/linux/man-pages/man3/mq_open.3.html">mq_open()</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">struct</span> <span class="n">mq_attr</span> <span class="n">attr</span> <span class="o">=</span> <span class="p">{</span>  <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="p">.</span><span class="n">mq_maxmsg</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>      <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="p">.</span><span class="n">mq_msgsize</span> <span class="o">=</span> <span class="mi">2049</span>   <i class="conum" data-value="3"></i><b>(3)</b>
<span class="p">};</span>

<span class="n">mqd_t</span> <span class="n">mqueue</span> <span class="o">=</span> <span class="n">mq_open</span><span class="p">(</span>
    <span class="s">"/foo-queue"</span><span class="p">,</span>
    <span class="n">O_CREAT</span> <span class="o">|</span> <span class="n">O_RDWR</span><span class="p">,</span>
    <span class="mo">0644</span><span class="p">,</span>
    <span class="o">&amp;</span><span class="n">attr</span> <i class="conum" data-value="1"></i><b>(1)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Estructura con propiedades para la cola cuando ésta se crea nueva.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Una de las propiedades es el número máximo de mensajes en la cola al mismo tiempo.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Otra de las propiedades es el tamaño máximo de cada mensaje.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Estos limites tienen unos valores por defecto por si en el lugar de <code>attr</code> en <a href="https://man7.org/linux/man-pages/man3/mq_open.3.html">mq_open()</a> se indica <code>NULL</code>.
El estándar POSIX indica que esos valores por defecto dependen de cada sistema operativo, por lo que es necesario ir a la documentación para desarrolladores de cada sistema para conocer los detalles en cada caso concreto.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, en Linux los valores por defecto son 10 mensajes y 8 KiB por mensaje, siendo estos, además, los valores máximos que admiten esas propiedades.
Estos valores máximos y por defecto se pueden cambiar de forma global para todo el sistema, por si tuviéramos interés en valores más altos.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_operaciones_síncronas_y_asíncronas">10.4. Operaciones síncronas y asíncronas</h3>
<div class="paragraph">
<p>La comunicación entre dos procesos tiene lugar por medio de las llamadas <code>send()</code> y <code>receive()</code>; de tal forma que generalmente la primera se bloquea cuando la cola de transmisión se llena —en función del tipo de <em>buffering</em>— mientras que la segunda lo hace cuando la cola de recepción está vacía.</p>
</div>
<div class="paragraph">
<p>Sin embargo, en lugar de bloquearse, puede que aun proceso le interese ejecutar otras tareas en la CPU.
A fin de cuentas las comunicaciones son bastante lentas, por lo que en caso de bloquearse podría estar dejando de aprovechar bastante tiempo de CPU.
Incluso puede darse el caso que tengan conexión con otros procesos y que quiera aprovecha para intentar comunicarse con alguno de ellos.</p>
</div>
<div class="paragraph">
<p>Por eso existen diferentes opciones de diseño a la hora de implementar las llamadas anteriores en función de si se pueden bloquear o no.
Concretamente, el paso de mensajes puede ser <strong>síncrono</strong> —con bloqueo— o <strong>asíncrono</strong> —sin bloqueo—.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Cuando el envío es asíncrono</strong>, el proceso transmisor nunca se bloquea.
Si se llamada a <code>send()</code> cuando la cola de mensajes esté llena, lo más común es que retorne con un código de retorno que indique que el proceso debe volver a intentar el envío más tarde.</p>
</li>
<li>
<p><strong>Cuando el envío es síncrono</strong>, el proceso transmisor se bloquea cuando no queda espacio en la cola de mensajes y hasta que pueda depositar el mensaje en la misma.</p>
</li>
<li>
<p><strong>Cuando la recepción es asíncrona</strong>, el proceso receptor nunca se bloquea.
En caso de que la cola de mensajes esté vacía, el sistema operativo puede indicar al proceso que lo intente más tarde a través de un código de retorno o devolviendo un mensaje vacío.</p>
</li>
<li>
<p><strong>Cuando la recepción es con bloqueo</strong>, el receptor se bloquea cuando no hay mensajes en la cola y hasta que llegue alguno.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Algunos sistemas de paso de mensajes son claramente síncronos o asíncronos.
Mientras que otros permiten activar un modo u otro según las necesidades del aplicación.
E incluso los hay que soportan que transmisión y recepción sean síncronas o asíncronas de manera totalmente independiente.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Comunicaciones asíncronas con colas de mensajes POSIX</div>
<div class="paragraph">
<p>Por defecto las colas de mensajes son síncronas, tanto en envío como en recepción.
Es decir, si al enviar un mensaje la cola está llena, el proceso transmisor quedará bloqueado en estado <strong>esperando</strong> hasta que haya un hueco libre para depositar el nuevo mensaje.
Si al recibir un mensaje la cola está vacía, el proceso receptor quedará bloqueado hasta que otro proceso deposite un mensaje.</p>
</div>
<div class="paragraph">
<p>Sin embargo, si en el argumento <code>oflag</code> de <a href="https://man7.org/linux/man-pages/man3/mq_open.3.html">mq_open()</a> un proceso indica la opción <code>O_NONBLOCK</code> estas operaciones para ese proceso en esa cola serán asíncronas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">mqd_t</span> <span class="n">mqueue</span> <span class="o">=</span> <span class="n">mq_open</span><span class="p">(</span>
    <span class="s">"foo-mqueue"</span><span class="p">,</span>
    <span class="n">O_RDONLY</span> <span class="o">|</span> <span class="n">O_NONBLOCK</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="mo">0644</span><span class="p">,</span>
    <span class="o">&amp;</span><span class="n">attr</span>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Abrir la cola de mensajes para solo lectura —con <code>O_RDONLY</code>— y para comunicaciones asíncronas —con <code>O_NONBLOCK</code>—.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Eso quiere decir que las funciones <a href="https://man7.org/linux/man-pages/man3/mq_send.3.html">mq_send()</a> y <a href="https://man7.org/linux/man-pages/man3/mq_receive.3.html">mq_receive()</a>, en lugar de bloquear el proceso en estado de esperando, devolverán -1 y el valor de <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a> será <code>EAGAIN</code>.
Así el proceso puede aprovechar el tiempo de CPU del que dispone para realizar otras tareas mientras tanto y volver a intentarlo más tarde.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">int</span> <span class="n">return_code</span> <span class="o">=</span> <span class="n">mq_receive</span><span class="p">(</span><span class="n">mqueue</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">message</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">message</span><span class="p">),</span> <span class="o">&amp;</span><span class="n">msg_prio</span><span class="p">);</span>
<span class="k">if</span> <span class="p">(</span> <span class="n">return_code</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">)</span> <i class="conum" data-value="1"></i><b>(1)</b>
<span class="p">{</span>
    <span class="c1">// Aquí va código para usar el mensaje recibido...</span>
<span class="p">}</span>
<span class="k">else</span> <span class="nf">if</span><span class="p">(</span> <span class="n">return_code</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">errno</span> <span class="o">!=</span> <span class="n">EAGAIN</span><span class="p">)</span> <i class="conum" data-value="2"></i><b>(2)</b>
<span class="p">{</span>
    <span class="c1">// Aquí va código para manejar el error de mq_receive()...</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Si todo va bien, <a href="https://man7.org/linux/man-pages/man3/mq_receive.3.html">mq_receive()</a> devuelve el tamaño en bytes del mensaje.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Si devuelve -1, es que ha ocurrido un error. Pero solo será un error eal si el código de error en <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a> no es <code>EAGAIN</code>.
Si es <code>EAGAIN</code>, se pueden ejecutar otras partes del programa y volver a intentar la recepción más adelante.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Si un proceso debe comunicarse mediante varias colas de mensajes, la comunicación asíncrona también sirve para intentar recibir y enviar de varias colas sin bloquearse en ninguna.
Para este caso algunos sistemas ofrece una alternativa más sencilla y eficiente, que veremos en el <a href="#_colas_de_mensajes_posix">Apartado 10.5.1</a>.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ejemplos_de_sistemas_de_paso_de_mensajes">10.5. Ejemplos de sistemas de paso de mensajes</h3>
<div class="sect3">
<h4 id="_colas_de_mensajes_posix">10.5.1. Colas de mensajes POSIX</h4>
<div class="paragraph">
<p>Como hemos comentado a lo largo de capítulo, las colas de mensajes POSIX son un caso de <strong>comunicación indirecta</strong>, con <strong>tamaño de mensaje variable</strong>, <em>buffering</em> con <strong>capacidad limitad</strong> y que soporta operaciones <strong>asíncronas</strong>.</p>
</div>
<div class="paragraph">
<p>Las colas de mensajes son útiles para enviar mensajes de pequeño tamaño entre procesos que se ejecutan en el mismos sistema.
Además tienen la posibilidad de asociar a cada mensaje una prioridad, de tal forma que se reciban primero los mensajes de prioridad más alta.
Su uso es relativamente común en sistemas de tiempo real, aunque lo más frecuente en los sistemas de propósito general es usar <em>sockets</em>.</p>
</div>
<div class="paragraph">
<p>En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/message_queue.hpp">message_queue.hpp</a> se puede ver un ejemplo de una clase desarrollada en C++ para utilizar colas de mensajes POSIX.
En los distintos métodos se puede ver como se utilizan las funciones de la librería del sistema para crear la cola y enviar y recibir mensajes.</p>
</div>
<div class="paragraph">
<p>En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/mqueue-client.cpp">mqueue-server.cpp</a> y <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/mqueue-client.cpp">mqueue-client.cpp</a> se puede ver un ejemplo de cómo se utiliza la clase en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/message_queue.hpp">message_queue.hpp</a>.
El primero es un programa que muestra la hora del sistema periódicamente.
El segundo se puede comunicar con el primero a través de una cola de mensajes para controlarlo.
En ejemplo es muy sencillo, así que, por el momento, lo único que puede hacer <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/mqueue-client.cpp">mqueue-client.cpp</a> es pedirle a <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/mqueue-client.cpp">mqueue-server.cpp</a> que termine.
Aunque no costaría nada añadir otras órdenes, como pedir que cambie la hora del sistema o la periodicidad con la que la muestra.</p>
</div>
<div class="paragraph">
<p>En Linux los descriptores de colas de mensajes son descriptores de archivo —como también lo son los descriptores de <em>sockets</em>, tuberías y los de archivos abiertos con <a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a>, entre otros—. Esta particularidad implica que en Linux, mediante las funciones <a href="https://man7.org/linux/man-pages/man2/select.2.html">select()</a>, <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a> o <a href="https://man7.org/linux/man-pages/man7/epoll.7.html">epoll()</a>, se pueden monitorizar al mismo tiempo varios descriptores de colas de mensajes, para así saber cuándo se puede enviar o recibir por ellas sin que el proceso se bloquee.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Este comportamiento es específico de Linux.
No está contemplado en el estándar POSIX, por lo que otros sistemas POSIX no tienen por qué soportarlo.
Así que no es portable.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A continuación se puede ver un ejemplo específico con <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a>, aunque las tres funciones se utilizan empleando un patrón similar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">mqd_t</span> <span class="n">mqueue1</span> <span class="o">=</span> <span class="n">mq_open</span><span class="p">(</span> <span class="s">"/foo-queue"</span><span class="p">,</span> <span class="cm">/* ... */</span> <span class="p">);</span> <i class="conum" data-value="1"></i><b>(1)</b>
<span class="n">mqd_t</span> <span class="n">mqueue2</span> <span class="o">=</span> <span class="n">mq_open</span><span class="p">(</span> <span class="s">"/bar-queue"</span><span class="p">,</span> <span class="cm">/* ... */</span> <span class="p">);</span>

<span class="k">struct</span> <span class="n">pollfd</span> <span class="n">fds</span><span class="p">[]</span> <span class="o">=</span>
<span class="p">{</span>
    <span class="p">{</span>
        <span class="p">.</span><span class="n">fd</span> <span class="o">=</span> <span class="n">mqueue1</span><span class="p">,</span> <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="p">.</span><span class="n">events</span> <span class="o">=</span> <span class="n">POLLIN</span><span class="p">,</span> <i class="conum" data-value="3"></i><b>(3)</b>
        <span class="p">.</span><span class="n">revents</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">},</span> <span class="p">{</span>
        <span class="p">.</span><span class="n">fd</span> <span class="o">=</span> <span class="n">mqueue2</span><span class="p">,</span> <i class="conum" data-value="2"></i><b>(2)</b>
        <span class="p">.</span><span class="n">events</span> <span class="o">=</span> <span class="n">POLLIN</span> <span class="o">|</span> <span class="n">POLLOUT</span><span class="p">,</span> <i class="conum" data-value="3"></i><b>(3)</b>
        <span class="p">.</span><span class="n">revents</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">}</span>
<span class="p">};</span>

<span class="k">while</span> <span class="p">(</span> <span class="o">!</span><span class="n">quit_app</span> <span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">return_code</span> <span class="o">=</span> <span class="n">poll</span><span class="p">(</span> <span class="n">fds</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span> <span class="p">);</span> <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="k">if</span> <span class="p">(</span><span class="n">return_code</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <i class="conum" data-value="5"></i><b>(5)</b>
    <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">fds</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">revents</span> <span class="o">&amp;</span> <span class="n">POLLIN</span><span class="p">)</span> <i class="conum" data-value="7"></i><b>(7)</b>
        <span class="p">{</span>
            <span class="n">mq_receive</span><span class="p">(</span> <span class="n">fds</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">fd</span><span class="p">,</span> <span class="cm">/* ... */</span> <span class="p">);</span>

            <span class="c1">// Aquí va código para usar el mensaje recibido...</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">fds</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">revents</span> <span class="o">&amp;</span> <span class="n">POLLIN</span><span class="p">)</span> <i class="conum" data-value="7"></i><b>(7)</b>
        <span class="p">{</span>
            <span class="n">mq_receive</span><span class="p">(</span> <span class="n">fds</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">fd</span><span class="p">,</span> <span class="cm">/* ... */</span> <span class="p">);</span>

            <span class="c1">// Aquí va código para usar el mensaje recibido...</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">fds</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">revents</span> <span class="o">&amp;</span> <span class="n">POLLOUT</span><span class="p">)</span> <i class="conum" data-value="7"></i><b>(7)</b>
        <span class="p">{</span>
            <span class="c1">// Aquí va código para preparar el mensaje a enviar...</span>

            <span class="n">mq_send</span><span class="p">(</span> <span class="n">fds</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">fd</span><span class="p">,</span> <span class="cm">/* ... */</span> <span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">return_code</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <i class="conum" data-value="6"></i><b>(6)</b>
    <span class="p">{</span>
        <span class="c1">// Error en poll().</span>
        <span class="c1">// Aquí va código para leer errno y manejar el error...</span>

        <span class="n">quit_app</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Abrimos o creamos las colas que vamos a utilizar.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Creamos un <em>array</em> de la estructura <code>pollfd</code> con un elemento por cola que vamos a monitorizar con <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a>.
En cada estructura, en el campo <code>fd</code>, se indica el descriptor de cada una de las cola de mensajes.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Para cada cola hay que utilizar el campo <code>events</code> para indicar qué queremos que monitorice <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a>.
<code>events</code> es una máscara de bit donde a cada evento monitorizable le corresponde un bit.
Si queremos monitorizar un evento, debemos poner su bit a 1.
<div class="paragraph">
<p>Para eso nos podemos ayudar de macros como <code>POLLIN</code> y <code>POLLOUT</code>.
Por ejemplo, para <code>mqueue1</code> se quiere monitorizar cuándo hay mensajes para recibir, por lo que se activa <code>POLLIN</code>.
Mientras que para <code>mqueue2</code> se quiere saber tanto cuándo hay mensajes para recibir como cuándo hay un hueco en la cola para enviar sin bloqueos, por lo que se activan <code>POLLIN</code> y <code>POLLOUT</code>.</p>
</div></td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Iterativamente se llama a <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a> —mientras no queramos que termine la aplicación— que pondrá el proceso en estado <strong>esperando</strong> hasta que ocurra alguno de los eventos que nos interesan.
<a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a> necesita <code>fds</code> —el <em>array</em> de la estructura <code>pollfd</code> que hemos inicializado previamente— el número de elementos en el <em>array</em> y el tiempo máximo que debe mantener bloqueado el proceso esperando a que ocurra alguno de los eventos.
Con un número negativo en este último campo, se indica que queremos que espere indefinidamente.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Si <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a> tiene éxito, devuelve un numero positivo que indica en cuántos descriptores se ha detectado un evento.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Si <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a> devuelve un valor negativo, es que ha ocurrido algún error.
El motivo del error se puede conocer comprobando el valor de la variable global <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>El campo <code>revents</code> es una máscara de bits similar a <code>events</code>, pero al retornar de <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a> indica qué eventos se han detectado, para cada cola de mensajes en <code>fds</code>.
<div class="paragraph">
<p>Por ejemplo, en ambas colas se comprueba si <code>POLLIN</code> está activo.
En caso afirmativo, sabemos que podemos leer un mensaje sin que <a href="https://man7.org/linux/man-pages/man3/mq_receive.3.html">mq_receive()</a> se bloquee.
Igualmente, sabemos si <code>mqueue2</code> tiene hueco para enviar un mensaje comprobando si <code>POLLOUT</code> está activo.
En caso afirmativo, podemos enviar un mensaje con <a href="https://man7.org/linux/man-pages/man3/mq_send.3.html">mq_send()</a> sabiendo que no se bloqueará.</p>
</div></td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_señales_en_sistemas_operativos_posix">10.5.2. Señales en sistemas operativos POSIX</h4>
<div class="paragraph">
<p>En los sistemas POSIX, una forma más sencilla de comunicar dos procesos del mismo sistema es mediante el envío de una <strong>señal</strong> de uno al otro.</p>
</div>
<div class="paragraph">
<p>Los procesos pueden mandar señales utilizando la llamada al sistema <a href="https://man7.org/linux/man-pages/man2/kill.2.html">kill()</a>, que sólo requiere el identificador del proceso de destino y el número que identifica la señal.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">kill</span><span class="p">(</span><span class="n">pid</span><span class="p">,</span> <span class="n">SIGTERM</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Como se usa el identificado del proceso, estamos hablando de un mecanismo de <strong>comunicación directa</strong>.</p>
</div>
<div class="paragraph">
<p>El <strong>tamaño y formato del mensaje es fijo</strong>.
Las señales solo pueden portar la información de que ha ocurrido un evento, indicado qué evento es a través del número que identifica la señal.</p>
</div>
<div class="paragraph">
<p>Cada señal tiene un efecto particular por defecto —que por lo general es matar al proceso— en el proceso que las recibe.
Sin embargo, cada proceso puede declarar un <strong>manejador de señal</strong>.
Una función del programa que será invocada por el sistema operativo para tratar una señal determinada, interrumpiendo lo que esté haciendo el proceso en ese momento.
En ese sentido las señales en POSIX puede interpretarse como una forma de interrupción por software.</p>
</div>
<div class="paragraph">
<p>El <strong>manejador de señal</strong> se puede configurar usando la llamada al sistema <a href="https://man7.org/linux/man-pages/man2/signal.2.html">signal()</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">signal</span><span class="p">(</span>
    <span class="n">SIGTERM</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="o">&amp;</span><span class="n">mi_manejador_de_sigterm</span> <i class="conum" data-value="2"></i><b>(2)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Identificador de la señal a recibir.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Puntero al manejador de señal.
Es decir, la del programa que será llamada por el sistema operativo cuando llegue la señal <code>SIGTERM</code>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>El problema de <a href="https://man7.org/linux/man-pages/man2/signal.2.html">signal()</a> es que el estándar POSIX permite diferencias que hacen que se pueda comportar de forma distinta en diferentes sistemas operativos.
Para resolverlo, el estándar recomienda usar <a href="https://man7.org/linux/man-pages/man2/sigaction.2.html">sigaction</a> en su lugar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">struct</span> <span class="n">sigaction</span> <span class="n">act</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">.</span><span class="n">sa_handler</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">mi_manejador_de_sigterm</span><span class="p">,</span> <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="p">.</span><span class="n">sa_sigaction</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">,</span>   <i class="conum" data-value="5"></i><b>(5)</b>
    <span class="p">.</span><span class="n">sa_mask</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>           <i class="conum" data-value="6"></i><b>(6)</b>
    <span class="p">.</span><span class="n">sa_flags</span> <span class="o">=</span> <span class="n">SA_RESTART</span><span class="p">,</span> <i class="conum" data-value="7"></i><b>(7)</b>
<span class="p">}</span>

<span class="n">sigaction</span><span class="p">(</span>
    <span class="n">SIGTERM</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="o">&amp;</span><span class="n">act</span><span class="p">,</span>    <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="nb">NULL</span>     <i class="conum" data-value="3"></i><b>(3)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Identificador de la señal a recibir.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Puntero a una estructura de tipo <code>sigaction</code> que describe los detalles de como tratar la señal cuando llega al proceso.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Puntero a una estructura de tipo <code>sigaction</code> donde <a href="https://man7.org/linux/man-pages/man2/sigaction.2.html">sigaction</a> guarda la configuración anterior sobre como tratar la señal indicada.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Puntero al manejador de señal para la señal indicada.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Puntero a un manejador de señal alternativo al de <code>sa_handler</code>.
Este manejador recibe más información sobre la señal cuando es llamado.
Para activar es necesario indicar <code>SA_SIGINFO</code> en el campo <code>sa_flags</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Máscara de bits de señales a bloquear durante el manejo de la señal.
Cada bit de la máscara identifica a una señal.
Deben ponerse a 1 aquellas señales que queremos que estén bloqueadas —es decir, que no se puedan recibir— mientras se ejecuta el manejador de señal porque ha llegado una.
Es especialmente útil si se va a usar el mismo manejador para varias señales.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Opciones de configuración.
Por ejemplo, <code>SA_RESTART</code> indica que si la señal llega durante una llamada al sistema, la llamada debe continuar una vez se haya salido del manejador de señal.
El comportamiento por defecto, sin esta opción, es que la llamada al sistema interrumpida falle con el error <code>EINTR</code> en <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Las señales fueron diseñadas originalmente como un mecanismo para que el sistema operativo notificara a los programas ciertos errores y sucesos críticos.
Por ejemplo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La señal <code>HUP</code> o <code>SIGHUP</code> es enviada a cada proceso iniciado desde una sesión de terminal cuando dicha sesión termina —o cuando se usa la combinación de teclas <span class="keyseq"><kbd>CTRL</kbd>+<kbd>D</kbd></span>, que tiene el mismo efecto—.</p>
<div class="paragraph">
<p>En el caso de los servicios del sistema —que, como no son interactivos, no están conectados a ninguna terminar— esta señal suele usarse para indicarles que deben reiniciarse, volviendo a leer sus archivos de configuración, o para que guarden su estado interno en algún sitio conocido del almacenamiento.</p>
</div>
</li>
<li>
<p>La señal <code>INT</code> o <code>SIGINT</code> es enviada al proceso que está enganchado a la consola cuando el usuario pulsa el carácter de interrupción —frecuentemente la combinación de teclas <span class="keyseq"><kbd>CTRL</kbd>+<kbd>C</kbd></span>—.</p>
</li>
<li>
<p>La señal <code>TERM</code> o <code>SIGTERM</code> es enviada al proceso cuando debe terminar.
Por ejemplo, el sistema operativo envía esta señal a todos los procesos cuando se está apagando el sistema.</p>
</li>
<li>
<p>La señal <code>SEGV</code> o <code>SIGSEGV</code> es enviada a un proceso cuando intenta acceder a una zona de memoria a la que no tiene permiso.
Si no se maneja esta señal, el programa termina con el conocido mensaje de <strong>violación de segmento</strong>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Obviamente hay muchas más señales.
Entre todas, el estándar POSIX incluye dos señales —<code>USR1</code> y <code>USR2</code>— especialmente indicadas para usarlas con el significado que nosotros queramos.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Se puede consultar una lista de las señales del estándar POSIX en <a href="https://es.wikipedia.org/wiki/Se%C3%B1al_(inform%C3%A1tica)">«Señales (informática)&#8201;&#8212;&#8201;Wikipedia»</a>.
Mientras que la lista completa de señales soportadas en Linux se puede consultar en el <a href="https://man7.org/linux/man-pages/man7/signal.7.html">manual</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>El ejemplo en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/mqueue-client.cpp">mqueue-server.cpp</a> y en otros ejemplos de este capítulo, utiliza señales para manejar <code>SIGINT</code>, <code>SIGTERM</code> y para mostrar la hora periódicamente.
El código dedicado a eso está en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/common/timeserver.c">timeserver.c</a> y se comparte entre todos los ejemplos.</p>
</div>
<div class="paragraph">
<p>En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/signals.c">signals.c</a> hay un programa de ejemplo que muestra cómo manejar las señales del sistema y que sirve para ver como funcionan.
Solo hay que ejecutarlo y luego enviarle señales con el comando <code>kill</code> desde otra terminal.</p>
</div>
</div>
<div class="sect3">
<h4 id="_tuberías">10.5.3. Tuberías</h4>
<div class="paragraph">
<p>Las <strong>tuberías</strong> son un mecanismo de paso de mensajes de <strong>comunicación indirecta</strong>, <strong>orientada a flujos</strong>, <strong>capacidad limitada</strong> y, generalmente, <strong>comunicación síncrona</strong> —aunque en algunos sistema operativos también puede soportar asíncrona—.</p>
</div>
<div class="paragraph">
<p>Conceptualmente cada tubería tiene dos extremos en los que se puede leer y escribir mediante las operaciones básicas de lectura y escritura de archivos <code>read()</code> y <code>write()</code>.
Un extremo permite los procesos en ese extremo escribir en la tubería, mientras el otro extremo permite a los procesos leer de la tubería los datos escritos desde el otro extremo.</p>
</div>
<div class="paragraph">
<p>Existen dos tipos de tuberías:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Las <strong>tuberías anónimas</strong> sólo existen en el espacio de direcciones del proceso que las crea, de tal forma que debe heredarse de padres a hijos para que otros procesos puedan tener acceso.</p>
</li>
<li>
<p>Las <strong>tuberías con nombre</strong> son públicas al resto del sistema, por lo que teóricamente cualquier proceso con permisos puede abrir una para comunicarse con otros procesos.
Por eso se suele utilizar en aplicaciones cliente-servidor, dónde un proceso servidor ofrece algún servicio a otros procesos cliente a través de la tubería.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En los sistemas POSIX las <strong>tuberías con nombre</strong> se denominan <em>FIFO</em> y tienen presencia en el sistema de archivos como archivos especiales.</p>
</div>
</td>
</tr>
</table>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Tabla 3. Funciones de la API para manipular tuberías.</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">POSIX API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Windows API</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crear tubería anónima</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/pipe.2.html">pipe()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/namedpipeapi/nf-namedpipeapi-createpipe">CreatePipe()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Crear tubería con nombre</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man3/mkfifo.3.html">mkfifo()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-createnamedpipea">CreateNamedPipe()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Abrir tubería con nombre</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/open.2.html">open()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea">CreateFile()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Leer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/read.2.html">read()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-readfile">ReadFile()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escribir</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/write.2.html">write()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-writefile">WriteFile()</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cerrar</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://man7.org/linux/man-pages/man2/close.2.html">close()</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.microsoft.com/en-us/windows/win32/api/handleapi/nf-handleapi-closehandle">CloseHandle()</a></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Con <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> es muy sencillo lanzar otros procesos para que ejecuten tareas en paralelo.
El proceso hijo tiene acceso a los datos del padre por la forma en la que funciona <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> y gracias a las tuberías anónimas puede comunicar los resultados al padre.
En {forkpipe_cpp} se puede observar un ejemplo de esto.</p>
</div>
<div class="paragraph">
<p>Además, el hecho de que cada extremo se comporte como un archivo —uno en modo solo lectura y el otro en modo solo escritura— hace posible redirigir la E/S estándar del proceso hijo.
Es decir, conectar la entrada, la salida estándar o la salida de error a una tubería, desde la que leer lo que el proceso intenta imprimir por la pantalla de la terminal o proporcionarle lo que debe leer, como si fuera desde el teclado.
En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/fork-redir.c">fork-redir.c</a> se puede ver un ejemplo de como ejecutar el comando <code>ls</code> y redirigir su salida al proceso padre para contar el número de líneas en lo que eñ comando quería mostrar por pantalla.</p>
</div>
<div class="paragraph">
<p>Por otro lado, las tuberías con nombre permiten que un proceso se comunique con cualquier otro, solo con conocer la ruta de la tubería.
En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/fifo-client.c">fifo-server.c</a> tenemos un ejemplo de un programa que muestra la hora del sistema de forma periódica, mientras espera órdenes de una tubería que sirve de canal de control remoto.
Los programas en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/fifo-client.c">fifo-client.c</a> y <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/fifo-client.cpp">fifo-client.cpp</a> pueden conectarse a esa tubería y mandar el comando que hace terminar <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/fifo-client.c">fifo-server.c</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_sockets">10.5.4. Sockets</h4>
<div class="paragraph">
<p>Mientras que las tuberías son conceptualmente un enlace de comunicación unidireccional que tiene dos extremos, un <strong><em>socket</em></strong> representa un solo extremo en un enlace de comunicación bidireccional.
Para que una pareja de procesos se pueda comunicar son necesarios dos <em>sockets</em> —uno en cada proceso— de manera que cada uno de ellos es el medio por el que el proceso accede al enlace de comunicación.</p>
</div>
<div class="paragraph">
<p>La API de <em>sockets</em> fue creada por la Universidad de Berkeley para abstraer el acceso a la familia de protocolos de Internet en el UNIX desarrollado por esa misma universidad.
Sin embargo, rápidamente se convirtió en el estándar de facto para la comunicación en red, por lo que todos los sistemas operativos modernos —incluidos los sistemas POSIX y Microsoft Windows— tienen una implementación de la misma.</p>
</div>
<div class="paragraph">
<p>Pese a sus orígenes en Internet, los <em>sockets</em> se diseñaron para ser independientes de la tecnología de red subyacente con la que se implementa el enlace de comunicación.
En Linux, por ejemplo, se puede utilizar como interfaz de programación para utilizar dos decenas de familias de protocolos y tecnologías diferentes.</p>
</div>
<div class="paragraph">
<p>Para crear un <em>socket</em> te utiliza la llamada al sistema <a href="https://man7.org/linux/man-pages/man2/socket.2.html">socket()</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">int</span> <span class="n">sockfd</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">AF_UNIX</span><span class="p">,</span>         <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="n">SOCK_DGRAM</span><span class="p">,</span>      <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="mi">0</span>
<span class="p">)</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>En sistemas POSIX la función devuelve un <code>int`con el descriptor del socket mientras que en Microsoft Windows devuelve un `HANDLE</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>En el primer argumento se especifica la familia de protocolos.
<code>AF_UNIX</code> son un tipo de <em>socket</em> que solo sirve para comunicar procesos en el mismo sistema, denominado <strong>socket de dominio UNIX</strong>.
Otras familias muy comunes son <code>AF_INET</code>, que corresponde a la la familia de protocolos TCP/IP y <code>AF_INET6</code> para los protocolos IPv6.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>En el segundo argumento se especifica el tipo del <em>socket</em>.
Cada tipo suele corresponde con un protocolo concreto de la familia elegida.
Por ejemplo, los <em>sockets</em> <code>SOCK_DGRAM</code> son «no orientados a conexión», no fiables y de longitud máxima fija, así que en la familia <code>AF_INET</code> estos <em>sockets</em> utiliza UDP.
Mientras que los <em>sockets</em> <code>SOCK_STREAM</code> son orientados a conexión, fiables, bidireccionales y orientados a flujo, por lo que en la familia <code>AF_INET</code> utilizan TCP.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Un <em>socket</em> recién creado no tiene un nombre que otro proceso pueda usar para identificarlo y comunicarse con él.
Para asignar ese nombre o dirección se utiliza <a href="https://man7.org/linux/man-pages/man2/bind.2.html">bind()</a>.
La dificultad es que cada familia de protocolos tiene un formato de direcciones diferente, así que hay que tener cuidado de usar le adecuado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">struct</span> <span class="n">sockaddr_un</span> <span class="n">addr</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">.</span><span class="n">sun_family</span> <span class="o">=</span> <span class="n">AF_INET</span><span class="p">,</span>        <i class="conum" data-value="5"></i><b>(5)</b>
    <span class="p">.</span><span class="n">sun_path</span> <span class="o">=</span> <span class="s">"/tmp/foo-socket"</span> <i class="conum" data-value="6"></i><b>(6)</b>
<span class="p">};</span>

<span class="kt">int</span> <span class="n">result_code</span> <span class="o">=</span> <span class="n">bind</span><span class="p">(</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">sockfd</span><span class="p">,</span> <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="p">(</span><span class="k">struct</span> <span class="n">sockaddr</span><span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">addr</span><span class="p">,</span> <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="k">sizeof</span><span class="p">(</span><span class="n">addr</span><span class="p">)</span> <i class="conum" data-value="4"></i><b>(4)</b>
<span class="p">)</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Como en el esto de llamadas al sistema, en caso de error se devuelve un número negativo y <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a> contendrá el código del error.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>El descriptor del <em>socket</em> al que se le quiere cambiar la dirección.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>La nueva dirección del <em>socket</em> especificada como una estructura adecuada para la familia del <em>socket</em>.
En <em>socket</em> de tipo <code>AF_UNIX</code> la estructura debe ser de tipo <code>sockaddr_un</code> mientras que en los de tipo <code>AF_INET</code> es del tipo <code>sockaddr_in</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>El tamaño en bytes de la estructura con la nueva dirección.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>En la estructura con la dirección, el primero campo siempre es para indicar la familia.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>En los <em>sockets</em> de dominio UNIX la dirección es una ruta en el sistema de archivos.
Para otras familias, la direcciones se indica de otra manera, por lo que es necesario consultar la documentación.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>La API de <em>sockets</em> incluye muchas otras funciones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://man7.org/linux/man-pages/man2/listen.2.html">listen()</a>, para poner <em>sockets</em> tipo <code>SOCK_STREAM</code> a la espera de conexiones.</p>
</li>
<li>
<p><a href="https://man7.org/linux/man-pages/man2/connect.2.html">connect()</a>, para conectar un <em>socket</em> tipo <code>SOCK_STREAM</code> con otro que esté a la espera de conexiones.</p>
</li>
<li>
<p><a href="https://man7.org/linux/man-pages/man2/accept.2.html">accept()</a> para que un <em>socket</em> tipo <code>SOCK_STEAM</code> a la espera de conexiones acepte una solicitud de conexión.</p>
</li>
<li>
<p><a href="https://man7.org/linux/man-pages/man2/shutdown.2.html">shutdown()</a> para cerrar uno de los sentidos de una conexión.</p>
</li>
<li>
<p><a href="https://man7.org/linux/man-pages/man2/close.2.html">close()</a> para destruir un <em>socket</em></p>
</li>
<li>
<p><a href="https://man7.org/linux/man-pages/man2/send.2.html">send()</a>, <a href="https://man7.org/linux/man-pages/man2/send.2.html">sendto()</a> y <a href="https://man7.org/linux/man-pages/man2/send.2.html">sendmsg()</a> para enviar mensajes.
<a href="https://man7.org/linux/man-pages/man2/send.2.html">sendto()</a> sólo se puede utilizar con <em>sockets</em> conectados.
Mientras que <a href="https://man7.org/linux/man-pages/man2/send.2.html">sendto()</a> permiten indicar la dirección del <em>socket</em> de destino, por lo que es útil en <em>sockets</em> no orientados a conexión <code>SOCK_DGRAM</code>.</p>
</li>
<li>
<p><a href="https://man7.org/linux/man-pages/man2/recv.2.html">recv()</a>, <a href="https://man7.org/linux/man-pages/man2/recvfrom.2.html">recvfrom()</a> y <a href="https://man7.org/linux/man-pages/man2/recvmsg.2.html">recvmsg()</a> para recibir mensajes.
<a href="https://man7.org/linux/man-pages/man2/recvfrom.2.html">recvfrom()</a> permite obtener la dirección del <em>socket</em> del que llegó el mensaje.
Por eso es útil en <em>sockets</em> no orientados a conexión <code>SOCK_DGRAM</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">struct</span> <span class="n">sockaddr_un</span> <span class="n">addr</span><span class="p">;</span>
<span class="n">socklen_t</span> <span class="n">addrlen</span><span class="p">;</span>

<span class="kt">int</span> <span class="n">result_code</span> <span class="o">=</span> <span class="n">recvfrom</span><span class="p">(</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">sockfd</span><span class="p">,</span>          <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="o">&amp;</span><span class="n">message</span><span class="p">,</span>        <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="k">sizeof</span><span class="p">(</span><span class="n">message</span><span class="p">),</span> <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="mi">0</span><span class="p">,</span>               <i class="conum" data-value="5"></i><b>(5)</b>
    <span class="p">(</span><span class="k">struct</span> <span class="n">sockaddr</span><span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">addr</span><span class="p">,</span> <i class="conum" data-value="6"></i><b>(6)</b>
    <span class="o">&amp;</span><span class="n">addrlen</span>         <i class="conum" data-value="7"></i><b>(7)</b>
<span class="p">)</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>En caso de éxito devuelve número de bytes del mensaje recibido.
En caso de error, un -1 y <a href="https://man7.org/linux/man-pages/man3/errno.3.html">errno</a> contiene el código del error.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>El descriptor del <em>socket</em> al que se le quiere cambiar la dirección.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Puntero a la dirección de memoria donde está el mensaje.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Tamaño del mensaje en bytes.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Opciones adicionales de configuración.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Estructura de dirección vacía donde se copiará la dirección del <em>socket</em> que remite el mensaje.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Puntero donde la llamada al sistema copiará el tamaño de la estructura copiada en <code>addr</code>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Las operaciones con <em>sockets</em> son síncronas por defecto.
Sin embargo, es posible configurarlos en modo asíncrono, para que así cualquiera de estas funciones falle, retornando -1 y código de error <code>EAGAIN</code> o <code>EWOULDBLOCK</code>, antes de poner el proceso en estado <strong>esperando</strong>.</p>
</div>
<div class="paragraph">
<p>También se pueden utilizar las funciones <a href="https://man7.org/linux/man-pages/man2/select.2.html">select()</a> y <a href="https://man7.org/linux/man-pages/man2/poll.2.html">poll()</a> para monitorizar varios <em>sockets</em> al mismo tiempo, de forma similar a como se hace para colas de mensajes POSIX (véase el <a href="#_colas_de_mensajes_posix">Apartado 10.5.1</a>).</p>
</div>
<div class="paragraph">
<p>En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/socket-client.cpp">socket-server.cpp</a> y <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/socket-client.cpp">socket-client.cpp</a> se puede observar un ejemplo similar al que usamos con las tuberías y las colas de mensajes, pero empleando <em>sockets</em> de dominio UNIX.
Ambos programas utilizan la cabecera <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap10/socket.hpp">socket.hpp</a> que incluye un ejemplo de clase en C++ para comunicaciones mediante <em>sockets</em>.
En los distintos métodos se puede ver como se utilizan las funciones de la librería del sistema para crear <em>sockets</em>, asignarles dirección y usarlos para enviar y recibir mensajes.</p>
</div>
<div class="paragraph">
<p>En resumen, los <strong><em>sockets</em></strong> son un mecanismo de paso de mensajes de <strong>comunicación indirecta</strong>, que admite tanto comunicación <strong>orientada a flujos</strong> como <strong>mensajes de tamaño variable</strong>, <em>buffering</em> de <strong>capacidad limitada</strong> y tanto <strong>comunicación síncrona</strong> como <strong>asíncrona</strong>, aunque el comportamiento real final de la interfaz depende de la tecnología de red utilizada.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_memoria_compartida">11. Memoria compartida</h2>
<div class="sectionbody">
<div class="paragraph">
<p>La <strong>memoria compartida</strong> es una estrategia para comunicar procesos dónde uno de ellos gana acceso a regiones de la memoria del otro; algo que por lo general el sistema operativo siempre intenta evitar.
Por eso, para que pueda haber memoria compartida es necesario que los dos procesos estén de acuerdo en eliminar dicha restricción.</p>
</div>
<div class="paragraph">
<p>Dos procesos que comparten una región de la memoria pueden intercambiar información simplemente leyendo y escribiendo datos en la misma.
Sin embargo debemos tener en cuenta que:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La estructura de los datos y su localización dentro de la región compartida la determinan los procesos en comunicación y no el sistema operativo, a diferencia de lo que ocurre en los sistemas de paso de mensajes.</p>
</li>
<li>
<p>Los procesos son responsables de sincronizarse para no escribir y leer en el mismo sitio de la memoria al mismo tiempo, pues esto puede generar inconsistencias (véase el <a href="#_sincronización">Capítulo 13</a>) .</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Las principales ventajas de la memoria compartida frente a otros mecanismos de comunicación son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Eficiencia</strong>.
Puesto que la comunicación tiene lugar a la velocidad de la memoria principal, se trata de un mecanismo tremendamente rápido.</p>
</li>
<li>
<p><strong>Conveniencia</strong>.
Puesto que el mecanismo de comunicación sólo requiere leer y escribir de la memoria, se trata de un sistema muy sencillo y fácil de utilizar.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Como ocurre con las tuberías (véase el <a href="#_tuberías">Apartado 10.5.3</a>) la memoria compartida puede ser anónima o con nombre.</p>
</div>
<div class="sect2">
<h3 id="_memoria_compartida_anónima">11.1. Memoria compartida anónima</h3>
<div class="paragraph">
<p>La <strong>memoria compartida anónima</strong> solo existe para el proceso que la crea y para sus procesos hijos, que heredan el acceso.
Es por tanto, una forma eficiente de comunicar procesos padres e hijos.</p>
</div>
<div class="paragraph">
<p>En lo sistemas POSIX, las funciones y operadores de reserva de memoria como <a href="https://en.cppreference.com/w/c/memory/malloc">malloc()</a> y <a href="https://en.cppreference.com/w/cpp/language/new">new</a>, utilizan internamente la llamada al sistema <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap()</a>.
Esta función se puede llamar de la siguiente manera para reservar <code>length</code> bytes de memoria.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">void</span><span class="o">*</span> <span class="n">p</span> <span class="o">=</span> <span class="n">mmap</span><span class="p">(</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="nb">NULL</span><span class="p">,</span>
    <span class="n">length</span><span class="p">,</span>     <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span>      <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="n">MAP_ANONYMOUS</span> <span class="o">|</span> <span class="n">MAP_PRIVATE</span><span class="p">,</span> <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">0</span>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Si todo va bien, <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap()</a> devuelve un puntero al primer byte de la memoria reservada.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Cantidad de memoria a reservar en bytes.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Permisos de acceso para la memoria reservada.
En este caso, se solicita permitir la lectura y la escritura de la memoria.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td><code>MAP_ANONYMOUS</code> indica que la memoria no está respaldada por ningún archivo, por lo que su contenido inicial será cero.
Mientras que <code>MAP_PRIVATE</code> establece que la región de memoria es privada.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Lo interesante es que si se cambia <code>MAP_PRIVATE</code> por <code>MAP_SHARED</code> la región de memoria reservada es memoria compartida:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">void</span><span class="o">*</span> <span class="n">p</span> <span class="o">=</span> <span class="n">mmap</span><span class="p">(</span>
    <span class="nb">NULL</span><span class="p">,</span>
    <span class="n">length</span><span class="p">,</span>
    <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span>
    <span class="n">MAP_ANONYMOUS</span> <span class="o">|</span> <span class="n">MAP_SHARED</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">0</span>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Memoria anónima y compartida.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Es decir, que al crear un hijo con <a href="https://man7.org/linux/man-pages/man2/fork.2.html">fork()</a> este tendrá una copia de toda la memoria del proceso padre, excepto esta región en particular, que será la misma que la del padre.
Por lo tanto, escribiendo y leyendo en esa región, ambos procesos pueden comunicarse.</p>
</div>
<div class="paragraph">
<p>En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap11/anom-shared-memory.cpp">anom-shared-memory.cpp</a> se puede ver un ejemplo muy simple, similar a {forkpipe_cpp} pero utilizando memoria compartida para comunicar ambos procesos.
Como se puede apreciar, la versión que usa memoria compartida es bastante más sencilla que la que utiliza tuberías.</p>
</div>
<div class="paragraph">
<p>En Microsoft Windows se puede hacer algo similar con <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-createfilemappinga">CreateFileMapping()</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">HANDLE</span> <span class="n">hMapFile</span> <span class="o">=</span> <span class="n">CreateFileMapping</span><span class="p">(</span> <i class="conum" data-value="3"></i><b>(3)</b>
    <span class="n">INVALID_HANDLE_VALUE</span><span class="p">,</span>
    <span class="nb">NULL</span><span class="p">,</span>
    <span class="n">PAGE_READWRITE</span><span class="p">,</span> <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="mi">0</span><span class="p">,</span>
    <span class="n">length</span><span class="p">,</span>         <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="nb">NULL</span>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Permisos de acceso para la memoria reservada.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Cantidad de memoria a reservar en bytes.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>A diferencia de <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap()</a>, <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-createfilemappinga">CreateFileMapping()</a> crea un objeto de memoria compartida pero no hace visible esa memoria para nuestro proceso.
Para eso hay que llamar a <a href="https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-mapviewoffile">MapViewOfFile()</a> pasándole el manejador <code>hMapFile</code> devuelto por <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-createfilemappinga">CreateFileMapping()</a>.</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_memoria_compartida_con_nombre">11.2. Memoria compartida con nombre</h3>
<div class="paragraph">
<p>La <strong>memoria compartida con nombre</strong> es pública para el resto del sistema, por lo que teóricamente cualquier proceso con permisos puede acceder a ella para comunicarse con otros procesos.</p>
</div>
<div class="paragraph">
<p>Como ocurre en las tuberías con nombre, los <strong>objetos de memoria compartida con nombre</strong> hay que crearlos antes de comenzar a utilizarlos.
Para eso los sistemas POSIX ofrecen la función <a href="https://www.man7.org/linux/man-pages/man3/shm_open.3.html">shm_open()</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">int</span> <span class="n">shmfd</span> <span class="o">=</span> <span class="n">shm_open</span><span class="p">(</span>   <i class="conum" data-value="4"></i><b>(4)</b>
    <span class="s">"/foo-shm"</span><span class="p">,</span>         <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">O_RDWR</span> <span class="o">|</span> <span class="n">O_CREAT</span><span class="p">,</span>   <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="mi">666</span>                 <i class="conum" data-value="3"></i><b>(3)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Nombre que identifica al objeto de memoria compartida.
Como ocurre con los archivos, varios procesos pueden acceder al mismo objeto indicando el mismo nombre.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Valores que indican diferentes opciones a la hora de abrir el objeto.
Por ejemplo, usando <code>O_RDWR</code> indicamos que se abra para lectura y escritura.
Mientras que con <code>O_CREAT</code> se indica que el objeto debe crearse si no existía previamente.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Indica los permisos del objeto de memoria compartida al crearlo nuevo, de forma similar a los permisos que se aplican a los archivos en el sistema de archivos.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>El valor devuelto por <a href="https://www.man7.org/linux/man-pages/man3/shm_open.3.html">shm_open()</a> es el descriptor del objeto de memoria compartida, que utilizaremos posteriormente con <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap()</a> al reservar una región de la memoria de nuestro proceso donde ese objeto de memoria compartida será visible:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">void</span><span class="o">*</span> <span class="n">p</span> <span class="o">=</span> <span class="n">mmap</span><span class="p">(</span>
    <span class="nb">NULL</span><span class="p">,</span>
    <span class="n">length</span><span class="p">,</span>                 <i class="conum" data-value="2"></i><b>(2)</b>
    <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span>
    <span class="n">MAP_SHARED</span><span class="p">,</span>             <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="n">shmfd</span><span class="p">,</span>                  <i class="conum" data-value="1"></i><b>(1)</b>
    <span class="mi">0</span>                       <i class="conum" data-value="2"></i><b>(2)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Al pasar el descriptor del objeto de memoria compartida, ya no se puede indicar <code>MAP_ANONYMOUS</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Se puede hacer visible para el proceso todo el objeto de memoria compartida o solo una parte.
Para esto último se indica el tamaño de la región y el desplazamiento dentro del objeto, que es el último argumento de <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap()</a>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Un objeto de memoria compartida recién creado tiene tamaño 0.
Para redimensionarlo se utiliza <a href="https://linux.die.net/man/2/ftruncate">ftruncate()</a>, que lo que necesita es el descriptor del objeto y el nuevo tamaño.</p>
</div>
<div class="paragraph">
<p>En <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap11/shared-memory-server.c">shared-memory-server.c</a> y <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap11/shared-memory-client.cpp">shared-memory-client.cpp</a> se puede ver el ejemplo de un programa que muestra periódicamente la hora del sistema.
En este caso controlado por otro mediante memoria compartida.
Ambos programas usan la clase definida en <a href="https://github.com/ull-esit-sistemas-operativos/ssoo-ejemplos/blob/master/src/cap11/shared_memory.hpp">shared_memory.hpp</a> para gestionar el objeto de memoria compartida.
Sus métodos muestran de forma práctica cómo utilizar las llamadas al sistema comentadas.</p>
</div>
<div class="paragraph">
<p>En Microsoft Windows también se utiliza <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-createfilemappinga">CreateFileMapping()</a> para crear el objeto de memoria compartida con nombre.
Simplemente hay que indicar el nombre en el último argumento de la función.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">HANDLE</span> <span class="n">hMapFile</span> <span class="o">=</span> <span class="n">CreateFileMapping</span><span class="p">(</span>
    <span class="n">INVALID_HANDLE_VALUE</span><span class="p">,</span>
    <span class="nb">NULL</span><span class="p">,</span>
    <span class="n">PAGE_READWRITE</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span>
    <span class="n">length</span><span class="p">,</span>
    <span class="s">"Global</span><span class="se">\\</span><span class="s">FooMemoriaCompartida"</span> <i class="conum" data-value="1"></i><b>(1)</b>
<span class="p">);</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Nombre del nuevo objeto de memoria compartida.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hilos">12. Hilos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Hasta el momento el modelo de proceso que hemos descrito asume que tenemos un sólo <strong>hilo</strong> de ejecución, es decir, que se ejecuta en la CPU una única secuencia de instrucciones.
Un proceso con un hilo de ejecución sólo puede realizar una tarea a la vez.
Por ejemplo, en un procesador de textos con un sólo hilo de ejecución el usuario nunca podría escribir al mismo tiempo que se comprueba la ortografía.
Por eso muchos sistemas operativos modernos han extendido el concepto de proceso para permitir múltiples hilos de ejecución en cada uno.
Los procesos con varios hilos pueden realizar varias tareas a la vez.</p>
</div>
<div class="sect2">
<h3 id="_introducción_2">12.1. Introducción</h3>
<div class="paragraph">
<p><em>El hilo es la unidad básica de uso de la CPU en los sistemas operativos multihilo</em>.
De los recursos de un proceso es privado a cada hilo (véase la ):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>El identificador del hilo</strong> lo identifica en el sistema de la misma manera que lo hace el identificador de proceso con el proceso.</p>
</li>
<li>
<p><strong>El contador de programa</strong> indica la dirección de la próxima instrucción del proceso que debe ser ejecutada por la CPU.</p>
</li>
<li>
<p><strong>Los registros de la CPU</strong>.</p>
</li>
<li>
<p><strong>La pila</strong> contiene datos temporales como parámetros y direcciones de retorno de las funciones y variables locales.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Sin embargo todos los hilos de un mismo proceso comparten (véase la ):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>El código del programa</strong>.</p>
</li>
<li>
<p><strong>Otras secciones de datos</strong>, como el montón.</p>
</li>
<li>
<p>Y <strong>otros recursos del proceso</strong> como archivos abiertos y señales.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_beneficios">12.1.1. Beneficios</h4>
<div class="paragraph">
<p>Muchos son los beneficios que aporta la programación multihilo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Respuesta</strong>.
Una aplicación multihilo interactiva puede continuar ejecutándose aunque parte de la misma esté bloqueada o realizando una operación lenta, mejorando la <em>respuesta al usuario</em> de la misma.
Por ejemplo, un navegador Web multihilo puede gestionar la interacción del usuario a través de un hilo mientras el contenido solicitado se descarga en otro hilo.</p>
</li>
<li>
<p><strong>Compartición de recursos</strong>.
Por defecto los hilos comparten la memoria y los recursos del proceso al que pertenecen.
El compartir el código es lo que permite a una aplicación tener varios hilos que realizan diferentes actividades dentro del mismo espacio de direcciones.</p>
</li>
<li>
<p><strong>Economía</strong>.
Reservar memoria y otros recursos para la creación de un proceso es costoso.
Puesto que los hilos comparten los recursos de los procesos a los que pertenecen es más económico crearlos.
También es más económico el cambio de contexto entre ellos ya que hay que guardar y recuperar menos información.
Por ejemplo en Oracle/Sun Microsystems Solaris crear un proceso es 30 veces más lento que crear un hilo; y el cambio de contexto es 5 veces más lento.</p>
</li>
</ul>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Aprovechamiento de las arquitecturas multiprocesador</strong>.
En esas arquitecturas diferentes hilos pueden ejecutarse en paralelo en distintos procesadores.
Por el contrario un proceso monohilo sólo se puede ejecutar en una CPU a la vez, independientemente de cuantas estén disponibles para ejecutarlo.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_soporte_multihilo">12.1.2. Soporte multihilo</h4>
<div class="paragraph">
<p><em>Las <strong>librerías de hilos</strong> proporcionan al programador la API para crear y gestionar los hilos de su proceso</em>.
Hay dos formas fundamentales de implementar una librería de hilos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La primera forma es <em>implementar la librería enteramente en el espacio de usuario, sin requerir el soporte del núcleo</em>:</p>
<div class="ulist">
<ul>
<li>
<p>Los hilos así gestionados no existen para el núcleo.
Sólo existen en el espacio de usuario dentro del proceso que los ha creado.
Por ese motivo se los denomina <strong>hilos de usuario</strong>.</p>
</li>
<li>
<p>El código y los datos de la librería residen en el espacio de usuario, por lo que invocar una función de la misma se reduce a una simple llamada a una función, evitando el coste de hacer llamadas al sistema.</p>
</li>
</ul>
</div>
</li>
<li>
<p>La segunda forma es <em>implementar la librería en el núcleo</em>.</p>
<div class="ulist">
<ul>
<li>
<p>Los hilos así gestionados son soportados y gestionados por el núcleo, quien se encarga de planificarlos en la CPU.
Por ese motivo se los denomina <strong>hilos de núcleo</strong>.</p>
</li>
<li>
<p>El código y los datos de la librería residen en el espacio del núcleo, por lo que invocar una función de la misma requiere frecuentemente hacer una llamada al sistema.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>En la actualidad en los diferentes sistemas operativos se pueden encontrar librerías de ambos tipos.
Por ejemplo, la librería de hilos del API Win32 es del segundo tipo mientras que la librería de hilos POSIX Threads —frecuentemente utilizada en los sistemas POSIX— puede ser de ambos tipos, dependiendo solamente del sistema donde se implemente<sup class="footnote">[<a id="_footnoteref_1" class="footnote" href="#_footnotedef_1" title="View footnote.">1</a>]</sup>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_modelos_multihilo">12.2. Modelos multihilo</h3>
<div class="paragraph">
<p>Las distintas formas de implementar los hilos comentadas anteriormente —en espacio de usuario o en el núcleo— no son excluyentes ya que en un sistema operativo concreto se pueden implementar ambas, una de las dos o ninguna —esto último en el caso de los sistemas operativos que no soportan de ninguna forma múltiples hilos de ejecución—.
Así que en general debe existir una relación entre los hilos de usuario y los del núcleo.
A continuación veremos tres formas de establecer dicha relación.</p>
</div>
<div class="sect3">
<h4 id="_muchos_a_uno">12.2.1. Muchos a uno</h4>
<div class="paragraph">
<p><em>En un sistema operativo cuyo núcleo no soporta múltiples hilos de ejecución la única posibilidad es utilizar una librería de hilos implementada en el espacio de usuario.
El planificador de dicha librería se encarga de determinar que hilo de usuario se ejecuta en cada momento en el proceso, mientras este es planificado en la CPU por el núcleo, obviamente elegido cuando le corresponda de entre todos los procesos del sistema.</em></p>
</div>
<div class="paragraph">
<p>A efectos prácticos un proceso «sin hilos» se puede interpretar como un proceso con «un único hilo» de ejecución en el núcleo.
Por eso se dice que <em>en el modelo <strong>muchos a uno</strong> se mapean los múltiples hilos de usuario de un proceso en el único hilo de núcleo del mismo</em> (véase la ).</p>
</div>
<div class="paragraph">
<p>Las principales características de este modelo son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>La gestión de hilos se hace con una librería en el espacio de usuario</em>, por lo que puede ser muy eficiente.
Como hemos visto anteriormente la invocación de las funciones de la librería se hace por medio de simples llamadas a funciones.</p>
</li>
<li>
<p><em>El proceso entero se bloquea si un hilo hace una llamada al sistema que deba ser bloqueada</em>.
Por ejemplo operaciones de E/S a archivos, esperar a que suceda un evento, etc.</p>
</li>
<li>
<p>Como sólo un hilo de usuario puede ser asignado al hilo de núcleo, <em>los hilos de un mismo proceso no se pueden ejecutar en paralelo en sistemas multiprocesador</em>.
El planificador de la librería de hilos es el encargado de determinar que hilo de usuario es asignado al único hilo de núcleo del proceso y este sólo puede ejecutarse en una única CPU al mismo tiempo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El problema del bloqueo de procesos puede ser evitado sustituyendo las funciones de la librería del sistema, de manera que las llamadas al sistema que se pueden bloquear sean sustituidas por versiones con llamadas equivalentes pero no bloqueantes.
Por ejemplo, las llamadas al sistema de E/S se pueden reemplazar por llamadas de E/S asíncrona, que retornan inmediatamente aunque la operación no haya sido completada.
Después de cada una de estas llamadas asíncronas al sistema, la librería del sistema invoca al planificador de la librería de hilos para que bloquee el hilo que ha realizado la llamada y asigne el hilo de núcleo a un nuevo hilo de usuario.
Obviamente el planificador de la librería de hilos debe estar al tanto de cuando las operaciones asíncronas son completadas para poder volver a planificar los hilos de usuario bloqueados.
Este procedimiento es a todas luces bastante complejo y requiere versiones no bloqueantes de todas las llamadas al sistema, así como modificar las funciones bloqueantes de la librería del sistema para implementar el comportamiento descrito.</p>
</div>
<div class="paragraph">
<p>Ejemplos de implementaciones este modelo de hilos son la Green Threads, una de las implementaciones de hilos para Solaris y Java, Stackless Python<sup class="footnote">[<a id="_footnoteref_2" class="footnote" href="#_footnotedef_2" title="View footnote.">2</a>]</sup> y GNU Portable Threads<sup class="footnote">[<a id="_footnoteref_3" class="footnote" href="#_footnotedef_3" title="View footnote.">3</a>]</sup>.
Estas implementaciones son muy útiles en los sistemas monohilo, de cara a poder ofrecer cierto soporte de hilos a las aplicaciones, pero también en los sistemas multihilo, ya que debido a su bajo coste en recursos y a su alta eficiencia son ideales cuando la cantidad de hilos a crear —el nivel de concurrencia— va a ser previsiblemente muy alta .</p>
</div>
</div>
<div class="sect3">
<h4 id="_uno_a_uno">12.2.2. Uno a uno</h4>
<div class="paragraph">
<p><em>Si el núcleo del sistema operativo soporta hilos de ejecución, lo más común es que estos sean visibles directamente en el espacio de usuario.
Por lo tanto se dice que _en el modelo <strong>uno a uno</strong> se mapea cada hilo de usuario en exactamente un hilo de núcleo</em> (véase la ).</p>
</div>
<div class="paragraph">
<p>Las principales características de este modelo son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Permite a otro hilo del mismo proceso ejecutarse aun cuando un hilo hace una llamada al sistema que debe bloquearse</em>, ya que el núcleo se encarga de ponerlo en espera y planificar en la CPU a otro de los hilos preparados para ejecutarse de entre todos los existentes en el sistema.</p>
</li>
<li>
<p><em>Permite paralelismo en sistemas multiprocesador</em>, ya que diferentes hilos pueden ser planificados por el núcleo en distintos procesadores.</p>
</li>
<li>
<p>Crear un hilo de usuario requiere crear el correspondiente hilo de núcleo.
Debido a que la cantidad de memoria disponible para el núcleo suele estar limitada, <em>muchos sistemas restringen la cantidad máxima de hilos soportados</em>.</p>
</li>
<li>
<p><em>Las gestión de los hilos se hace con una librería en el espacio de núcleo</em>, lo que requiere utilizar llamadas al sistema.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Este modelo se utilizar en la mayor parte de los sistemas operativos multihilo modernos.
Linux, Microsoft Windows 95/98/NT/2000/XP y superiores, y Solaris 9 y superiores, son ejemplos de sistemas operativos que los utilizan.</p>
</div>
</div>
<div class="sect3">
<h4 id="_muchos_a_muchos">12.2.3. Muchos a muchos</h4>
<div class="paragraph">
<p><em>En teoría debería ser posible aprovechar lo mejor de los dos modelos anteriores.
Por eso _en el modelo <strong>muchos a muchos</strong> se mapean los hilos de usuario en un menor o igual número de hilos de núcleo del proceso</em> (véase la ).
Así los desarrolladores pueden utilizar la librería de hilos en el espacio de usuario para crear tantos hilos como quieran.
El planificador de la librería de hilos se encarga de determinar que hilo de usuario es asignado a que hilo de núcleo.
Mientras que el planificador de la CPU asigna la CPU a alguno de los hilos de núcleo del sistema.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Los hilos de núcleo pueden ser ejecutados en paralelo en sistemas multiprocesador</em>.</p>
</li>
<li>
<p><em>Permite a otro hilo del mismo proceso ejecutarse cuando un hilo hace una llamada al sistema que debe ser bloqueada</em>, puesto que si un hilo de usuario realiza una llamada al sistema que debe ser bloqueada, el correspondiente hilo de núcleo quedará bloqueado.
Sin embargo, el resto de los hilos de usuario pueden seguir ejecutándose en los otros hilos de núcleo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Existe una variación del modelo muchos a muchos donde, además de hacer lo comentado anteriormente, se permite que un hilo de usuario quede ligado a un único hilo de núcleo.
Esta variación se denomina en ocasiones modelo de <strong>dos niveles</strong> (véase la ) y es soportada en sistemas operativos como Solaris 8 y anteriores, IRIX, HPUX y Tru64 UNIX.</p>
</div>
<div class="paragraph">
<p>Tanto en el modelo <em>muchos a muchos</em> como en el de <em>dos niveles</em> es necesario cierto grado de coordinación entre el núcleo y la librería de hilos del espacio de usuario.
Dicha comunicación tiene como objetivo ajustar dinámicamente el número de hilos del núcleo para garantizar la máxima eficiencia.
Uno de los esquemas de comunicación se denomina <strong>activación del planificador</strong> y consiste en que el núcleo informa a la librería de hilos en espacio de usuario del bloqueo de un hilo de un proceso.
Antes de dicha notificación el núcleo se encarga de crear un nuevo hilo de núcleo en el proceso, de manera que el planificador de la librería pueda encargarse de asignarle alguno de los otros hilos de usuario.
Así es como se ajusta el número de hilos dinámicamente de manera que el proceso nunca quede bloqueado.</p>
</div>
<div class="paragraph">
<p>Debido a la complejidad del mecanismo descrito anteriormente y a la dificultad de coordinar el planificador de la libraría de hilos con el de la CPU para obtener un rendimiento óptimo, sistemas como Linux y Solaris —a partir de la versión 9— han optado por el modelo uno a uno.
Con el objetivo de evitar las penalizaciones de dicho modelo, los desarrolladores de Linux han preferido concentrar sus esfuerzos en conseguir un planificador de CPU más eficiente, así como en reducir los costes de la creación de hilos de núcleo.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_otras_consideraciones_sobre_los_hilos">12.3. Otras consideraciones sobre los hilos</h3>
<div class="sect3">
<h4 id="_datos_específicos_de_hilo">12.3.1. Datos específicos de hilo</h4>
<div class="paragraph">
<p>Los hilos de un mismo proceso comparten los datos del mismo, siendo este uno de los principales beneficios de la programación multihilo.
Por ejemplo todas las variables globales del programa son compartidas por todos los hilos.
Sin embargo en algunas ocasiones puede interesar definir ciertos datos como privados a cada hilo.
A esos datos se los denomina <strong>TSD</strong> o <em>thread-specific data</em> y son soportados por muchas librerías de hilos, incluyendo el API Win32 y Pthreads, aunque no es común que sean soportados directamente por los distintos lenguajes de programación.</p>
</div>
</div>
<div class="sect3">
<h4 id="_cancelación_de_hilos">12.3.2. Cancelación de hilos</h4>
<div class="paragraph">
<p><em>La <strong>cancelación</strong> es la operación de terminar un hilo antes de que termine su trabajo</em>.
Por ejemplo, en un navegador web un hilo se puede encargar de la interfaz de usuario mientras otros hilos se encargan de descargar las páginas y las imágenes de la misma.
Si el usuario pulsa el botón <em>cancelar</em> es necesario que todos los hilos que intervienen en la descarga sean cancelados.
Esto puede ocurrir de dos maneras:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>En la <strong>cancelación asíncrona</strong> un hilo puede terminar inmediatamente la ejecución de otro</em>.
Esto puede causar problemas al no liberarse los recursos reservados al proceso por parte del hilo —no se cierran los archivos abiertos, no se libera la memoria, etc.—.
Además si el hilo que termina estaba modificando estructuras de datos que compartía con otros hilos, estas podrían quedar inconsistentes.</p>
</li>
<li>
<p><em>En la <strong>cancelación en diferido</strong> el hilo comprueba periódicamente cuando debe terminar</em>.
Esto da al hilo una oportunidad de terminarse así mismo de forma ordenada y en un punto dónde es seguro hacerlo.
En la terminología de Pthreads a estos puntos se los denomina <strong>puntos de cancelación</strong> —o <em>cancellation points</em>— y muchas llamadas al sistema lo son por si mismas.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_funciones_reentrantes_y_seguras_en_hilos">12.3.3. Funciones reentrantes y seguras en hilos</h4>
<div class="paragraph">
<p>A la hora de utilizar una librería en un programa multihilo es necesario que tengamos en cuenta los conceptos de reentrante y de seguridad de hilos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Una función<sup class="footnote">[<a id="_footnoteref_4" class="footnote" href="#_footnotedef_4" title="View footnote.">4</a>]</sup> es <strong>reentrante</strong> si puede ser interrumpida en medio de su ejecución y mientras espera puede volver a ser llamada con total seguridad</em>.
Obviamente las funciones recursivas deben ser reentrantes para poder llamarse a sí mismas una y otra vez con total seguridad.
+ En el contexto de la programación multihilo ocurre una reentrada cuando, durante la ejecución de una función por parte de un hilo, este es interrumpido por el sistema operativo para planificar posteriormente a otro del mismo proceso que invoca la misma función.
En general una función es reentrante si:</p>
<div class="ulist">
<ul>
<li>
<p>No modifica variables estáticas o globales.
Si lo hiciera sólo puede hacerlo mediante operaciones <em>leer-modificar-escribir</em> que sean ininterrumpibles —es decir, atómicas—.</p>
</li>
<li>
<p>No modifica su propio código y no llama a otras funciones que no sean reentrantes.</p>
</li>
</ul>
</div>
</li>
<li>
<p><em>Una función es <strong>segura en hilos</strong> o <strong>thread-safe</strong> si al manipular estructuras compartidas de datos lo hace de tal manera que se garantiza la ejecución segura de la misma por múltiples hilos al mismo tiempo</em>.
Obviamente estamos hablando de un problema de secciones críticas, por lo que se resuelven sincronizando el acceso a estos datos mediante el uso de semáforos, <em>mutex</em> u otros recursos similares ofrecidos por el sistema operativo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En ocasiones ambos conceptos se confunden porque es bastante común que el código reentrante también sea seguro en hilos.
Sin embargo es posible crear código reentrante que no sea seguro en hilos y viceversa.
Por ejemplo, una función que manipule <em>datos específicos de hilo</em> seguramente no será reentrante aunque si segura en hilos.
Mientras que una función que sólo utilice variables locales y que no invoque a otras funciones seguramente será reentrante y segura en hilos.</p>
</div>
</div>
<div class="sect3">
<h4 id="_las_llamadas_al_sistema_fork_y_exec_en_procesos_multihilo">12.3.4. Las llamadas al sistema fork() y exec() en procesos multihilo</h4>
<div class="paragraph">
<p>¿Qué debe ocurrir si un hilo de un proceso multihilo ejecuta la llamada <code>fork()</code>?:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>¿El nuevo proceso debe duplicar todos los hilos?.</p>
</li>
<li>
<p>¿O el nuevo proceso debe tener un único hilo copia del que invocó a <code>fork()</code>?.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Como hemos comentado anteriormente la llamada al sistema <code>exec()</code> sustituye el programa en ejecución con el programa indicado y este inicia su ejecución en <code>main()</code>.
Esto incluye liberar toda la memoria reservada y la destrucción de todos los hilos del programa original, por lo que duplicar los hilos en el proceso hijo creado por <code>fork()</code> parece algo innecesario.</p>
</div>
<div class="paragraph">
<p>El estándar POSIX establece que si se utiliza <code>fork()</code> en un programa multihilo, el nuevo proceso debe ser creado con un sólo hilo, que será una réplica del que hizo la llamada, así como un duplicado completo del espacio de direcciones del proceso.
Sin embargo algunos sistemas UNIX tienen una segunda llamada no estándar, denominada <code>forkall()</code>, capaz de duplicar todos los hilos del proceso padre.
Obviamente sólo resulta conveniente emplearla si no se va a utilizar la llamada <code>exec()</code> a continuación.</p>
</div>
</div>
<div class="sect3">
<h4 id="_manejo_de_señales_en_procesos_multihilo">12.3.5. Manejo de señales en procesos multihilo</h4>
<div class="paragraph">
<p>Una señal se utiliza en UNIX para informar a un proceso cuando un evento a ocurrido.
Existen dos tipos de señales:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Las <em><strong>señales síncronas</strong> se deben a alguna acción del propio proceso</em>.
Ejemplos de señales de este tipo son las originadas por accesos ilegales a memoria o divisiones por 0.
Las señales síncronas son enviadas al mismo proceso que las origina.</p>
</li>
<li>
<p>Las <em><strong>señales asíncronas</strong> son debidas a procesos externos</em>.
Un ejemplo de este tipo de señales es la terminación de procesos con teclas especiales como <span class="keyseq"><kbd>CTRL</kbd>+<kbd>C</kbd></span> o <kbd>CTRL-D</kbd></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Las señales que llegan a un proceso pueden ser interceptadas por una función definida por el programador —que se denominada <em>manejador de señal</em>-.
En caso de que esta función no haya sido definido, se utiliza un manejador por defecto cuya acción depende del tipo de evento.</p>
</div>
<div class="paragraph">
<p>La pregunta entonces es: ¿cuándo se tienen múltiples hilos cuál de ellos debe ser interrumpido para que ejecute el manejador de señales?</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Obviamente las señales síncronas, por su propia naturaleza, deben ser enviadas al hilo que las genera.</p>
</li>
<li>
<p>Con las señales asíncronas —las que vienen de fuentes externas— la cosa no está tan clara.
Dependiendo del caso algunas deben ser capturadas por un sólo hilo, mientras que otras —como aquellas que ordenan terminar el proceso— deberían ser enviadas a todos para que sepan lo que va a ocurrir.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>La mayor parte de los UNIX multihilo permiten especificar qué señales acepta cada hilo y cuáles no.
Por lo tanto una señal asíncrona sólo será entregada a aquellos hilos que no la bloquean.
Puesto que generalmente las señales necesitan ser manejadas una sola vez, normalmente sólo llegan al primer hilo al que se le asigna la CPU y que no las esté bloqueando.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_sincronización">13. Sincronización</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Hemos comentado anteriormente que los hilos comparten el espacio de direcciones del proceso al que pertenecen.
Al mismo tiempo distintos procesos pueden compartir regiones de la memoria con el objeto de cooperar en las tareas que deben desempeñar.
Ambas posibilidades introducen algunos riesgos, puesto que el acceso concurrente a los datos compartidos puede ocasionar inconsistencias.
En este apartado vamos a discutir <em>cómo se puede asegurar la ejecución ordenada de hilos o procesos cooperativos que comparten regiones de la memoria, con el fin de mantener la consistencia de los datos</em>.</p>
</div>
<div class="sect2">
<h3 id="_el_problema_de_las_secciones_críticas">13.1. El problema de las secciones críticas</h3>
<div class="paragraph">
<p><em>Llamamos <strong>condición de carrera</strong> a la situación donde varios procesos o hilos pueden acceder y manipular los mismos datos concurrentemente, y donde el resultado de la ejecución depende del orden particular en el que tienen lugar dichos accesos</em>.
Estas situaciones ocurren frecuentemente en los sistemas operativos puesto que diferentes componentes del mismo manipulan los mismos recursos interfiriendo unos con otros.</p>
</div>
<div class="paragraph">
<p>Para ilustrarlo, supongamos que dos hilos comparten una región de la memoria que contiene un vector de elementos y un contador con el número de elementos del vector:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>El primer hilo realiza varias tareas que no entraremos a describir.
Sin embargo, como resultado de esas tareas en ocasiones añade un elemento al vector e incrementa el contador que indica el número de elementos en el vector.
Es decir, el primer hilo actúa como un <strong>productor</strong> de elementos del vector.
A continuación mostramos una porción de la función del productor:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">while</span> <span class="p">(</span><span class="n">count</span> <span class="o">==</span> <span class="n">VECTOR_SIZE</span><span class="p">);</span>

<span class="c1">// añadir un elemento al vector</span>
<span class="n">vector</span><span class="p">[</span><span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">item</span><span class="p">;</span>
<span class="o">++</span><span class="n">count</span><span class="p">;</span></code></pre>
</div>
</div>
</li>
<li>
<p>El segundo hilo también realiza varias tareas que no describiremos.
Pero para realizar esas tareas en ocasiones debe tomar un elemento del vector compartido y decrementar el contador, porque ahora habrá un elemento menos en el vector.
Es decir, el segundo hilo actúa como un <strong>consumidor</strong> de elementos del vector.
A continuación mostramos una porción de la función del consumidor:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">while</span> <span class="p">(</span><span class="n">count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>

<span class="c1">// quitar un elemento del vector</span>
<span class="o">--</span><span class="n">count</span><span class="p">;</span>
<span class="n">item</span> <span class="o">=</span> <span class="n">vector</span><span class="p">[</span><span class="n">count</span><span class="p">];</span></code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Aunque las funciones del productor y del consumidor son correctas cuando no coinciden en el tiempo, no funcionan adecuadamente cuando si lo hacen.
El motivo es que los distintos hilos comparten la variable <code>count</code> y las sentencias <code>count` y `--count` no tiene porque tener una instrucción en lenguaje máquina equivalente.
Por ejemplo, `count</code> podría ser traducida de la siguiente manera por el compilador:</p>
</div>
<div class="listingblock">
<div class="title">++count</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">registro1</span> <span class="o">=</span> <span class="n">count</span><span class="p">;</span>
<span class="n">registro1</span> <span class="o">=</span> <span class="n">registro1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">registro1</span><span class="p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>registro1</code> representa un registro de la CPU.
De forma parecida la sentencia <code>--count</code> puede ser implementada de la siguiente manera:</p>
</div>
<div class="listingblock">
<div class="title">--count</div>
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">registro2</span> <span class="o">=</span> <span class="n">count</span><span class="p">;</span>
<span class="n">registro2</span> <span class="o">=</span> <span class="n">registro2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">registro2</span><span class="p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde nuevamente <code>registro2</code> representa un registro de la CPU.
Realmente, aunque <code>registro1</code> y <code>registro2</code> pueden ser el mismo registro físico, el contenido de los registros se guarda y se recupera durante los cambios de contexto de un hilo al otro, por lo que cada uno ve sus propios valores y no los del otro.</p>
</div>
<div class="paragraph">
<p>La ejecución concurrente de las sentencias <code>++count</code> y <code>--count</code> es similar a la ejecución secuencial, pero las instrucciones de lenguaje máquina de ambas sentencias en ambos hilos o procesos pueden ser entrelazadas en algún orden aleatorio.
No olvidemos que la ejecución concurrente se puede dar bien porque:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Tenemos un sistema multiprocesador, donde ambos hilos se ejecutan a la vez en procesadores diferentes.</p>
</li>
<li>
<p>O bien porque tenemos un sistema monoprocesador, donde uno de los hilos puede ser interrumpido por el sistema operativo en cualquier momento (véase el <a href="#_planificación_expropiativa">Apartado 14.1</a>) para asignar la CPU al otro.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Un posible entrelazado de las instrucciones en lenguaje máquina entre hilos, suponiendo que inicialmente <code>count = 5</code>, podría ser el siguiente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="c1">// Entra ++count</span>
<span class="n">registro1</span> <span class="o">=</span> <span class="n">count</span><span class="p">;</span>          <span class="c1">// registro1 = 5</span>
<span class="n">registro1</span> <span class="o">=</span> <span class="n">registro1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>  <span class="c1">// registro1 = 6</span>
<span class="c1">// Sale ++count y entra --count</span>
<span class="n">registro2</span> <span class="o">=</span> <span class="n">count</span><span class="p">;</span>          <span class="c1">// registro2 = 5</span>
<span class="n">registro2</span> <span class="o">=</span> <span class="n">registro2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>  <span class="c1">// registro2 = 4</span>
<span class="c1">// Sale --count y entra ++count</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">registro1</span><span class="p">;</span>          <span class="c1">// count = 6 </span><i class="conum" data-value="2"></i><b>(2)</b>
<span class="c1">// Entra --count</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">registro2</span><span class="p">;</span>          <span class="c1">// count = 4 </span><i class="conum" data-value="1"></i><b>(1)</b> <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Llegamos al resultado incorrecto <code>count = 4</code>, indicando que hay 4 elementos en el vector cuando realmente hay 5.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Si invertimos el orden de las sentencias obtendríamos el resultado, también incorrecto, <code>count = 6</code>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Como se puede apreciar, hemos llegado a estos valores incorrectos porque hemos permitido la manipulación concurrente de la variable <code>count</code>.
Según como se entrelacen las instrucciones de <code>++count</code> y <code>--count</code> en la CPU, el resultado final podría ser: 4, 5 o 6.
Pero el único resultado correcto es 5, que es el que obtendríamos si ejecutamos las sentencias secuencialmente.</p>
</div>
<div class="paragraph">
<p>Para evitar que estas situaciones lleven a la corrupción de los datos y a caídas de servicios y sistemas debemos asegurarnos que sólo un hilo en cada momento puede manipular recursos y variables compartidas.
Por tanto, necesitamos algún tipo de mecanismo de sincronización para que mientras se ejecuta <code>++count</code> no se pueda ejecutar <code>--count</code> ni viceversa.</p>
</div>
<div class="paragraph">
<p>Una forma de controlar el acceso a los recursos compartidos es definiendo en nuestro código <em>secciones críticas</em>.
Una <strong>sección crítica</strong> es una porción del código dónde se accede a variables, tablas, listas, archivos y otros recursos compartidos que no deben ser accedidos al mismo tiempo por otros hilos de ejecución.
El acceso a las secciones críticas es controlado de manera que <em>cuando un hilo se esté ejecutando en una sección de este tipo ningún otro pueda hacerlo en la suya correspondiente para manipular los mismos recursos</em>.
En estos casos se dice que la ejecución es <em>mutuamente exclusiva</em> en el tiempo.</p>
</div>
</div>
<div class="sect2">
<h3 id="_semáforos_mutex_y_spinlocks">13.2. Semáforos, <em>mutex</em> y <em>spinlocks</em></h3>
<div class="paragraph">
<p>La exclusión mutua en las secciones críticas se asegura utilizando adecuadamente una serie de recursos que para ese fin proporciona el sistema operativo.
Estos recursos utilizan internamente instrucciones y otras características de la CPU incluidas por los diseñadores para resolver este tipo de problemas.
Ese es el caso de los <em>semáforos</em>.</p>
</div>
<div class="paragraph">
<p><em>Los <strong>semáforos</strong> son un tipo de objetos del sistema operativo que nos permite controlar el acceso a una sección crítica</em>, por medio de dos primitivas: <code>wait()</code> y <code>signal()</code> —o <code>acquire()</code> y <code>release()</code>, según el libro de texto—.
A continuación describimos el mecanismo de funcionamiento:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="cpp"><span class="n">semaphore</span> <span class="nf">S</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>    <i class="conum" data-value="1"></i><b>(1)</b>

<span class="n">S</span><span class="p">.</span><span class="n">wait</span><span class="p">()</span>            <i class="conum" data-value="2"></i><b>(2)</b>

 <span class="p">...</span>                <i class="conum" data-value="3"></i><b>(3)</b>

<span class="n">S</span><span class="p">.</span><span class="n">signal</span><span class="p">();</span>         <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Crear el semáforo <code>S</code> inicializado a 10. Un semáforo contiene fundamentalmente un contador con el número máximo de hilos que pueden estar ejecutando el código de la sección crítica al mismo tiempo. Los semáforos con contadores inicializados a 1 se denominan <strong>mutex</strong> o <strong>semáforos binarios</strong>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Intentar entrar en la sección crítica:
<div class="ulist">
<ul>
<li>
<p>Si el contador interno del semáforo es mayor que 0, <code>wait()</code> lo decrementa y retorna para que la ejecución continue.</p>
</li>
<li>
<p>Si el contador interno del semáforo es igual a 0, <code>wait()</code> saca al hilo de la CPU y lo pone en una cola de espera, suspendiendo así su ejecución. Básicamente, hay demasiados hilos dentro de la sección crítica.</p>
</li>
</ul>
</div></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Código protegido con el semáforo. Aquí iría el código de la sección crítica en sí.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Salir de la sección crítica:
<div class="ulist">
<ul>
<li>
<p>Si el contador interno del semáforo es mayor que 0, <code>signal()</code> lo incrementa y retorna para que la ejecución continue.</p>
</li>
<li>
<p>Si el contador interno del semáforo es igual a 0, <code>signal()</code> lo incrementa y saca a uno de los hilos en la cola de espera, donde los puso <code>wait()</code>, para meterlo en la cola de preparados, dejándolo listo para entrar en la CPU. Cuando ocurra, ese hilo decrementará el contador interno del semáforo y saldrá de <code>wait()</code>, donde hasta a hora estaba atrapado. Mientras tanto <code>signal()</code> retorna y la ejecución del hilo que sale del sección crítica continua.</p>
</li>
</ul>
</div></td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Para que funcione correctamente, el semáforo S debe ser el mismo para todos los hilos que tengan secciones críticas cuya ejecución deber ser <em>mutuamente exclusiva</em>. Es decir, el semáforo S debe estar compartido entre los hilos de la misma manera que las estructuras de datos, variables y otros recursos que protege.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Como hemos comentado anteriormente la implementación del <code>wait()</code> y el <code>signal()</code> del semáforo debe realizarse utilizando las características proporcionadas por el hardware, de forma que el incremento, decremento y comparación del contador interno se pueda realizar de forma atómica<sup class="footnote">[<a id="_footnoteref_5" class="footnote" href="#_footnotedef_5" title="View footnote.">5</a>]</sup>.</p>
</div>
<div class="paragraph">
<p>Por otro lado existen dos alternativas desde el punto de vista de la forma en la que se implementa la espera de los hilos dentro de <code>wait()</code>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>El hilo puede cambiar su estado a esperado y moverse a una cola de espera asociada al semáforo</em>, tal y como explicamos antes.
Entonces el planificador de la CPU escogerá a otro proceso para ser ejecutado.</p>
</li>
<li>
<p><em>El hilo puede iterar comprobado constantemente el contador, esperando a que sea incrementado</em>.
Este tipo de <strong>espera ocupada</strong> sólo se utiliza en el caso de esperas previsiblemente cortas, puesto que se desperdician ciclos de CPU que otro hilo podría utilizar de forma más productiva.
Por eso, para evitar que las esperas ocupadas sean demasiado largas, los sistema operativos nunca expulsan de la CPU (véase el <a href="#_planificación_expropiativa">Apartado 14.1</a>) a hilos que se estén ejecutando dentro de secciones críticas controladas por semáforos con este tipo de espera.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A estos semáforos con <strong>espera ocupada</strong> también se los denomina <strong>spinlocks</strong>.
Los <strong>spinlocks</strong> son utilizados frecuentemente para proteger las estructuras del núcleo en los sistemas multiprocesador, cuando la tarea a realizar dentro de la sección crítica en el núcleo requiere poco tiempo y es mayor el tiempo de CPU que se pierde si se saca al hilo en espera para ejecutar otro en su lugar.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_planificación_de_la_cpu">14. Planificación de la CPU</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>El <strong>planificador de la CPU</strong> o <strong>planificador de corto plazo</strong> selecciona de la cola de preparados el siguiente proceso o hilo del núcleo a ejecutar</em>.
En dicha cola suelen estar los PCB de todos los procesos que esperan una oportunidad para usar la CPU.
Aunque se suelen pensar en la cola de preparados como una cola FIFO, como veremos más adelante, no tiene por qué ser así.
En cualquier caso, sea cual sea el algoritmo de planificación utilizado, éste no debe ser excesivamente lento ya que es ejecutado con mucha frecuencia; aproximadamente una vez cada 100 milisegundos.</p>
</div>
<div class="paragraph">
<p><strong>Aunque a lo largo de este tema hablaremos de planificar procesos en la CPU, en los sistemas operativos multihilo se planifican los hilos de núcleo y no los procesos</strong>.
Por ello todo lo que comentemos a partir de ahora se aplica de la misma manera a los hilos de núcleo, en aquellos sistemas operativos que los soportan.</p>
</div>
<div class="sect2">
<h3 id="_planificación_expropiativa">14.1. Planificación expropiativa</h3>
<div class="paragraph">
<p>Las decisiones de planificación <em>se deben tomar necesariamente</em> en los siguientes casos:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Cuando un proceso pasa de <strong>ejecutando</strong> a <strong>esperando</strong></em>.
Por ejemplo, por solicitar una operación de E/S, esperar a que un hijo termine, etc.</p>
</li>
<li>
<p><em>Cuando un proceso termina</em>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Cuando el planificador es invocado en alguno de los casos anteriores decimos que tenemos un sistema operativo con <strong>planificación cooperativa</strong> o <strong>no expropiativa</strong>.</p>
</div>
<div class="paragraph">
<p>En la planificación cooperativa cuando la CPU es asignada a un proceso, dicho proceso la acapara hasta terminar o pasar al estado de <em>esperando</em>.
La planificación cooperativa no requiere de ningún hardware especial, por lo que en algunas plataformas puede ser la única opción.
Por ello estaba presente en los sistemas operativos más antiguos, como Microsoft Windows 3.1 y Mac OS.</p>
</div>
<div class="paragraph">
<p>Sin embargo, las decisiones de planificación <em>también pueden ser tomadas en otros casos</em>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Cuando ocurre una interrupción del temporizador</em>.</p>
</li>
<li>
<p><em>Cuando un proceso pasa de <strong>esperando</strong> a <strong>preparado</strong></em>.
Por ejemplo porque para un proceso ha terminado la operación de E/S por la que estaba esperando.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Cuando el planificador es invocado en los cuatro casos decimos que tenemos planificación <strong>expropiativa</strong> o <strong>apropiativa</strong>.
La planificación expropiativa si requiere de un soporte adecuado por parte del hardware, por lo que se utiliza en la mayor parte de los sistemas operativos modernos.
Ejemplos de estos sistemas son Microsoft Windows 9x/NT/2000/XP, macOS, GNU/Linux y los UNIX modernos.</p>
</div>
<div class="paragraph">
<p>La utilización de un planificador expropiativo introduce algunas dificultades adicionales:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Puesto que un proceso puede ser expropiado en cualquier momento, el sistema operativo debe proporcionar <em>mecanismos de sincronización</em> (véase el <a href="#_sincronización">Capítulo 13</a>) para coordinar el acceso a datos compartidos que podrían estar siendo modificados por el proceso que abandona la CPU.</p>
</li>
<li>
<p>¿Qué pasa si un proceso va a ser expropiado cuando se está ejecutando una llamada al sistema? No debemos olvidar que generalmente dentro del núcleo se manipulan datos importantes que deben permanecer consistentes en todo momento.
Para resolver esta cuestión los diseñadores pueden optar por <em>impedir la expropiación dentro del núcleo</em>.
Es decir, antes de hacer el cambio de contexto, que sacaría al proceso de la CPU, se espera a que la llamada se complete o se bloquee pasando el proceso al estado de <em>esperando</em>.
Esto permite núcleos simples y garantiza que las estructuras del mismo permanezcan consistentes, pero es un modelo pobre en sistemas de tiempo real o multiprocesador.
Exploraremos otras soluciones más adelante (véase el <a href="#_planificación_de_tiempo_real">Apartado 14.6</a>).</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_el_asignador">14.2. El asignador</h3>
<div class="paragraph">
<p><em>El <strong>asignador</strong> es el componente que da el control de la CPU al proceso seleccionado por el planificador de corto plazo</em>.
Esta tarea implica realizar las siguientes funciones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cambiar el contexto.</p>
</li>
<li>
<p>Cambiar al modo usuario.</p>
</li>
<li>
<p>Saltar al punto adecuado del programa para continuar con el proceso.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Puesto que el <em>asignador</em> es invocado para cada conmutación entre procesos, es necesario que el tiempo que tarda en detener un proceso e iniciar otro sea lo más corto posible.
<em>Al tiempo que transcurre desde que un proceso es escogido para ser planificado en la CPU hasta que es asignado a la misma se lo denomina <strong>latencia de asignación</strong></em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_criterios_de_planificación">14.3. Criterios de planificación</h3>
<div class="paragraph">
<p>Los diferentes algoritmos de planificación de la CPU tienen diversas propiedades que pueden favorecer a una clase de procesos respecto a otra.
Por ello es interesante disponer de algún criterio para poder comparar dichos algoritmos y determinar cual es el mejor.
Se han sugerido muchos criterios para comparar los algoritmos de planificación de CPU pero la elección de uno u otro puede crear una diferencia sustancial a la hora de juzgar cual es el mejor.
A continuación presentamos los criterios más comunes.</p>
</div>
<div class="sect3">
<h4 id="_criterios_a_maximizar">14.3.1. Criterios a maximizar</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Uso de CPU</strong>: Un buen <em>planificador debería mantener la CPU lo más ocupada posible</em>.
El uso de CPU es la proporción de tiempo que se usa la CPU en un periodo de tiempo determinado.
Se suele indicar en tanto por cierto.</p>
<div class="stemblock">
<div class="content">
\$bb "uso de CPU" = "tiempo que la CPU permanece ocupada" / "tiempo durante el que se toma la medida" "%"\$
</div>
</div>
</li>
<li>
<p><strong>Tasa de procesamiento</strong>: Cuando la CPU está ocupada es porque el trabajo se está haciendo.
Por tanto <em>una buena medida del volumen de trabajo realizado puede ser el número de tareas o procesos terminados por unidad de tiempo.
_A dicha magnitud es a la que denominamos como _tasa de procesamiento</em>.</p>
<div class="stemblock">
<div class="content">
\$bb "tasa de procesamiento" = "numero de procesos terminados" / "tiempo durante el que se toma la medida" "procesos/s"\$
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_criterios_a_minimizar">14.3.2. Criterios a minimizar</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Tiempo de ejecución</strong>: Es el <em>intervalo de tiempo que transcurre desde que el proceso es cargado hasta que termina</em>.</p>
</li>
<li>
<p><strong>Tiempo de espera</strong>: Es la <em>suma de tiempos que el proceso permanece a la espera en la cola de preparados</em>.
Evidentemente esta medida de tiempo no incluye el tiempo de espera debido a las operaciones de E/S.</p>
</li>
<li>
<p><strong>Tiempo de respuesta</strong>: Es <em>el intervalo de tiempo que transcurre desde que se le lanza un evento —se pulsa una tecla, se hace clic con el ratón o llega un paquete por la interfaz de red— hasta que se produce la primera respuesta del proceso</em>.
Evidentemente esto mide el tiempo que se tarda en responder y no el tiempo de E/S, mientras que el tiempo de ejecución sí suele estar limitado por la velocidad de los dispositivos E/S.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_elección_del_criterio_adecuado">14.3.3. Elección del criterio adecuado</h4>
<div class="paragraph">
<p>En función del tipo de sistema o de la clase de trabajos que se van a ejecutar puede ser conveniente medir la eficiencia del sistema usando un criterio u otro.
Esto a su vez beneficiará a unos algoritmos de planificación frente a otros, indicándonos cuáles son los más eficientes para nuestra clase de trabajos en particular.</p>
</div>
<div class="paragraph">
<p>En general podemos encontrar dos clases de trabajos para los que puede ser necesario evaluar la eficiencia del sistema de manera diferente.:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>En los sistemas interactivos —ya sean sistemas de escritorio o <em>mainframes</em> de tiempo compartido— los procesos pasan la mayor parte del tiempo esperando algún tipo de entrada por parte de los usuarios.
En este tipo de sistemas el tiempo de ejecución no suele ser el mejor criterio para determinar la bondad de un algoritmo de planificación, ya que vendrá determinado en gran medida por la velocidad de la entrada de los usuarios.
Por el contrario se espera que el sistema reaccione lo antes posible a las órdenes recibidas, lo que hace que <em>el tiempo de respuesta se el criterio más adecuado</em> para evaluar al planificador de la CPU.
Además el tiempo de respuesta se reduce generalmente cuando el tiempo que pasan los procesos interactivos en la cola de preparados también lo hace —tras haber sido puestos ahí por la ocurrencia de algún evento— por lo que también <em>puede ser una buena idea utilizar como criterio el tiempo de espera</em>.
Esta selección de criterios no sólo es adecuada para los sistemas interactivos, ya que existen muchos otros casos donde es interesante seleccionar un planificador de la CPU que minimice el tiempo de respuesta.
Esto por ejemplo ocurre con algunos servicios en red como: sistemas de mensajería instantánea, chats, servidores de videojuegos, etc.</p>
</li>
<li>
<p>Por el contrario en los <em>mainframes</em> de procesamiento por lotes y multiprogramados, en los superordenadores que realizan complejas simulaciones físicas y en los grandes centros de datos de proveedores de Internet como Google, lo de menos es el tiempo de respuesta y lo realmente importante es realizar cada tarea en el menor tiempo posible.
Por eso en ese tipo de sistemas <em>es aconsejable utilizar criterios tales como el tiempo de ejecución o la tasa de procesamiento</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Obviamente estos criterios varían de un proceso a otro, por lo que normalmente lo que se busca es optimizar los valores promedios en el sistema.
Sin embargo no debemos olvidar que <em>en muchos casos puede ser más conveniente optimizar el máximo y mínimo de dichos valores antes que el promedio</em>.
Por ejemplo, en los sistemas interactivos es más importante minimizar la varianza en el tiempo de respuesta que el tiempo de respuesta promedio, puesto que para los usuarios un sistema con un tiempo de respuesta predecible es más deseable que uno muy rápido en promedio pero con una varianza muy alta.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ciclo_de_ráfagas_de_cpu_y_de_es">14.4. Ciclo de ráfagas de CPU y de E/S</h3>
<div class="paragraph">
<p>El éxito de la planificación de CPU depende en gran medida de la siguiente propiedad que podemos observar en los procesos: <em>La ejecución de un proceso consiste de ciclos de CPU y esperas de E/S, de forma que alternan entre estos dos estados.
La ejecución empieza con una ráfaga de CPU, seguida por una ráfaga de E/S, que a su vez es seguida por otra de CPU y así sucesivamente.
Finalmente la última ráfaga de CPU finaliza con una llamada al sistema —generalmente exit()— para terminar la ejecución del proceso</em>.</p>
</div>
<div class="paragraph">
<p>La curva que relaciona la frecuencia de las ráfagas de CPU con la duración de las mismas tiende a ser exponencial o hiper-exponencial (véase la ) aunque varía enormemente entre procesos y sistemas informáticos distintos.
Esto significa que los procesos se pueden clasificar entre aquellos que presentan un gran número de ráfagas de CPU cortas o aquellos con un pequeño número de ráfagas de CPU largas.
Concretamente:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Decimos que un <em>proceso es <strong>limitado por la E/S</strong> cuando presenta muchas ráfagas de CPU cortas, debido a que si es así pasa la mayor parte del tiempo esperando por la E/S</em>.</p>
</li>
<li>
<p>Decimos que un <em>proceso está <strong>limitado por la CPU</strong> cuando presenta pocas ráfagas de CPU largas, debido a que si es así hace un uso intensivo de la misma y a penas pasa tiempo esperando por la E/S</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Esta distinción entre tipos de procesos puede ser importante en la selección de un algoritmo de planificación de CPU adecuado.
En general:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>El algoritmo escogido debe favorecer —planificándolos antes— a los procesos limitados por la E/S</em>, evitando así que los procesos limitados por la CPU —que son los que tienden a usarla más tiempo— la acaparen.
Si eso ocurriera, los procesos limitados por la E/S se acumularían en la cola de preparados, dejando vacías las colas de dispositivos.
A este <em>fenómeno tan negativo que provoca una infrautilización de los dispositivos de E/S se lo denomina <strong>efecto convoy</strong></em>.</p>
</li>
<li>
<p>Además planificar primero a los procesos limitados por la E/S tiene dos efectos muy positivos:</p>
<div class="ulist">
<ul>
<li>
<p><em>Los procesos interactivos son generalmente procesos limitados por la E/S, por lo que planificarlos primero hace que mejore el tiempo de respuesta</em>.</p>
</li>
<li>
<p><em>Generalmente el tiempo de espera promedio se reduce cuando se planifican primero los procesos con ráfagas de CPU cortas</em><sup class="footnote">[<a id="_footnoteref_6" class="footnote" href="#_footnotedef_6" title="View footnote.">6</a>]</sup>, Según las definiciones anteriores, estos procesos son precisamente los limitados por la E/S.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_planificación">14.5. Planificación</h3>
<div class="paragraph">
<p>Hasta el momento hemos considerado la cola de preparados como una estructura donde los procesos que están preparados para ser ejecutados se ordenan y se escogen según el criterio del algoritmo de planificación.
Aunque a lo largo de todo el tema <a href="#_gestión_de_procesos">Apartado 4.1</a> se puede haber intuido que dicha cola es de tipo FIFO —lo que se conoce como algoritmo de planificación FCFS o <em>First Come, First Served</em>— ya al principio del <a href="#_planificación_de_la_cpu">Capítulo 14</a> indicamos que no tiene porqué ser así pues existen muchos otros algoritmos —SJF o <em>Shortest-Job First</em>, SRTF o <em>Shortest-Remaing-Time First</em>, RR o <em>Round-Robin</em>, por prioridades, etc.— que pueden ser preferibles en función del criterio que utilicemos para evaluar la eficiencia de los mismos.</p>
</div>
<div class="paragraph">
<p>Sin embargo en los sistemas operativos modernos realmente las cosas son un poco más complejas ya que generalmente se utiliza algún tipo de <strong>planificación con colas multinivel</strong>.
<em>En este tipo de planificación _no existe una única cola de preparados sobre la que se utiliza un único algoritmo de planificación sino que</em>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>La cola de preparados se divide en varias colas separadas</em> y los procesos son asignados a alguna de dichas colas en base a características de los mismos.</p>
</li>
<li>
<p><em>Cada cola puede tener un algoritmo de planificación de la CPU distinto</em>.
Es decir, alguno de los que hemos mencionado anteriormente y que se estudiarán en las clases de problemas.</p>
</li>
<li>
<p><em>Mediante un algoritmo determinado se debe seleccionar la cola que debe escoger al siguiente proceso a ejecutar.</em></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Precisamente una cuestión interesante es la indicada en éste último punto ¿cómo seleccionar la cola que debe escoger al siguiente proceso que debe ser ejecutado?.</p>
</div>
<div class="sect3">
<h4 id="_prioridad_fija">14.5.1. Prioridad fija</h4>
<div class="paragraph">
<p>Aunque existen muchas maneras de clasificar los procesos entre las diferentes colas, lo más común en los sistemas operativos modernos es hacerlo en base a la prioridad de los procesos (véase la ):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>A cada proceso se le asigna una prioridad</em>.</p>
</li>
<li>
<p><em>En la cola de preparados hay una cola para cada nivel de prioridad</em>.</p>
</li>
<li>
<p><em>Los procesos, al entrar en la cola de preparados, son insertados en aquella cola que coincide con su prioridad</em>.</p>
</li>
<li>
<p><em>El planificador escoge primero siempre la cola de prioridad más alta que no esté vacía</em>.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_definición_de_las_prioridades">Definición de las prioridades</h5>
<div class="paragraph">
<p>Las prioridades se suelen indicar con números enteros en un rango fijo.
Por ejemplo [0-7], [0-31], [0-139] o [0-4095].
En algunos sistemas operativos los números más grandes representan mayor prioridad, mientras que en otros son los procesos con números más pequeños los que se planifican primero.
<em>En éste curso utilizaremos la convención de que a menor valor mayor prioridad</em>.</p>
</div>
<div class="paragraph">
<p>En los sistemas con prioridad fija:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez se asigna una prioridad a un proceso ésta nunca cambia.</p>
</li>
<li>
<p><em>Las prioridades normalmente vienen determinadas por criterios ajenos al sistema operativo</em>.
Por ejemplo: la importancia del proceso, la cantidad de dinero pagada para el uso del sistema u otros factores políticos.
<em>A este tipo de prioridades se las denomina definidas externamente</em>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_planificación_expropiativa_o_cooperativa">Planificación expropiativa o cooperativa</h5>
<div class="paragraph">
<p>La planificación con prioridades puede ser expropiativa o cooperativa.
<em>En el caso expropiativo cuando un proceso llega a la cola de preparados su prioridad es comparada con la del proceso en ejecución, de manera que el segundo es expulsado si la prioridad del primero es superior a la suya</em>.
Obviamente en la planificación cooperativa los nuevos procesos simplemente son insertados en la cola que les corresponde en base a su prioridad, independientemente de si tienen o no mayor prioridad que el que se esté ejecutando.</p>
</div>
</div>
<div class="sect4">
<h5 id="_planificación_entre_procesos_con_la_misma_prioridad">Planificación entre procesos con la misma prioridad</h5>
<div class="paragraph">
<p>Cada cola en cada nivel de prioridad puede tener cualquier algoritmo de planificación de CPU, lo que virtualmente significa que el abanico de posibilidad es muy amplio.
Sin embargo lo más común es que los diseñadores del sistema opten por utilizar o bien el planificador FCFS o bien el RR<sup class="footnote">[<a id="_footnoteref_7" class="footnote" href="#_footnotedef_7" title="View footnote.">7</a>]</sup>.</p>
</div>
<div class="paragraph">
<p>En la planificación <strong>FCFS</strong> (<em>First Come, First Served</em>) o <em>primero que llega, primero servido</em> la cola es FIFO:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Los procesos que llegan se colocan al final de la cola que les corresponde</em>.</p>
</li>
<li>
<p><em>El proceso asignado a la CPU se coge siempre del principio de la cola seleccionada</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El algoritmo <strong>RR</strong> (<em>Round-Robin</em>) es similar al FCFS pero utilizando el temporizador para expropiar la CPU a los procesos a intervalos regulares, alternando así entre ellos de manera que se da a todos los procesos la oportunidad de ejecutarse.
Como se puede intuir, fue diseñado para los sistemas de tiempo compartido, siendo ampliamente utilizado en cualquier sistema operativo de propósito general moderno.</p>
</div>
<div class="paragraph">
<p>El algoritmo RR requiere los siguientes elementos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Se define una ventana de tiempo o *cuanto*</em>, generalmente entre 10 y 100 ms.</p>
</li>
<li>
<p><em>La cola RR se define como una cola circular dónde el planificador asigna la CPU a cada proceso en intervalos de tiempo de hasta un cuanto</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Cuando se utilizar la planificación RR el tamaño del cuanto es un factor clave en la eficiencia del planificador:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Cuando se reduce el tiempo del cuanto, el tiempo de respuesta y el tiempo de espera promedio tienden a mejorar</em>.
Sin embargo el número de cambios de contexto será mayor, por lo que la ejecución de los procesos será mas lenta.
Además es importante tener en cuenta que interesa que el tiempo del cuanto sea mucho mayor que el tiempo del cambio de contexto; pues si por ejemplo el tiempo del cambio de contexto es un 10% del tiempo del cuanto, entonces alrededor del 10% de CPU se perdería en cambios de contexto.</p>
</li>
<li>
<p><em>Cuando se incrementa el tiempo del cuanto, el tiempo de espera promedio se incrementa</em> dado que entonces el RR tiende a comportarse como un FCFS, que suele tener grandes tiempos de espera promedio.
Además se puede observar experimentalmente que el tiempo de ejecución promedio generalmente mejora cuantos más procesos terminan su próxima ráfaga de CPU dentro del tiempo del cuanto<sup class="footnote">[<a id="_footnoteref_8" class="footnote" href="#_footnotedef_8" title="View footnote.">8</a>]</sup>.
Por lo tanto nos interesan un cuanto grande para que más procesos terminen su siguiente ráfaga dentro del mismo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>La <em>regla general que siguen los diseñadores es intentar que el 80% de las ráfagas de CPU sean menores que el tiempo de cuanto</em>.
Se busca así equilibrar los criterios anteriores, evitando que el tiempo de cuanto sea demasiado grande o demasiado corto<sup class="footnote">[<a id="_footnoteref_9" class="footnote" href="#_footnotedef_9" title="View footnote.">9</a>]</sup>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_muerte_por_inanición_y_otros_inconvenientes">Muerte por inanición y otros inconvenientes</h5>
<div class="paragraph">
<p>El principal problema de este tipo de planificación es el <em>bloqueo indefinido</em> o <strong>muerte por inanición</strong>, puesto que el algoritmo puede dejar a los procesos de baja prioridad esperando indefinidamente si hay un conjunto de procesos de mayor prioridad demandando CPU continuamente.</p>
</div>
<div class="paragraph">
<p>Además, como vimos en el <a href="#_ciclo_de_ráfagas_de_cpu_y_de_es">Apartado 14.4</a>, es conveniente favorecer a los procesos limitados por la E/S frente a los procesos limitados por la CPU para evitar el <em>efecto convoy</em> y para mejorar los tiempos tanto de espera como de respuesta promedio.
Lamentablemente este tipo de planificación con <em>prioridad fija no es capaz de hacerlo ya que la prioridad de los procesos viene determinada exclusivamente por criterios externos al funcionamiento del sistema operativo</em>.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_prioridad_dinámica">14.5.2. Prioridad dinámica</h4>
<div class="paragraph">
<p>La mayor parte de los sistemas operativos modernos de propósito general<sup class="footnote">[<a id="_footnoteref_10" class="footnote" href="#_footnotedef_10" title="View footnote.">10</a>]</sup> <em>solucionan los inconvenientes de la planificación con prioridad fija permitiendo que la prioridad de los procesos se ajuste dinámicamente</em> bajo su propio criterio:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Por ejemplo, <em>una solución al problema de la muerte por inanición es utilizar un mecanismo de <strong>envejecimiento</strong></em> que aumente gradualmente la prioridad de los procesos mientras están esperando en la cola de preparados —por ejemplo 1 nivel de prioridad cada 15 minutos—.
De esta manera los procesos de baja prioridad tarde o temprano tendrán oportunidad de ejecutarse.
Con este mecanismo una vez consiguen ejecutarse, se les restablece su prioridad original.</p>
</li>
<li>
<p><em>Para favorecer en la planificación a los procesos limitados por la E/S el sistema puede añadir o quitar prioridad a los procesos, respecto a su prioridad fija, en función de medidas internas del sistema operativo</em>.
Por ejemplo se puede tomar en consideración: límites de tiempo, necesidades de memoria, número de archivos abiertos, la proporción entre el tiempo de ráfaga de E/S promedio y el de ráfaga de CPU promedio del proceso, etc.
Obviamente el objetivo suele ser mejorar el rendimiento del sistema priorizando unos procesos respecto a otros.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El resultado de estas políticas es que la prioridad que finalmente utiliza el sistema operativo para planificar los procesos en un valor calculado dinámicamente a partir de intereses externos y medidas internas.
Por lo tanto los procesos pueden cambiar múltiples veces de cola durante su tiempo de vida.
<em>A la planificación de múltiples niveles donde los procesos pueden cambiar de una cola a otra se la denomina <strong>planificación con colas multinivel realimentadas</strong></em>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_planificación_por_reparto_proporcional">14.5.3. Planificación por reparto proporcional</h4>
<div class="paragraph">
<p>Hasta el momento hemos hablado de planificadores que se concentran en cuál es el proceso más importante que debe ser ejecutado en cada instante.
Sin embargo otra opción, desde el punto de vista de la planificación ,es repartir el tiempo de CPU entre los procesos a un ritmo controlado.
Esto es precisamente lo que hace <em>la <strong>planificación equitativa</strong> (Fair Scheduling) que intenta repartir por igual el tiempo de CPU entre los procesos de la cola de preparados</em>.
Por ejemplo, si 4 procesos compiten por el uso de la CPU, el planificador asignará un 25%
del tiempo de la misma a cada uno.
Si a continuación un usuario iniciase un nuevo proceso, el planificador tendría que ajustar el reparto asignando un 20% del tiempo a cada uno.
El algoritmo de planificación equitativa es muy similar al algoritmo RR pero, a diferencia de este último en el que se utiliza un cuanto de tamaño fijo, <em>la ventana de tiempo se calcula de dinámicamente para garantizar el reparto equitativo de la CPU</em>.</p>
</div>
<div class="paragraph">
<p>Al igual que en los algoritmos anteriores, en ocasiones puede ser interesante priorizar unos procesos frente a otros, tanto por motivos ajenos al sistema operativo como por motivos internos.
Por ejemplo se puede querer favorecer a los procesos limitados por la E/S para mejorar la eficiencia del sistema, tal y como comentamos en el apartado <a href="#_ciclo_de_ráfagas_de_cpu_y_de_es">Apartado 14.4</a>.
La <em>planificación equitativa</em> resuelve este problema asignando proporcionalmente más tiempo de CPU a los procesos con mayor prioridad.
<em>A esta generalización del planificador equitativo se la conoce como <strong>planificador equitativo ponderado</strong></em><sup class="footnote">[<a id="_footnoteref_11" class="footnote" href="#_footnotedef_11" title="View footnote.">11</a>]</sup>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_de_tiempo_real">14.6. Planificación de tiempo real</h3>
<div class="paragraph">
<p>En el <a href="#_sistemas_de_tiempo_real">Apartado 2.7</a> discutimos la importancia de los sistemas de tiempo real.
A continuación, describiremos las funcionalidades necesarias para soportar la ejecución de procesos en tiempo real dentro de un sistema operativo de propósito general.</p>
</div>
<div class="sect3">
<h4 id="_tiempo_real_estricto">14.6.1. Tiempo real estricto</h4>
<div class="paragraph">
<p>Los sistemas de <strong>tiempo real estricto</strong> son necesarios para realizar tareas críticas que deben ser completadas dentro de unos márgenes de tiempo preestablecidos.
Generalmente las tareas son entregas al sistema operativo junto con una declaración de las restricciones de tiempo —periodicidad y límite de tiempo— y la cantidad de tiempo que necesitan para ejecutarse.
El planificador sólo admitirá las tareas si puede garantizar el cumplimiento de las restricciones de tiempo, rechazándolas en caso contrario.
El proporcionar estas garantías requiere que el planificador conozca exactamente el tiempo máximo que se tarda en realizar todas y cada una de las funciones del sistema operativo.
Esto es imposible en sistemas con almacenamiento secundario o memoria virtual, ya que introducen variaciones no controladas en la cantidad de tiempo necesario para ejecutar una tarea.
Por tanto, el <em>tiempo real estricto no es compatible con los sistemas operativos de propósito general</em>, como los de tiempo compartido.</p>
</div>
</div>
<div class="sect3">
<h4 id="_tiempo_real_flexible">14.6.2. Tiempo real flexible</h4>
<div class="paragraph">
<p>La ejecución de procesos de <strong>tiempo real flexible</strong> es menos restrictiva.
Tan sólo requiere que los procesos críticos reciban mayor prioridad que los que no lo son.
Esto es compatible con los sistemas de tiempo compartido, aunque <em>puede generar excesos en la cantidad de recursos asignados a los procesos de tiempo real, así como inanición y grandes retardos en la ejecución del resto de los procesos</em>.
Sin embargo esto nos permite conseguir sistemas de propósito general que soporten multimedia, videojuegos y otras tareas que no funcionarían de manera aceptable en un entorno que no implementara tiempo real flexible.
Por ello la mayor parte de los sistemas operativos modernos soportan este tipo de tiempo real.</p>
</div>
<div class="paragraph">
<p>Implementar el soporte de tiempo real flexible en un sistema operativo de propósito general requiere:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Sistema operativo con planificación con prioridades.
<em>Los procesos de tiempo real deben tener la mayor prioridad.
Además, no deben ser afectados por ningún mecanismo de envejecimiento o bonificación</em><sup class="footnote">[<a id="_footnoteref_12" class="footnote" href="#_footnotedef_12" title="View footnote.">12</a>]</sup>, que sí puede afectar a los procesos de tiempo no real.</p>
</li>
<li>
<p><em>Baja latencia de asignación</em>.
Cuanto menor es la latencia más rápido comenzará a ejecutarse el proceso de tiempo real después de ser seleccionado por el planificador de la CPU.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Mientras que el primer requerimiento es bastante sencillo de conseguir, el segundo es mucho más complejo.
Muchos sistemas operativos tienen un núcleo no expropiable.
Estos núcleos no pueden realizar un cambio de contexto mientras se está ejecutando código del núcleo —por ejemplo debido a una llamada al sistema— por lo que se ven obligados a esperar hasta que la tarea que se esté realizando se termine antes de asignar la CPU a otro proceso.
Esto aumenta la <em>latencia de asignación</em> dado que algunas llamadas al sistema pueden ser muy complejas y requerir mucho tiempo para ser completadas.
Con el objetivo de resolverlo existen diversas alternativas:</p>
</div>
<div class="sect4">
<h5 id="_puntos_de_expropiación">Puntos de expropiación</h5>
<div class="paragraph">
<p>Una posibilidad es <em>hacer que el código del núcleo sea expropiable</em>.
Esto se consigue introduciendo <strong>puntos de expropiación</strong> en diversos lugares <em>seguros</em> dentro del código.
En dichos puntos se comprueba si algún proceso de prioridad más alta está en la cola de preparados.
En caso de que sea así se expropia la CPU al proceso actual y se le asigna al proceso de más alta prioridad.</p>
</div>
<div class="paragraph">
<p>Debido a la función que realizan los puntos de expropiación, sólo pueden ser colocados en lugares seguros del código del núcleo.
Es decir, sólo pueden estar situados allí donde no se interrumpe la modificación de estructuras de datos.
Sin embargo esto limita el número de puntos que pueden ser colocados, por lo que la latencia de asignación puede seguir siendo muy alta para algunas tareas muy complejas del código del núcleo.</p>
</div>
</div>
<div class="sect4">
<h5 id="_núcleo_expropiable">Núcleo expropiable</h5>
<div class="paragraph">
<p>Otra posibilidad es <em>diseñar un núcleo completamente expropiable</em>.
Puesto que en este caso la ejecución de cualquier tarea en el núcleo puede ser interrumpida en cualquier momento por procesos de mayor prioridad —que el que actualmente tiene asignada la CPU— es necesario proteger las estructuras de datos del núcleo con mecanismos de sincronización, lo que hace que el diseño de un núcleo de estas características sea mucho más complejo.</p>
</div>
<div class="paragraph">
<p>Supongamos que un proceso de baja prioridad es interrumpido, porque hay un proceso de alta prioridad en la cola de preparados, mientras accede a una importante estructura de datos del núcleo.
Durante su ejecución el proceso de alta prioridad podría intentar acceder a la misma estructura que manipulaba el proceso de baja prioridad cuando fue interrumpido.
Debido al uso de mecanismos de sincronización el proceso de alta prioridad tendría que abandonar la CPU a la espera de que el de baja libere el acceso.
Sin embargo este tardará en ser asignado a la CPU mientras haya algún otro proceso de alta prioridad en la cola de preparados.
Además otros procesos puede irse añadiendo a la cola de espera del mecanismo de sincronización que regula el acceso a la estructura de datos del núcleo.
Al hecho de que un proceso de alta prioridad tenga que esperar por uno de baja se le conoce como <strong>inversión de la prioridad</strong>.
Para resolverlo se utiliza un <strong>protocolo de herencia de la prioridad</strong> dónde un proceso de baja prioridad hereda la prioridad del proceso de más alta prioridad que espera por un recurso al que el primero está accediendo.
En el momento en que el proceso de baja prioridad libere el acceso a dicho recurso, su prioridad retornará a su valor original.</p>
</div>
<div class="paragraph">
<p>Linux 2.6, Solaris y Microsoft Windows NT/2000/XP son algunos ejemplos de sistemas operativos con núcleos expropiables.
En el caso concreto de Solaris la latencia de asignación es inferior a 1 ms.
mientras que con la expropiación del núcleo desactivada ésta puede superar los 100 ms.</p>
</div>
<div class="paragraph">
<p>Lamentablemente el <em>conseguir baja latencia de asignación no tiene coste cero</em>.
El hecho de que el núcleo sea expropiable aumenta el número de cambios de contexto, lo que reduce el rendimiento del sistema a cambio de una mejor respuesta.
Por ello resulta muy interesante para aplicaciones de tiempo real, multimedia y sistemas interactivos pero es poco adecuado para servidores y computación de alto rendimiento.
Es por eso que Linux 2.6 permite escoger entre tener un núcleo expropiativo, usar puntos de expropiación o nada de lo anterior.
De esta forma Linux está preparado tanto para servidores como para sistemas de escritorio o de tiempo real.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_en_sistemas_multiprocesador">14.7. Planificación en sistemas multiprocesador</h3>
<div class="paragraph">
<p>Para tratar el problema de la planificación en los sistemas multiprocesador nos limitaremos al caso de los <em>sistemas homogéneos</em><sup class="footnote">[<a id="_footnoteref_13" class="footnote" href="#_footnotedef_13" title="View footnote.">13</a>]</sup>.
En dichos sistemas los procesadores son idénticos, por lo que cualquiera de ellos puede ejecutar cualquier proceso.
Esto es bastante común y simplifica el problema de la planificación.
Aun así no debemos olvidar que incluso en el caso de los sistemas homogéneos pueden aparecer limitaciones en la planificación.
Por ejemplo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Un dispositivo de E/S puede estar conectado mediante un bus privado a un procesador en particular.
En ese caso los procesos que quieren utilizar ese dispositivo deben ejecutarse en dicho procesador.</p>
</li>
<li>
<p>Los procesadores SMT<sup class="footnote">[<a id="_footnoteref_14" class="footnote" href="#_footnotedef_14" title="View footnote.">14</a>]</sup> (<em>Simultaneous Multithreading</em>) permiten la ejecución concurrente de varios hilos como si de varias CPU se tratara.
Sin embargo, al no disponer cada hilo de una CPU completa es posible que algunos deban esperar a que algún otro libere unidades de la CPU que le son necesarias.
Eso debe ser tenido en cuenta por el planificador con el fin de optimizar el rendimiento del sistema.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Al margen de estas cuestiones, existen diversas posibilidades a la hora de enfrentar el problema de la planificación en un sistema multiprocesador:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando utilizamos <strong>multiprocesamiento asimétrico</strong><sup class="footnote">[<a id="_footnoteref_15" class="footnote" href="#_footnotedef_15" title="View footnote.">15</a>]</sup> todas las decisiones de planificación, procesamiento de E/S y otras actividades son gestionadas por un único procesador, el <em>servidor</em> o <em>maestro</em>.
El resto de procesadores se limitan a ejecutar el código de usuarios que les es asignado.
Este esquema <em>es sencillo puesto que evita la necesidad de compartir estructuras de datos entre el código que se ejecuta en los procesadores</em>.</p>
</li>
<li>
<p>Cuando utilizamos <strong>multiprocesamiento simétrico</strong><sup class="footnote">[<a id="_footnoteref_16" class="footnote" href="#_footnotedef_16" title="View footnote.">16</a>]</sup> o <em>SMP</em> cada procesador ejecuta su propia copia del núcleo del sistema operativo y se auto-planifica mediante su propio planificador de CPU.
En estos sistemas nos podemos encontrar con varias alternativas:</p>
<div class="ulist">
<ul>
<li>
<p>Algunos sistemas disponen de <em>una cola de preparados común para todos los procesadores</em>.
Puesto que se mira en una única cola, <em>todos los procesos pueden ser planificados en cualquier procesador</em>.
Este esquema requiere el uso mecanismos de sincronización debido a que hay estructuras de datos que se comparten entre todos los núcleos.
En caso contrario varios procesadores podrían escoger y ejecuta el mismo proceso a la vez.</p>
</li>
<li>
<p>Por el contrario otros sistemas disponen de <em>una cola de preparados para cada procesador</em>.
El mayor inconveniente de esta solución es que puede generar desequilibrios entre los procesadores, ya que un procesador puede acabar desocupado —con la cola de preparados vacía— mientras otro está muy ocupado.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Muchos sistemas operativos modernos implementan el esquema SMP con una cola de preparados común.
Esto incluye Microsoft Windows NT/2000/XP, Solaris, macOS y versiones anteriores a Linux 2.6.
Sin embargo, esta solución presenta algunos inconvenientes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La posibilidad de que un proceso se pueda ejecutar en cualquier CPU —aunque parezca beneficiosa— es negativa desde el punto de vista de que dejan de ser útiles las cachés de los procesadores, penalizando notablemente el rendimiento del sistema.
Por eso realmente la mayoría de los sistemas operativos de este tipo intenta evitar la migración de procesos de un procesador a otro.
A esto se lo conoce con el nombre de <strong>afinidad al procesador</strong>.</p>
</li>
<li>
<p>Los mecanismos de sincronización requeridos para controlar el acceso a la cola de preparados pueden mantener a los procesadores mucho tiempo desocupados —mientras esperan— en sistemas con un gran número de procesadores y con muchos procesos a la espera de ser ejecutados.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Cada vez más sistemas modernos —incluido Linux 2.6— están optando por utilizar el esquema SMP con una cola de preparados por procesador.
De esta manera, al no utilizar mecanismos de sincronización, se eliminan los tiempos de espera para acceder a la cola de preparados y escoger un nuevo proceso.
Sin embargo, con el fin de mantener la carga de trabajo equilibrada entre todos los procesadores es necesario disponer de algunos mecanismos de <strong>balanceo de carga</strong>.
Por ejemplo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>En la <strong>migración comandada</strong> o <em>push migration</em> un tarea específica —que se ejecuta con menor frecuencia que el planificador de la CPU— estima la carga de trabajo de cada CPU y en caso de encontrar algún desequilibrio mueve algunos procesos de la cola de preparados de unos procesadores a la de los otros * En la <strong>migración solicitada</strong> o <em>pull migration</em> un procesador inactivo extrae de la cola de preparados de un procesador ocupado alguna tarea que esté esperando.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Tanto el planificador de Linux 2.6 como el planificador ULE, disponible en los sistemas FreeBSD, implementan ambas técnicas.
Mientras que en Microsoft Windows, a partir de Windows Vista, sólo se hace uso de la <em>migración solicitada</em>.</p>
</div>
<div class="paragraph">
<p>Para ilustrar los visto hasta el momento sobre la planificación de la CPU en sistemas operativos modernos, vamos a estudiar las principales características de las últimas versiones de Microsoft Windows a este respecto.</p>
</div>
<div class="paragraph">
<p>Las actuales versiones de sistemas operativos Windows se agrupan dentro de la familia Microsoft Windows NT; que nació con el sistema operativo Windows NT 3.1 en 1993 y que llega hasta hoy en día con Microsoft Windows 8.1 y Windows Server 2012 R2 —que se corresponden con la versión 6.3 de dicha familia Windows NT—</p>
</div>
<div class="paragraph">
<p>El núcleo de la familia <em>Windows NT</em> es multihilo e internamente implementa un algoritmo de planificación expropiativa con colas multinivel realimentadas basado en prioridades:</p>
</div>
<div class="paragraph">
<p>Como cualquier sistema operativo moderno, el núcleo de Windows es expropiable —lo que sabemos que ofrece latencias de asignación más bajas que si no lo fuera— y soporta tiempo real flexible:</p>
</div>
<div class="paragraph">
<p>Respecto a esto último, en Windows los programadores o administradores del sistema pueden utilizar el API para establecer la prioridad de los hilos.
Sin embargo sobre estas preferencias el núcleo aplica ciertas bonificaciones para obtener la prioridad real; combinando diferentes criterios para reducir la latencia, mejorar la respuesta —obviamente a través de beneficiar a los hilos limitados por E/S— evitar la muerte por inanición y la inversión de prioridad.
Estas bonificaciones pueden ocurrir en los siguientes casos:</p>
</div>
<div class="paragraph">
<p>Respecto al tiempo de cuanto, desde Windows Vista —NT 6.0— no se usa el temporizador para controlarlo sino un contador de ciclos de reloj de la CPU<sup class="footnote">[<a id="_footnoteref_17" class="footnote" href="#_footnotedef_17" title="View footnote.">17</a>]</sup>.
Así el sistema puede determinar con precisión el tiempo que se hay estado ejecutando un hilo, sin incluir los tiempos dedicados a otras cuestiones, como por ejemplo a manejar interrupciones.</p>
</div>
<div class="paragraph">
<p>En Windows los hilos se insertan en la cabeza de su cola —no en el final— y conservan lo que les queda de cuanto, cuando son expropiados.
Mientras que se insertan por el final con el valor de cuanto reiniciado, cuando abandonan la CPU por haber agotado el cuanto anterior.</p>
</div>
<div class="paragraph">
<p>En Windows las prioridades de los procesos se pueden ver desde dos perspectivas: la del API de Windows y la del núcleo.
Esta última es la que hemos estudiado en el apartado anterior.
Mientras que el API tiene una organización muy diferente que en última instancia debe ser mapeada a las prioridades numéricas del núcleo de Windows.</p>
</div>
<div class="paragraph">
<p>El API organiza los procesos por clases de prioridad: Tiempo real (15), Alta (10), Arriba de lo normal (9), Normal (8), Debajo de lo normal (7), Baja (6) y Reposo (1) .
Al tiempo que cada hilo tiene una prioridad relativa: De tiempo crítico (15), Más alta (2), Arriba de lo normal (1), Normal (0), Debajo de lo normal (—1), Más baja (—2) y Reposo (—15).
Por lo que la prioridad interna de cada hilo, desde el punto de vista del núcleo, es el resultado de sumar la prioridad base obtenida a partir de la clase de prioridad del proceso con la prioridad relativa del hilo en cuestión.</p>
</div>
</div>
</div>
</div>
<h1 id="_gestión_de_la_memoria" class="sect0">Parte IV: Gestión de la memoria</h1>
<div class="sect1">
<h2 id="_memoria_principal">15. Memoria principal</h2>
<div class="sectionbody">
<div class="paragraph">
<p>La memoria es un recurso central para el funcionamiento de un sistema operativo moderno, puesto que es el único medio de almacenamiento al que la CPU puede acceder directamente.
Por ello, para que un programa pueda ser ejecutado debe ser cargado en la memoria, desde el disco, y creadas o modificadas las estructuras internas del sistema operativo necesarias para convertirlo en un proceso.
Además, dependiendo de la forma en la que se gestiona la memoria, los procesos o partes de los mismos pueden moverse de la memoria al disco y viceversa durante su ejecución, con el objetivo de ajustar las necesidades de memoria manteniendo la utilización de la CPU lo más alta posible.</p>
</div>
<div class="paragraph">
<p>Como ya comentamos en el aparatado <a href="#_mainframe">Apartado 2.1</a>, en los <strong>sistemas multiprogramados</strong> existe una <strong>cola de entrada</strong> que se define <em>como aquella formada por el conjunto de procesos en disco que esperan para ser cargados en la memoria para su ejecución</em>.</p>
</div>
<div class="paragraph">
<p>Por tanto, el procedimiento normal de ejecución de un programa en dichos sistemas es:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Seleccionar un proceso de la cola de entrada y cargarlo en la memoria</em>.</p>
</li>
<li>
<p><em>Mientras el proceso se ejecuta, éste accede a instrucciones y datos de la memoria</em>.</p>
</li>
<li>
<p><em>Finalmente el proceso termina y su espacio en memoria es marcado como disponible</em>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>En los <strong>sistemas de tiempo compartido</strong> no existe <strong>cola de entrada</strong>, por lo que los programas se cargan inmediatamente en memoria cuando su ejecución es solicitada por los usuarios.
Excepto por eso, el procedimiento normal de ejecución de un programa es el mismo que para los <em>sistemas multiprogramados</em>.</p>
</div>
<div class="sect2">
<h3 id="_reubicación_de_las_direcciones">15.1. Reubicación de las direcciones</h3>
<div class="paragraph">
<p>La mayor parte de los sistemas permiten que un proceso de usuario resida en cualquier parte de la memoria física.
Así, aunque el espacio de direcciones del sistema comience en <code>0x000000</code>, la primera dirección del proceso de usuario no tiene porque ser esa.
En la mayor parte de los casos, un programa de usuario debe pasar por diferentes etapas —algunas de las cuales son opcionales— antes de ser ejecutado (véase la ).
En cada una de ellas las direcciones pueden representarse de formas distintas, por lo que en cada paso es necesario reubicar las direcciones usadas en una etapa en direcciones de la siguiente.
Por ejemplo, en el código fuente de un programa las direcciones son generalmente <em>simbólicas</em>, como los nombres de las variables y las funciones.
A continuación, un compilador suele reasignar esas direcciones simbólicas en <em>direcciones reubicables</em> del estilo de "120 bytes desde el comienzo del módulo".
Finalmente, el enlazador o el cargador convierte esas direcciones reubicables en <em>direcciones absolutas</em> como <code>0x210243</code>.</p>
</div>
<div class="paragraph">
<p>Por tanto, en cada etapa se mapean las direcciones de un espacio de direcciones en el siguiente.
Sin embargo, para que al final el programa pueda ser ejecutado es necesario que tanto a los datos como a las instrucciones se les reasignen direcciones absolutas de la memoria.
Esto realmente puede ocurrir en cualquiera de las siguientes etapas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>En <strong>tiempo de compilación</strong>.
Si durante la compilación o el enlazado se conoce el lugar de la memoria donde va a ser ejecutado el proceso, se puede generar directamente código con <em>direcciones absolutas</em>, o <strong>código absoluto</strong>.
Si en algún momento la dirección de inicio donde es cargado el programa cambia, es necesario recompilar el código fuente del programa.
Los programas con formato COM del MS-DOS son un ejemplo de este tipo de programas.</p>
</li>
</ul>
</div>
<div class="ulist">
<ul>
<li>
<p>En <strong>tiempo de carga</strong>.
Si no se conoce durante la compilación el lugar donde va a residir un programa cuando sea ejecutado, el compilador debe generar <strong>código reubicable</strong>.
En este tipo de código se utilizan <em>direcciones reubicables</em>, de manera que se retrasa la reubicación a direcciones absolutas hasta el momento de la carga del programa.
Esto permite a muchos sistemas operativos que un proceso pueda residir en cualquier parte de la memoria física, cargando los procesos donde más convenga para maximizar el aprovechamiento de la misma.</p>
</li>
<li>
<p>En <strong>tiempo de ejecución</strong>.
Si un proceso puede ser movido durante su ejecución de un lugar de la memoria a otro, la reubicación de direcciones debe ser retrasada hasta el momento de la ejecución de cada instrucción del programa.
Para que esto sea posible necesitamos disponer de hardware especial que suele estar presente en la mayor parte de las CPU modernas, por lo que la inmensa mayoría de los sistemas operativos modernos de propósito general utilizan este método.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En el <a href="#_protección_de_la_memoria">Apartado 7.3</a> vimos en lo sistemas operativos modernos, como medida de protección, los procesos no tienen acceso libre a la memoria física.
En lugar de eso el sistema operativo —asistido por la MMU (Memory-Management Unit)— proporciona a cada proceso un <em>espacio de direcciones virtual</em> que ofrece una «vista» privada de la memoria similar a la que tendrían si cada uno de los procesos estuviera siendo ejecutando en solitario (véase la ).
Es durante los acceso a la memoria principal en tiempo de ejecución cuando estas <em>direcciones virtuales</em> son convertidas en las <em>direcciones física</em> con las que realmente se accede a la memoria.</p>
</div>
<div class="paragraph">
<p>El mecanismo de protección descrito <em>es una forma muy común de reubicación de las direcciones en tiempo de ejecución</em> que está presente en la mayor parte de los sistemas operativos modernos de propósito general.
A parte de la protección, algunas de las características de dicho mecanismo son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Los programas pueden ser cargados en cualquier zona libre de la memoria física e incluso movidos de una región a otra durante la ejecución de los procesos</em>, puesto que la transformación (reubicación) de las direcciones virtuales en direcciones físicas se realiza durante la ejecución de cada instrucción.</p>
</li>
<li>
<p><em>La reubicación de las direcciones virtuales —es decir, la asignación de direcciones virtuales a las direcciones del programa— puede hacerse en tiempo de compilación</em> puesto que de antemano se sabe que todo el espacio de direcciones virtual va a estar disponible.
Lo común es que los programas se ubiquen en la parte baja del espacio de direcciones virtual, por ejemplo en empezando en la dirección <code>0x00000000</code>.</p>
</li>
<li>
<p><em>Se puede reducir el consumo de memoria principal compartiendo las regiones de memoria física asignadas al código y los datos de sólo lectura de los procesos de un mismo programa</em>.
El código de un programa suele contener direcciones tanto para los saltos como para el acceso a los datos.
Al ubicar los programas siempre en las mismas regiones de los espacios de direcciones virtuales nos estamos asegurando de que el código en memoria de los procesos de un mismo programa siempre es el mismo, por lo que se puede compartir la memoria física que ocupan.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_enlazado_dinámico_y_librerías_compartidas">15.2. Enlazado dinámico y librerías compartidas</h3>
<div class="paragraph">
<p>Fundamentalmente existen dos tipos de enlazado:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>En el <strong>enlazado estático</strong>, las librerías del sistema y otros módulos son combinados por el enlazador para formar la imagen binaria del programa que es almacenada en disco</em>.
Algunos sistemas operativos, como MS-DOS, sólo soportan este tipo de enlazado.</p>
</li>
<li>
<p><em>En el <strong>enlazado dinámico</strong>, éste se pospone hasta la carga o la ejecución</em> (véase la ).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Generalmente el enlazado dinámico ocurre durante la carga del programa:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Durante la carga del módulo ejecutable se comprueban las dependencias del mismo</em>.
Estas se almacenan en el mismo archivo en disco que dicho módulo.</p>
</li>
<li>
<p><em>Las librerías a enlazar se cargar y ubican en el espacio de direcciones virtual creado para el nuevo proceso</em>.</p>
</li>
<li>
<p>Finalmente, <em>las referencias del programa a las funciones de cada una de las librerías cargadas se actualizan con la dirección en memoria de las mismas</em>.
Así la invocación de las funciones por parte del programa se puede realizar de forma transparente, como si siempre hubieran formado parte del mismo.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Cuando el enlazado se va a realizar en tiempo de ejecución se habla de <em>enlazado dinámico con carga diferida</em>.
En ese caso el procedimiento es el siguiente.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Durante el enlazado estático del módulo ejecutable se pone un stub a cada referencia a alguna función de la librería que va a ser enlazada dinámicamente</em>.</p>
</li>
<li>
<p><em>Si durante la ejecución alguna de dichas funciones es invocada, se ejecuta el stub</em>.
El <em>stub</em> es una pequeña pieza de código que sabe como carga la librería, si no ha sido cargada previamente, y como localizar la función adecuada en la misma.</p>
</li>
<li>
<p>Finalmente, <em>el stub se sustituye a si mismo con la dirección de la función y la invoca</em>.
Esto permite que la siguiente ejecución de la función no incurra en ningún coste adicional.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Sin esta habilidad cada programa en el sistema, por ejemplo, debe tener una copia de la librería del sistema incluida en la imagen binaria del mismo, lo que significa un desperdicio de espacio libre en disco y memoria principal.
Además este esquema facilita la actualización de las librería, puesto que los programas pueden utilizar directamente las versiones actualizadas sin necesidad de volver a ser enlazados.</p>
</div>
<div class="paragraph">
<p>Puesto que durante la compilación de una librería no se conoce la región que va a ocupar dentro de los espacios de direcciones virtuales de los distintos procesos que la van a utilizar:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Para las librerías <em>el compilador debe generar código PIC (Position-Independent Code) o independiente de la posición</em>.
Este tipo de código se puede ejecutar adecuadamente y sin modificaciones independientemente del lugar de la memoria donde esté ubicado.
Esto permite reducir el consumo de memoria principal compartiendo las regiones de memoria física asignadas al código de una misma librería en los distintos procesos que la utilizan.</p>
</li>
<li>
<p>En los sistemas operativos donde no se usa código PIC el compilador debe generar código reubicable <em>para que la reubicación de las direcciones virtuales de las librerías dinámicas se haga en tiempo de carga</em>.
Esto aumenta el tiempo de carga de las librerías y sólo permite que compartan memoria física el código de las instancias de una misma librería que ha sido cargado en la misma región del espacio de direcciones virtual en los distintos procesos que la utilizan.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><em>Habitualmente las librerías incluyen información acerca de la versión que puede ser utilizada para evitar que los programas se ejecuten con versiones incompatibles de las mismas, o para permitir que haya más de una versión de cada librería en memoria</em>.
Así los viejos programas se pueden ejecutar con las viejas versiones de las mismas, o con versiones actualizadas pero compatibles, mientras los nuevos programas se ejecuten con las versiones más recientes e incompatibles con los viejos programas.
A este sistema se lo conoce como <strong>librerías compartidas</strong>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_asignación_de_memoria_contigua">15.3. Asignación de memoria contigua</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="_paginación">16. Paginación</h2>
<div class="sectionbody">
<div class="paragraph">
<p>El mapeo entre direcciones virtuales y físicas puede realizarse de diversas maneras.
La forma más extendida es <em>la <strong>paginación</strong>, que no es sino un esquema de gestión de la memoria que permite que el espacio de direcciones físico de un proceso no sea continuo</em>.</p>
</div>
<div class="sect2">
<h3 id="_método_básico">16.1. Método básico</h3>
<div class="paragraph">
<p>En la paginación <em>la memoria física se divide en bloques de tamaño fijo denominados <strong>marcos</strong>, mientras que el espacio de direcciones virtual se divide en bloques del mismo tamaño que los marcos, denominados <strong>páginas</strong></em>.
Cuando un proceso va a ser ejecutado sus páginas son cargadas desde el almacenamiento secundario en marcos libres de la memoria física.</p>
</div>
<div class="paragraph">
<p>La paginación es una forma de <em>reubicación de las direcciones en tiempo de ejecución</em> donde la transformación de las direcciones virtuales en direcciones físicas se realiza de la siguiente manera (véase la ):</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Cada dirección virtual generada por la CPU es divida en dos partes</em>: un <strong>número de página</strong> \$p\$ y un <strong>desplazamiento</strong> \$d\$.</p>
</li>
<li>
<p><em>El número de página es utilizado por la MMU para indexar la <strong>tabla de páginas</strong></em>, que contiene el <strong>número de marco</strong> \$f\$ de cada página en la memoria física.</p>
</li>
<li>
<p><em>El número de marco \$f\$ es combinado con el <strong>desplazamiento</strong> \$d\$</em> para generar la dirección física que va a ser enviada por el bus de direcciones hacia la memoria.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>El tamaño de las páginas —y el de los marcos— viene definido por el hardware y normalmente es un número entero potencia de 2 que puede variar entre 512 bytes y 16 MB, dependiendo de la arquitectura.
Es decir, si el espacio de direcciones es de \$2^m\$ y el tamaño de página es de \$2^n\$, los \$m - n\$ bits de mayor orden del espacio de direcciones indican el <em>número de página</em>, mientras que los \$n\$ bits de menor orden indican el <em>desplazamiento</em> (véase la )</p>
</div>
<div class="sect3">
<h4 id="_desde_el_punto_de_vista_de_los_procesos">16.1.1. Desde el punto de vista de los procesos</h4>
<div class="paragraph">
<p>Cada página de un proceso requiere un marco.
Por tanto, cuando un proceso llega al sistema:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Si el proceso requiere n páginas, el sistema operativo debe escoger n marcos</em>.
Estos marcos son tomados de la <em>lista de marcos libres</em> que debe mantener el sistema.
Puesto que son escogidos de allí donde los haya libres, <em>el espacio de direcciones físico puede no ser contiguo aunque los procesos vean un espacio de direcciones virtual contiguo</em>.</p>
</li>
<li>
<p>Los marcos seleccionados son asignados al proceso y <em>cada página del proceso es cargada en uno</em> de dichos marcos.</p>
</li>
<li>
<p><em>La tabla de páginas es actualizada</em> de manera que en la entrada de cada página del proceso se pone el número de marco correspondiente.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Un aspecto importante de la paginación es la diferencia entre como ven los proceso la memoria y como es realmente la memoria física.
Cada proceso ve la memoria como un espacio único que lo contiene sólo a él.
Sin embargo la realidad es que el programa está disperso por la memoria física, que además puede almacenar a otros programas.
<em>Esto es posible porque en cada momento la tabla de páginas sólo contiene las páginas del proceso actual</em>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_desde_el_punto_de_vista_del_sistema_operativo">16.1.2. Desde el punto de vista del sistema operativo</h4>
<div class="paragraph">
<p>Puesto que el sistema operativo es quién gestiona la memoria física, <em>éste debe mantenerse al tanto de las particularidades de su uso</em>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Que marcos están asignados y a que página de que proceso o procesos</em>.</p>
</li>
<li>
<p><em>Que marcos están disponibles</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Toda esta información generalmente se guarda en una estructura denominada la <em><strong>tabla de marcos</strong>, que tiene una entrada por cada marco de la memoria física</em>.</p>
</div>
<div class="paragraph">
<p>Además <em>el sistema operativo debe mantener una copia de la tabla de páginas para cada proceso en el PCB</em>, igual que mantiene una copia del contador de programa y del contenido de los registros de la CPU.
Esta copia es utilizada:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Por <em>el asignador para sustituir la tabla de páginas hardware cuando realiza un cambio de contexto</em>.
Por lo tanto el uso de la paginación incrementa el tiempo del cambio de contexto.</p>
</li>
<li>
<p><em>Para el mapeo manual de direcciones virtuales en físicas</em>.
Por ejemplo, cuando un proceso realiza una llamada al sistema para realizar una operación de E/S y proporciona una dirección como parámetro, dicha dirección debe ser mapeada manualmente para producir la dirección física correspondiente que será utilizada por el hardware para realizar la operación.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_tamaño_de_las_páginas">16.1.3. Tamaño de las páginas</h4>
<div class="paragraph">
<p>Una decisión de diseño importante es escoger el tamaño de las páginas adecuado:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Con páginas más pequeñas esperamos tener menos fragmentación interna</em>.
Los marcos son asignados como unidades indivisibles, por lo que si los requerimientos de memoria de un procesos no coinciden con un límite de páginas el último marco asignado no sería utilizado completamente (en ocasiones incluso se podría desperdiciar un marco completo).
A ese fenómeno se lo conoce como <em>fragmentación interna</em></p>
</li>
<li>
<p><em>Con páginas más grande se pierde menos espacio en la tabla de páginas</em>.
No olvidemos que cuanto más pequeñas son las páginas más páginas son necesarias y, por tanto, más entradas en la tabla de páginas se necesitan.
Además <em>la E/S es más eficiente cuanto más datos son transferidos en cada operación</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Los tamaños de páginas típicos son 4 y 8 KB.
Por ejemplo, normalmente cada entrada en la tabla de paginas es de 4 bytes —aunque esto también puede variar—.
Eso significa que cada entrada puede direccionar a uno de los 2<sup>32</sup> marcos de la memoria física.
Si suponemos que el tamaño de cada marco es de 4 KB, podemos determinar que el sistema es capaz de direccionar 2<sup>44</sup> bytes —o 16 TB— de memoria física, para lo que es necesario disponer de una tabla de páginas de 4 MB.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_soporte_hardware_de_la_tabla_de_páginas">16.2. Soporte hardware de la tabla de páginas</h3>
<div class="paragraph">
<p>La implementación en hardware de la tabla de páginas puede realizarse de diversas maneras:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Como un conjunto de registros dedicados de la CPU</em>.
Es decir, la tabla de páginas del proceso actual es alojada dentro de la propia CPU, en unos registros destinados a tal fin.</p>
</li>
<li>
<p><em>Almacenada en la memoria</em>.
Es decir, la tabla de páginas del proceso actual es alojada en la memoria, normalmente en un formato definido por la CPU.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Debido a la velocidad de los registros de la CPU <em>la implementación como conjunto de registros es la más eficiente.</em> Sin embargo <em>sólo puede ser utilizado para tablas de páginas razonablemente pequeñas</em>.
El DEC PDP-11 —para el que se diseño el primer UNIX— es un ejemplo de sistema con esta implementación.
En el mismo se utilizaba un espacio de direcciones de 16 bits y un tamaño de páginas de 8 KB, por lo que sólo necesitaba 8 registros dedicados para alojar toda tabla de páginas.</p>
</div>
<div class="paragraph">
<p>En los sistemas modernos se utilizan tablas de páginas muchos más grandes —de un millón de entradas o más— que difícilmente pueden alojarse en registros dentro de la CPU, ya que alojar tablas de páginas de más de 256 entradas es muy costoso.
Por eso los sistemas actuales almacenan la tabla de páginas del proceso en ejecución en la memoria._ Eso permite disponer tablas de páginas de gran tamaño_ aunque a costa de <em>necesitar dos acceso a la memoria física por cada acceso a una palabra de la memoria virtual<sup class="footnote">[<a id="_footnoteref_18" class="footnote" href="#_footnotedef_18" title="View footnote.">18</a>]</sup></em>.</p>
</div>
<div class="paragraph">
<p>Para que la MMU pueda conocer la ubicación de la tabla de páginas durante la traducción de las direcciones, <em>la CPU debe disponer de un registro —el <strong>PTBR</strong> (Page-Table Base Register)— donde se guarda la dirección de la tabla de páginas actual</em>.
Además esto permite que el cambio de contexto sea más rápido —respecto al uso de registros para almacenar la tabla de páginas— puesto que sólo es necesario carga un único registro más —el PTBR— durante el mismo.</p>
</div>
</div>
<div class="sect2">
<h3 id="_protección">16.3. Protección</h3>
<div class="paragraph">
<p>La protección de las páginas <em>se consigue mediante unos <strong>bits de protección</strong> asociados a cada entrada de la tabla de páginas</em> y normalmente almacenados en la misma.
Estos bits pueden ser:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Solo lectura</strong>.</p>
</li>
<li>
<p><strong>Lectura — Escritura</strong>.
En algunos sistemas hay un bit específico para este permiso, mientras que en otros se utilizan bit separados como: <em>lectura</em>, <em>escritura</em> y <em>ejecución</em>.</p>
</li>
<li>
<p><strong>Sólo ejecución</strong>.
Que no existen en todas las plataformas.
Por ejemplo, la familia Intel x86 careció de esta característica hasta que AMD la incluyó en su arquitectura AMD64, lo que obligó a Intel a incluirla en las versiones más modernas de su Pentium IV.
El bit —que para ser exacto indica <em>no ejecución</em>— fue introducido para evitar cierto tipo de ataques de seguridad.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Durante la traducción de las direcciones la MMU comprueba que el tipo de acceso sea válido.
Si esto no es así, se genera una excepción de violación de protección de memoria, dado que el acceso en un modo o autorizado se considera una instrucciones privilegiada.
Normalmente el sistema operativo responde a dicha excepción terminando el proceso que la generó.</p>
</div>
<div class="paragraph">
<p><em>Además de los bits comentados se suele añadir a cada entrada un <strong>bit de válido</strong></em>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Cuando una página es válida</em>, la pagina asociada está en el espacio de direcciones virtual del proceso.
Es decir, <em>es legal</em>.</p>
</li>
<li>
<p><em>Cuando la página no es inválida</em>, la página no está asociada al espacio de direcciones virtual del proceso.
Es decir, <em>es ilegal</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><em>El sistema operativo puede utilizar este bit para permitir o denegar el acceso a una página</em>, por ejemplo porque no le ha asignado un marco ya que no está siendo utilizada por el proceso.
Al igual que con los bits de permisos, los intentos de acceso a una página ilegal generan una excepción.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, en la vemos el espacio de direcciones virtual y la tabla de páginas de un proceso de 5096 bytes en un sistema con páginas de 1024 bytes.
Puesto que el proceso no ocupa todo el espacio de direcciones, sólo las direcciones de la 0 a la 5119 son válidas.
En dicho ejemplo podemos apreciar varios fenómenos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Debido a la fragmentación interna las direcciones de la 5097 a la 5119 son válidas, aunque el proceso solo ocupe hasta la 5096.
Es decir, se está asignando al proceso una porción de memoria que no necesita.</p>
</li>
<li>
<p>Las páginas ocupadas por el proceso son válidas.
Pero todas las paginas en direcciones por encima de la 5119 están marcadas como ilegales.
<em>Así el sistema operativo no tiene que asignar marcos a páginas no utilizadas por el proceso</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En general los procesos sólo necesitan una porción muy pequeña de su espacio de direcciones virtual.
En esos casos es un desperdicio de memoria crear y almacenar un tabla de página completa con una entrada para cada página del espacio de direcciones.
Para evitarlo <em>en algunas CPU existe el <strong>PTLR</strong> (Page-Table Length Register) que se utiliza para indicar el tamaño actual de la tabla de página</em>.
Este valor es comparado por la MMU durante la traducción con el número de página de cada dirección virtual, de manera que las páginas con entradas más allá de la última almacenada en la tabla son consideradas ilegales.</p>
</div>
<div class="paragraph">
<p>En realidad, tal y como vimos en el <a href="#_el_proceso">Apartado 9.1</a>, <em>lo más común es que los procesos tengan un espacio de direcciones virtual disperso como el de la _.
En la misma podemos observar como el sistema operativo ubica los diferentes componentes del proceso de una forma particular dentro del espacio de direcciones virtual.
Este esquema permite que tanto el _montón</em> —a través del mecanismo de asignación dinámica de memoria de <code>malloc()</code>— como la pila puedan extenderse, en base a las necesidades de memoria que tenga el proceso, sobre la región de memoria no ocupada.
Esa región también puede ser parcialmente ocupada por librerías de enlace dinámico o por otros objetos compartidos que sean necesitados durante la ejecución del proceso.
<em>En cualquier caso las páginas de dicha región forman parte del espacio de direcciones virtual pero no tienen marcos de memoria física asignados, en tanto en cuanto el proceso no las vaya a utilizar.
La falta de marco es indicada por el sistema operativo utilizando el bit de válido para denegar el acceso</em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_páginas_compartidas">16.4. Páginas compartidas</h3>
<div class="paragraph">
<p>Una de las ventajas importantes de la paginación es la posibilidad de compartir páginas entre procesos.
Para conseguir esto basta con que <em>las <strong>páginas compartidas</strong> de los distintos procesos tengan asignadas un mismo marco</em>.
Esto permite, por ejemplo, que los procesos de un mismo programa puedan compartir las páginas de código o los datos de sólo lectura con el fin de ahorrar memoria.
También permite compartir las páginas de código de una librería compartida enlazada a diferentes procesos.</p>
</div>
<div class="paragraph">
<p>Compartir páginas no sólo permite ahorrar memoria pues en <em>los sistemas operativos modernos la memoria compartida (véase el <a href="#_memoria_compartida">Capítulo 11</a>) se implementa mediante páginas compartidas</em>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_paginación_bajo_demanda">17. Paginación bajo demanda</h2>
<div class="sectionbody">
<div class="paragraph">
<p>La <em>paginación bajo demanda</em> es la técnica con la que frecuentemente se implementa la <em>memoria virtual</em> en los sistemas con paginación.
El concepto de <em>memoria virtual</em> no debe confundirse con el de <em>espacio de direcciones virtual</em>, aunque están relacionados puesto que <em>el que exista separación entre la memoria física y la manera en la que los procesos perciben la memoria es un requisito para poder implementar la memoria virtual</em>.</p>
</div>
<div class="sect2">
<h3 id="_memoria_virtual">17.1. Memoria virtual</h3>
<div class="paragraph">
<p><em>La <strong>memoria virtual</strong> es una técnica que permite la ejecución de procesos sin que éstos tengan que ser cargados completamente en la memoria</em>.</p>
</div>
<div class="paragraph">
<p>Los programas suelen tener partes de código que rara vez son ejecutadas, por ejemplo las funciones para manejar condiciones de error que, aunque útiles, generalmente nunca son invocadas.
También es frecuente que se reserve más memoria para datos de lo que realmente es necesario.
Por ejemplo muchos programadores tiene la costumbres de hacer cosas tales como declarar un <em>array</em> de 1000 por 1000 elementos cuando realmente sólo necesitan 100 por 100.
Teniendo todo esto en cuenta y con el fin de mejorar el aprovechamiento de la memoria, parece que sería interesante no tener que cargar todas las porciones de los procesos pero de manera que éstos aun así puedan seguir siendo ejecutados.
Eso es exactamente lo que proporciona la memoria virtual, en general, y la paginación bajo demanda, en particular, para los sistemas que soportan paginación.</p>
</div>
<div class="paragraph">
<p>La habilidad de ejecutar un proceso cargado parcialmente en memoria proporciona algunos beneficios importantes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Un programa no estará nunca más limitado por la cantidad de memoria disponible</em>.
Es decir, los desarrolladores pueden escribir programas considerando que disponen de un espacio de direcciones virtual extremadamente grande y sin considerar la cantidad de memoria realmente disponible.
Es importante no olvidar que sin memoria virtual para que un proceso pueda ser ejecutado debe estar completamente cargado en la memoria.</p>
</li>
<li>
<p>Puesto que cada programa ocupa menos memoria <em>más programas se pueden ejecutar al mismo tiempo, con el correspondiente incremento en el uso de la CPU y en el rendimiento del sistema</em> y sin efectos negativos en el tiempo de respuesta y en el de ejecución.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_método_básico_2">17.2. Método básico</h3>
<div class="paragraph">
<p><em>En la paginación bajo demanda las páginas individuales, en las que se dividen los espacios de direcciones virtuales de los diferentes procesos, pueden ser sacadas de la memoria de manera temporal y copiadas a un almacenamiento de respaldo, para posteriormente volver a ser traídas a la memoria cuando son necesitadas por su proceso</em>.
A este proceso de guardado y recuperación de las páginas sobre el almacenamiento de respaldo se lo denomina <strong>intercambio</strong> o <em>swapping</em> y es llevado a cabo por un componente del sistema operativo denominado el <em>paginador</em>.</p>
</div>
<div class="paragraph">
<p>Para que se puedan cargar las páginas cuando son necesitadas por su proceso hace falta que el paginador sepa cuando lo son.
Eso requiere que el hardware proporcione algún tipo de soporte, por ejemplo incorporando un <strong>bit de válido</strong> a la entrada de cada página en la tabla de páginas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Cuando el bit de válido está a 1 la página es legal y está en la memoria</em>.
Es decir, la página existe en el espacio de direcciones virtual del proceso y tiene asignado un marco de memoria física.</p>
</li>
<li>
<p><em>Cuando el bit de válido está a 0</em> pueden ocurrir varias cosas:</p>
<div class="ulist">
<ul>
<li>
<p><em>La página es legal pero esta almacenada en disco</em> y no en la memoria.</p>
</li>
<li>
<p><em>La página no es legal</em>.
Es decir, no existe en el espacio de direcciones virtual del proceso.
Esto puede ser debido a que la página esté en un hueco del espacio de direcciones —en una región que no está siendo utilizada— por lo que el sistema operativo no le ha asignado espacio de almacenamiento ni en disco ni en la memoria.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Si un proceso accede a una página <em>residente en memoria</em> —marcada como válida— no ocurre nada y la instrucción se ejecuta con normalidad.
Pero si accede a una página marcada como inválida:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Al intentar acceder a la página la MMU comprueba el bit de válido y <em>genera una excepción de fallo página al estar marcada como inválida</em>.
Dicha excepción es capturada por el sistema operativo.</p>
</li>
<li>
<p><em>El sistema operativo comprueba en una tabla interna si la página es legal o no</em>.
Es decir, si la página realmente no pertenece al espacio de direcciones virtual del proceso o si pertenece pero está almacenada en el disco.
Esta tabla interna suele almacenarse en el PCB del proceso como parte de la información de gestión de la memoria.</p>
</li>
<li>
<p><em>Si la página es ilegal, el proceso ha cometido un error y debe ser terminado</em>.
En UNIX, por ejemplo, el sistema envía al proceso una señal de <em>violación de segmento</em> que lo obliga a terminar.</p>
</li>
<li>
<p><em>Si la página es legal debe ser cargada desde el disco</em>:</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>..
<em>El núcleo debe buscar un marco de memoria libre</em> que, por ejemplo, se puede escoger de la lista de marcos libres del sistema.</p>
</div>
<div class="paragraph">
<p>..
<em>Se solicita una operación de disco para leer la página deseada en el marco asignado</em>.
Puesto que no resulta eficiente mantener la CPU ocupada mientras la página es recuperada desde el disco, el sistema debe solicitar la lectura de la página y poner al proceso en estado de espera.</p>
</div>
<div class="paragraph">
<p>..
<em>Cuando la lectura del disco haya terminado se debe modificar la tabla interna, antes mencionada, y la tabla de páginas para indicar que la página está en la memoria</em>.</p>
</div>
<div class="paragraph">
<p>..
<em>Reiniciar la instrucción que fue interrumpida por la excepción</em>.
Generalmente esto se hace colocando el proceso nuevamente en la cola de preparados y dejando que el asignador lo reinicie cuando sea escogido por el planificador de la CPU.</p>
</div>
<div class="paragraph">
<p>Un caso extremo de la paginación bajo demanda es la <strong>paginación bajo demanda pura</strong>.
En ella <em>la ejecución de un proceso se inicia sin cargar ninguna página en la memoria</em>.
Cuando el sistema operativo sitúa al contador de programas en la primera instrucción del proceso —que es una página no residente en memoria— se genera inmediatamente un fallo de página.
La página es cargada en la memoria —tal y como hemos descrito anteriormente— y el proceso continua ejecutándose, fallando cuando sea necesario con cada página que necesite y no esté cargada.
Las principales ventajas de la <em>paginación bajo demanda pura</em> son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Nunca se traerá desde el disco una página que no sea necesaria.</p>
</li>
<li>
<p>El inicio de la ejecución de un proceso es mucho más rápido que si se cargara todo el proceso desde el principio.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_requerimientos_de_la_paginación_bajo_demanda">17.3. Requerimientos de la paginación bajo demanda</h3>
<div class="paragraph">
<p>Los requerimientos hardware para que un sistema operativo pueda soportar la paginación bajo demanda son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Tabla de páginas con habilidad para marcar entradas inválidas</em>, ya sea utilizando un bit específico o con valores especiales en los bits de protección.</p>
</li>
<li>
<p><em>Disponibilidad de una memoria secundaria</em>.
En esta memoria se guardan las páginas que no están presentes en la memoria principal.
Normalmente se trata de un disco conocido como <strong>dispositivo de intercambio</strong>, mientras que la sección de disco utilizada concretamente para dicho propósito se conoce como <strong>espacio de intercambio</strong> o <em>swap</em>.</p>
</li>
<li>
<p><em>Posibilidad de reiniciar cualquier instrucción</em> después de un fallo de página.
En la mayor parte de los casos esta funcionalidad es sencilla de conseguir.
Sin embargo, la mayor dificultad proviene de las instrucciones que pueden modificar diferentes posiciones de la memoria, como aquellas pensadas para mover bloques de bytes o palabras.
En el caso de que el bloque de origen o de destino atraviese un borde de página, la instrucción sería interrumpida cuando la operación solo haya sido realizada parcialmente.
Si además ambos bloques se superpusieran, no se podría reiniciar la instrucción completa.
Las posibles soluciones a este problema deben ser implementadas en el hardware.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_rendimiento_de_la_paginación_bajo_demanda">17.4. Rendimiento de la paginación bajo demanda</h3>
<div class="paragraph">
<p>Indudablemente el rendimiento de un sistema con paginación bajo demanda se ve afectado por el número de fallos de páginas.
En el peor de los casos, en cada instrucción un proceso puede intentar acceder a una página distinta empeorando notablemente el rendimiento.
Sin embargo esto no ocurre puesto que los programas tienden a tener localidad de referencia (véase el <a href="#_hiperpaginación">Apartado 17.9</a>).</p>
</div>
<div class="sect3">
<h4 id="_tiempo_de_acceso_efectivo">17.4.1. Tiempo de acceso efectivo</h4>
<div class="paragraph">
<p>El rendimiento de un sistema con paginación bajo demanda está relacionado con el concepto de <strong>tiempo de acceso efectivo</strong> a la memoria.
<em>Éste intenta estimar el tiempo que realmente se tarda en acceder a la memoria teniendo en cuenta mecanismos del sistema operativo como la paginación bajo demanda</em>.</p>
</div>
<div class="paragraph">
<p>En muchos sistemas informáticos el <strong>tiempo de acceso</strong> —a la memoria física— \$T_m\$ es de unos pocos nanosegundos.
Por lo tanto, si no hay fallos de página, el <em>tiempo de acceso efectivo</em> es igual al tiempo de acceso a la memoria.
Pero si hay fallos de página, primero es necesario leer la página del disco, por lo que el <em>tiempo de acceso efectivo</em> a la memoria es mayor.</p>
</div>
<div class="paragraph">
<p>Supongamos que conocemos la probabilidad \$p\$ de que ocurra un fallo de página.
_El tiempo de acceso efectivo se podría calcular como una media ponderada por la probabilidad p del tiempo de acceso a la memoria \$T_m\$ mas el tiempo necesario para gestionar cada fallo de página —o <strong>tiempo de fallo de página</strong>— \$T_(fp)\$:</p>
</div>
<div class="stemblock">
<div class="content">
\$T_(em)=(1-p)*T_m+p T_(fp)\$
</div>
</div>
<div class="paragraph">
<p>Por tanto, para calcular el <em>tiempo de acceso efectivo</em> \$T_(em)\$ necesitamos estimar el <em>tiempo de fallo de página</em> \$T_(fp)\$, que se consume fundamentalmente en:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Servir la excepción de fallo de página</em>.
Esto incluye capturar la interrupción, salvar los registros y el estado del proceso, determinar que la interrupción es debida a una excepción de fallo de página, comprobar si la página es legal y determinar la localización de la misma en el disco.
Aproximadamente, en realizar esta tarea el sistema puede tardar de 1 a 100μs.</p>
</li>
<li>
<p><em>Leer la página en un marco libre</em>.
En esta tarea se puede tardar alrededor de 8ms, pero este tiempo puede ser mucho mayor si el dispositivo está ocupado y se debe esperar a que se realicen otras operaciones.</p>
</li>
<li>
<p><em>Reiniciar el proceso</em>.
Si incluimos el tiempo de espera en la cola de preparados, se puede tardar entre 1 y 100μs.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Como se puede apreciar <em>la mayor parte del tiempo de fallo de página es debido al tiempo requerido para acceder al dispositivo de intercambio</em>.</p>
</div>
<div class="paragraph">
<p>Para ilustrar el cálculo del <em>tiempo de acceso efectivo</em> a la memoria: sólo vamos a considerar el tiempo requerido para acceder al dispositivo de intercambio —ignorando las otras tareas a realizar durante el fallo de página— vamos suponer que el <em>tiempo de acceso</em> a la memoria \$T_m\$ es de 200 ns y que la probabilidad \$p\$ es muy pequeña (es decir, \$p ≪ 1\$):</p>
</div>
<div class="stemblock">
<div class="content">
\${:(T_(em),=,(1-p)*200ns+p * 8ms),
(      ,=,(1-p)*200ns+p * 8000000ns),
( ,approx, 200ns+7999800ns * p ):}\$
</div>
</div>
<div class="paragraph">
<p>Como se puede apreciar el <em>tiempo de acceso efectivo</em> es proporcional a la <strong>tasa de fallos de página</strong>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>[stem]
++++
T_(em) approx T_(m)+r_(fp)
++++</pre>
</div>
</div>
<div class="paragraph">
<p>Por ejemplo, si un proceso causa un fallo de página en uno de cada 1000 accesos (\$p = 0,001\$), el <em>tiempo de acceso efectivo</em> es de 8,2 ms.
Es decir, el rendimiento del sistema es 40 veces inferior debido a la paginación bajo demanda.
Por tanto <em>es necesario mantener la tasa de fallos de página lo más baja posible para mantener un rendimiento adecuado</em>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_manejo_y_uso_del_espacio_de_intercambio">17.4.2. Manejo y uso del espacio de intercambio</h4>
<div class="paragraph">
<p><em>Otro aspecto fundamental que afecta al rendimiento de la paginación bajo demanda es el uso del espacio de intercambio</em>.
Cuando un proceso genera un fallo de página el sistema operativo debe recuperar la página de allí donde esté almacenada.
Si esto ocurre al principio de la ejecución, ese lugar seguramente será el archivo que contiene la imagen binara del programa, pues es donde se encuentran las páginas en su estado inicial.
Sin embargo el acceso al espacio de intercambio es mucho más eficiente que el acceso a un sistema de archivos, incluso aunque el primero esté almacenado dentro de un archivo de gran tamaño.
Esto es debido a que los datos se organizan en bloques contiguos de gran tamaño, se evitan las búsquedas de archivos y las indirecciones en la asignación de espacio.
Por ello debemos plantearnos que hacer con las imágenes de los programas que van a ser ejecutados.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Se puede mejorar el rendimiento <em>copiando en el espacio de intercambio la imagen completa de los programas durante el inicio del proceso, para después realizar la paginación bajo demanda sobre dicha copia</em>.</p>
</li>
<li>
<p>Otra alternativa es <em>cargar las páginas desde el archivo que contiene la imagen cuando son usadas por primera vez pero siendo escritas en el espacio de intercambio cuando dichas páginas tiene que ser reemplazadas</em>.
Esta aproximación garantiza que sólo las páginas necesarias son leídas desde el sistema de archivos reduciendo el uso de espacio de intercambio, mientras que las siguientes operaciones de intercambio se hacen sobre dicho espacio.</p>
</li>
<li>
<p>También se puede suponer que el código de los procesos no puede cambiar.
Esto permite <em>utilizar el archivo de la imagen binaria para recargar las páginas de código, lo que también evita escribirlas cuando son sustituidas.
Sin embargo el espacio de intercambio se sigue utilizando para las páginas que no están directamente asociadas a un archivo, como la pila o el montón de los procesos</em>.
Este método parece conseguir un buen compromiso entre el tamaño del espacio de intercambio y el rendimiento.
Por eso se utiliza en la mayor parte de los sistemas operativos modernos.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_copy_on_write">17.5. Copy-on-write</h3>
<div class="paragraph">
<p><em>El <strong>copy-on-write</strong> o copia durante la escritura permite la creación rápida de nuevos procesos, minimizando la cantidad de páginas que deben ser asignadas a estos</em>.
Para entenderlo es importante recordar que la llamada al sistema <code>fork()</code> crear un proceso hijo cuyo espacio de direcciones es un duplicado del espacio de direcciones del padre.
Indudablemente esto significa que durante la llamada es necesario asignar suficientes marcos de memoria física como para alojar las páginas del nuevo proceso hijo.
El <em>copy-on-write</em> minimiza de la siguiente manera el número de marcos que deben ser asignadas al nuevo proceso:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Cuando la llamada al sistema <code>fork()</code> crea el nuevo proceso lo hace de forma que éste comparta todas sus páginas con las del padre</em> (véase la ).
Sin el <em>copy-on-write</em> el <code>fork()</code> tendría que asignar marcos de memoria física a el hijo, para a continuación copiar las páginas del padre en ellos.
Sin embargo con el <em>copy-on-write</em> padre e hijo mapean sus páginas en los mismos marcos, evitando tener que asignar memoria libre.</p>
</li>
<li>
<p><em>Las páginas compartidas se marcan como copy-on-write</em>.
Para ello se puede marcar todas las páginas como de <em>solo lectura</em> en la tabla de páginas de ambos procesos y utilizar una tabla interna alojada en el PCB para indicar cuales son realmente de <em>sólo lectura</em> y cuales están en <em>copy-on-write</em>.
<em>Es importante destacar que realmente sólo las páginas que pueden ser modificadas se marcan como copy-on-write.</em> Las páginas que no puede ser modificadas —por ejemplo las que contienen el código ejecutable del programa— simplemente pueden ser compartidas como de sólo lectura por los procesos, como hemos comentado anteriormente.</p>
</li>
<li>
<p><em>Si algún proceso intenta escribir en una página copy-on-write, la MMU genera una excepción para notificar el suceso al sistema operativo</em>.
Siguiendo lo indicado en el punto anterior, la excepción se originaría porque la página está marcada como de <em>solo lectura,</em> por lo que el sistema operativo debería comprobar si se trata de un acceso a una página <em>copy-on-write</em> o a un intento real de escribir en una página de <em>sólo lectura</em>.
Para ello el sistema sólo tendría que mirar la tabla interna almacenada en el PCB.
Si se ha intentado escribir en una página de <em>solo lectura</em>, el proceso ha cometido un error y generalmente debe ser terminado.</p>
</li>
<li>
<p><em>Si el sistema detecta una escritura a una página de copy-on-write sólo tiene que copiarla en un marco libre y mapearlo en el espacio de direcciones del proceso</em> (véase la ).
Para esto se sustituye la página compartida por otra que contiene una copia pero que ya no está compartida.
Indudablemente la nueva página debe ser marcada como de escritura para que en el futuro pueda ser modificada por el proceso.</p>
</li>
<li>
<p><em>La página original marcada como copy-on-write puede ser marcada como de escritura y no como copy-on-write, pero sólo si ya no va a seguir siendo compartida</em>.
Esto es así porque una página marcada como <em>copy-on-write</em> puede ser compartida por varios procesos.</p>
</li>
<li>
<p><em>El sistema operativo puede reiniciar el proceso</em>.
A partir de ahora éste puede escribir en la página sin afectar al resto de los procesos.
Sin embargo puede seguir compartiendo otras páginas en <em>copy-on-write</em>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>El <em>copy-on-write</em> permite ahorrar memoria y tiempo en la creación de los procesos puesto que sólo se copian las páginas que son modificadas por éstos, por lo que se trata de una técnica común en múltiples sistemas operativos, como por ejemplo Microsoft Windows, Linux y Solaris.</p>
</div>
<div class="paragraph">
<p>El <em>copy-on-write</em> <em>es especialmente interesante si a continuación se va a utilizar la llamada al sistema exec() puesto que si es así copiar el espacio de direcciones completo es una pérdida de tiempo</em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_archivos_mapeados_en_memoria">17.6. Archivos mapeados en memoria</h3>
<div class="paragraph">
<p><em>Los <strong>archivos mapeados en memoria</strong> permiten acceder a un archivo como parte del espacio de direcciones virtuales de un proceso</em>.
Algunas de las características de esta técnica son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando una región del espacio de direcciones queda marcada para ser mapeada sobre una región de un archivo <em>se utiliza una estrategia similar a la comentada para el método básico de la paginación bajo demanda.
La diferencia es que las páginas son cargadas desde dicho archivo y no desde el espacio de intercambio</em>.
Es decir, en un primer acceso a una página mapeada se produce un fallo de página que es resuelto por el sistema operativo leyendo una porción del archivo en el marco asignado a la página.</p>
</li>
<li>
<p>Esto significa que <em>la lectura y escritura del archivo se realiza a través de lecturas y escrituras en la memoria</em>, lo que simplifica el acceso y elimina el costo adicional de las llamadas al sistema: <code>read()</code>, <code>write()</code>, etc.</p>
</li>
<li>
<p><em>Las escrituras en disco se suelen realizar de forma asíncrona</em>.
Para ello el sistema operativo comprueba periódicamente las páginas modificadas y las escribe en disco.</p>
</li>
<li>
<p><em>Los marcos utilizados en el mapeo pueden ser compartidos, lo que permite compartir los datos de los archivo</em>.
Además se puede incluir soporte de <em>copy-on-write</em>, lo que permite a los procesos compartir un archivo en modo de sólo lectura pero disponiendo de sus propias copias de aquellas páginas que modifiquen.
Indudablemente para que los procesos puedan compartir datos es necesario que exista algún tipo de coordinación (véase el <a href="#_sincronización">Capítulo 13</a>).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Algunos sistemas operativos ofrecen el servicio de mapeo de archivos en la memoria sólo a través de una llamada al sistema concreta, permitiendo utilizar las llamadas estándar —<code>read()</code>, <code>write()</code>, etc.— para hacer uso de la E/S tradicional.
Sin embargo <em>muchos sistemas modernos utilizan el mapeo en la memoria independientemente de que se pidan o no</em>.
Por ejemplo, en Linux si un proceso utiliza llamada al sistema <code>mmap()</code> es porque explícitamente pide que el archivo sea mapeado en memoria.
Por tanto, el núcleo mapea el archivo en el espacio de direcciones del proceso.
Sin embargo, si un archivo es abierto con llamadas al sistemas estándar —como <code>open()</code>— Linux mapea el archivo en el espacio de direcciones del núcleo y traduce las llamadas <code>read()</code> y <code>write()</code> en accesos a la memoria en dicha región.
No importa como sea abierto el archivo, Linux trata toda la E/S a archivos como mapeada en memoria, permitiendo que el acceso a los mismos tenga lugar a través del eficiente componente de gestión de la memoria.</p>
</div>
</div>
<div class="sect2">
<h3 id="_reemplazo_de_página">17.7. Reemplazo de página</h3>
<div class="paragraph">
<p>Hasta el momento hemos considerado que disponemos de memoria física suficiente para atender cualquier fallo de página pero ¿qué pasa cuando no quedan marcos libres?.
En ese caso el código que da servicio a la excepción de fallo de página debe escoger alguna página, intercambiarla con el disco y utilizar el marco de la misma para cargar la nueva página.
Es decir, debemos modificar la función que ejecuta los pasos descritos en el <a href="#_protección_y_seguridad">Apartado 4.7</a> de la siguiente manera:</p>
</div>
<div class="paragraph">
<p>["arabic", start=4] .
. <em>Si la página es legal, debe ser cargada desde el disco</em>.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><em>Buscar la localización de la página en disco</em>.</p>
</li>
<li>
<p><em>El núcleo debe buscar un marco de memoria libre</em> que, por ejemplo, se puede escoger de la lista de marcos libres del sistema.</p>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p><em>Si hay uno, usarlo</em>.</p>
</li>
<li>
<p><em>Si no hay, usar un algoritmo de reemplazo de página para seleccionar una víctima</em>.</p>
</li>
<li>
<p><em>Escribir la víctima en el disco</em> y cambiar las tablas de paginas y de marcos libres de acuerdo a la nueva situación.
Para evitar mantener la CPU ocupada, el sistema debe solicitar la escritura de la página y poner al proceso en estado de espera.</p>
</li>
</ol>
</div>
</li>
<li>
<p><em>Se solicita una operación de disco para leer la página deseada en el marco asignado</em>.
Para evitar mantener la CPU ocupada, el sistema debe solicitar la escritura de la página y poner al proceso en estado de espera.</p>
</li>
<li>
<p><em>Cuando la lectura del disco haya terminado se debe modificar la tabla interna de páginas válidas y la tabla de páginas para indicar que la página está en la memoria.</em></p>
</li>
<li>
<p><em>Reiniciar el proceso interrumpido</em>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Es importante destacar que <em>en caso de reemplazo se necesita realizar dos accesos al disco.
Esto se puede evitar utilizando un <strong>bit de modificado</strong> asociado a cada página en la tabla de páginas</em>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Este bit es puesto a 1 por el hardware cuando se modifica la página</em>.</p>
</li>
<li>
<p><em>Se puede evitar escribir en disco aquellas páginas que tienen este bit a 0 cuando son seleccionada para reemplazo</em>, siempre que el contenido de la página no haya sido sobrescrito por otra en el espacio de intercambio</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En general para implementar la paginación bajo demanda necesitamos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Un algoritmo de asignación de marcos</em> que se encarga de asignar los marcos a los procesos.</p>
</li>
<li>
<p><em>Un algoritmo de reemplazo de página</em> para seleccionar que página reemplazamos cuando no hay marcos suficientes.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Obviamente estos algoritmos deben ser escogidos de forma que mantengan la tasa de fallos de página lo más baja posible.</p>
</div>
<div class="sect3">
<h4 id="_algoritmos_de_reemplazo_de_páginas">17.7.1. Algoritmos de reemplazo de páginas</h4>
<div class="paragraph">
<p>Existen diversos criterios para escoger la página que reemplazamos cuando no hay suficientes marcos disponibles.
En cualquier caso <em>el algoritmo óptimo —el que garantiza la tasa de fallos de página más baja— consiste en seleccionar siempre la página que más se va a tardar en necesitar</em>.
Desafortunadamente <em>este algoritmo es difícil de implementar puesto que necesita tener información acerca de cuáles van a ser las páginas referencias en el futuro</em>.
Por eso sólo se puede utilizar en estudios comparativos con el fin de saber cuanto se aproxima al óptimo un algoritmo de reemplazo concreto.</p>
</div>
<div class="paragraph">
<p>Otros algoritmos de reemplazo pueden utilizar uno o varios de los siguientes criterios:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Reemplazar la página que hace más tiempo que fue cargada</em>.
Este criterio da lugar al algoritmo FIFO de reemplazo que no siempre tiene un buen rendimiento puesto que la página más antigua no necesariamente es la que se va a tardar más tiempo en necesitar —que sería la elección óptima—.</p>
</li>
<li>
<p><em>Reemplazar la página que hace más tiempo que fue utilizada</em> bajo la hipótesis de que si una página no ha sido usada durante un gran periodo de tiempo, entonces es poco probable que vaya a serlo en el futuro.
Este criterio da lugar a la familia de algoritmos <strong>LRU</strong> (Least Recently Used):</p>
<div class="ulist">
<ul>
<li>
<p><em>Estos algoritmos requieren de soporte por parte del hardware</em> puesto que al sistema operativo no se le notifican los acceso legales a las páginas, por lo que no tiene forma de saber cuando una página fue usada por última vez.</p>
</li>
<li>
<p><em>Normalmente el soporte por parte del hardware es a través de un bit en la tabla de páginas llamado <strong>bit de referencia</strong></em>.
Este bit se pone a 1 cada vez que una instrucción ejecutada en la CPU referencia a una página, lo que permite al sistema operativo hacerse una idea aproximada<sup class="footnote">[<a id="_footnoteref_19" class="footnote" href="#_footnotedef_19" title="View footnote.">19</a>]</sup> de las páginas que han sido usadas recientemente.
A los algoritmos que siguen esta aproximación se los denomina <em>*NRU*</em> (Not Recently Used).</p>
</li>
<li>
<p><em>Dentro de los algoritmos NRU también están aquellos que son mejorados incluyendo el valor del bit de modificado en el criterio de elección de la página</em>.
Estos algoritmos escogen las páginas no referencias antes que las referencias —para lo que utilizan el valor del bit de referencia— y dentro de cada clase las no modificadas antes que las modificadas —para lo que utilizan el valor del bit de modificado— para evitar en lo posible reemplazar páginas cuyo contenido tiene que ser escrito en disco.</p>
</li>
</ul>
</div>
</li>
<li>
<p><em>Reemplazar la página que ha sido usada con mayor o menos frecuencia</em> utilizando contadores de referencias para cada página —almacenados en la tabla de páginas— que sos actualizados por el hardware en cada referencia.
Este criterio da lugar a los algoritmos <strong>LFU</strong> (Least Frequently Used) —cuando se escogen las páginas utilizadas con menos frecuencia— y <strong>MFU</strong> (Most Frequently Used) —cuando se escogen las páginas utilizadas con más frecuencia—.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_algoritmos_de_buffering_de_páginas">17.7.2. Algoritmos de buffering de páginas</h4>
<div class="paragraph">
<p>Existen otros procedimientos que pueden ser utilizados, junto con alguno de los algoritmos de reemplazo comentados, con el objetivo de mejorar su eficiencia.
Estos procedimientos se agrupan dentro de lo que se denomina algoritmos de <strong>buffering de páginas</strong>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Se puede mantener una lista de marcos libres</em>.
Cuando se produce un fallo de paginas se escoge un marco de la lista y se carga la página, al tiempo que se selecciona una página como víctima y se copia al disco.
Esto permite que el proceso se reinicie lo antes posible, sin esperar a que la página reemplazada sea escrito en el disco.
Posteriormente, cuando la escritura finalice, el marco es incluido en la lista de marcos libres.</p>
</li>
<li>
<p>Una mejora de lo anterior sería <em>recordar que página estuvo en cada marco antes de que éste pasara a la lista de marcos libres</em>.
De esta forma las páginas podrían ser recuperadas directamente desde la lista si fallara alguna antes de que su marco fuera utilizado por otra página.
Esto permite reducir los efectos de que el algoritmo de reemplazo escoja una víctima equivocada.</p>
</li>
<li>
<p><em>Se puede mantener una lista de páginas modificadas e ir escribiéndolas cuando el dispositivo del espacio de intercambio no esté ocupado</em>.
Este esquema aumenta la probabilidad de que una página esté limpia cuando sea seleccionada por el algoritmo de reemplazo, evitando la escritura en disco.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_reemplazo_local_frente_a_global">17.7.3. Reemplazo local frente a global</h4>
<div class="paragraph">
<p>Cuando un proceso necesita un marco el algoritmo de reemplazo puede tanto extraerlo de cualquier proceso como ser obligado a considerar sólo aquellas páginas que pertenecen al proceso que generó el fallo.
Eso permite clasificar los algoritmos de reemplazo en dos categorías:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>En <em>el <strong>reemplazo local</strong> sólo se pueden escoger marcos de entre los asignados al proceso</em>.</p>
<div class="ulist">
<ul>
<li>
<p>El número de marcos asignados a un proceso no cambia por que ocurran fallos de páginas.</p>
</li>
<li>
<p>El mayor inconveniente es que <em>un proceso no puede hacer disponible a otros procesos los marcos de memoria que menos usa</em>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>En <em>el <strong>reemplazo global</strong> se pueden escoger marcos de entre todos los del sistema</em>, independientemente de que estén asignados a otro proceso o no.</p>
<div class="ulist">
<ul>
<li>
<p>El número de marcos asignados a un proceso puede aumentar si durante los fallos de página se seleccionan marcos de otros procesos.</p>
</li>
<li>
<p>El mayor inconveniente <em>es que los procesos no pueden controlar su tasa de fallos de página</em>, puesto que esta depende del comportamiento de los otros procesos, afectando al tiempo de ejecución de forma significativa.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Generalmente <em>el reemplazo global proporciona mayor rendimiento por lo que es el método más utilizado</em>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_asignación_de_marcos_de_página">17.8. Asignación de marcos de página</h3>
<div class="paragraph">
<p>La cuestión que queda por resolver es cómo repartir los marcos de memoria física libre entre los diferentes procesos con el fin de cubrir las necesidades de reemplazo de cada uno de ellos.
Posibles soluciones a esto serían: repartir la memoria por igual entre todos los procesos o hacerlo en proporción a la cantidad de memoria virtual que utilizan.
Sin embargo parece que puede ser interesante determinar el mínimo número de marcos que realmente necesita cada proceso, pues así el sistema podría disponer de memoria libre para aumentar el número de procesos —aumentando el uso de la CPU— o para dedicarla a otras funciones —como es el caso de los <em>búferes</em> y las cachés de E/S —.</p>
</div>
<div class="paragraph">
<p>El mínimo número de marcos viene establecido por diversos factores:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando ocurre un fallo de página la instrucción que la ha provocado debe ser reiniciada después de cargar la página en un marco libre.
Por lo tanto <em>un proceso debe disponer de suficientes marcos como para guardar todas las páginas a las que una simple instrucción pueda acceder</em>, pues de lo contrario el proceso nunca podría ser reiniciado al fallar permanentemente en alguno de los acceso a memoria de la instrucción.
Obviamente este límite viene establecido por la arquitectura de la máquina.</p>
</li>
<li>
<p>Todo proceso tiene una cierta cantidad de páginas que en cada instante son utilizadas frecuentemente.
<em>Si el proceso no dispone de suficientes marcos como para alojar dichas páginas, generará fallos de página con demasiada frecuencia</em>.
Esto afecta negativamente al rendimiento del sistema, por lo que es conveniente que el sistema asigne al número de marcos necesario para que eso no ocurra.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En general, si se va reduciendo el número de marcos asignados a un proceso, mucho antes de haber alcanzado el mínimo establecido por la arquitectura, el proceso dejará de ser útil debido a la elevada tasa de fallos de página, que será mayor cuantos menos marcos tenga asignados.
Cuando eso ocurre se dice que el proceso está <em>hiperpaginando</em>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_hiperpaginación">17.9. Hiperpaginación</h3>
<div class="paragraph">
<p>Se dice que _un proceso sufre de <strong>hiperpaginación</strong> cuando gasta más tiempo paginando que ejecutándos_e.</p>
</div>
<div class="sect3">
<h4 id="_causas_de_la_hiperpaginación">17.9.1. Causas de la hiperpaginación</h4>
<div class="paragraph">
<p>En los primeros sistemas multiprogramados que implementaron la paginación bajo demanda era posible que se diera el siguiente caso:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>El sistema operativo monitorizaba el uso de la CPU</em>.
Si el uso de la misma era bajo, se cargaban nuevos procesos desde la cola de entrada para aumentar el grado de multiprogramación.</p>
</li>
<li>
<p><em>Si un proceso necesitaba demasiada memoria, le podía quitar los marcos a otro</em> puesto que se utilizaba un algoritmo de reemplazo global.
Esto podía ocasionar que aumentara la tasa de fallos de página del proceso que perdía los marcos.</p>
</li>
<li>
<p><em>Al aumentar los fallos de pagina el uso de la CPU decrecía</em>, por lo que el sistema operativo cargaba más procesos para aumentar el grado de multiprogramación y con ello el uso de la CPU.</p>
</li>
<li>
<p><em>Esto reducía la cantidad de memoria disponible para cada proceso</em>, lo que aumentaba la tasa de fallos de páginas que nuevamente reducía el uso de la CPU</p>
</li>
<li>
<p>Este mecanismo iteraba hasta reducir considerablemente el rendimiento del sistema.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>El fenómeno comentado se ilustra en la donde el uso de la CPU es trazado frente al número de procesos cargados en el sistema.
Cuando esto último aumenta el uso de la CPU aumenta hasta alcanzar un máximo.
Si el grado de multiprogramación supera dicho punto, el sistema comienza a hiperpaginar, por lo que el uso de la CPU disminuye bruscamente.
Por lo tanto, si el sistema está hiperpaginando, es necesario reducir el grado de multiprogramación con el objetivo de liberar memoria.</p>
</div>
<div class="paragraph">
<p>En los sistemas de tiempo compartido modernos ocurre algo parecido a lo descrito para los sistemas multiprogramados, aunque sin el efecto en cadena ocasionado por el intento del planificador de largo plazo de maximizar el uso de la CPU, ya que estos sistemas carecen de dicho planificador.
Sea como fuere, <em>en ambos casos los procesos hiperpaginarán si no se les asigna un número suficiente de marcos</em>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_soluciones_a_la_hiperpaginación">17.9.2. Soluciones a la hiperpaginación</h4>
<div class="paragraph">
<p>Para el problema de la hiperpaginación existen diversas soluciones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Utiliza un algoritmo de reemplazo local</em> pues de esta manera un proceso que hiperpagina no puede afectar a otro.
Sin embargo, el uso intensivo del dispositivo de intercambio podría afectar al rendimiento del sistema al aumentar el tiempo de acceso efectivo.</p>
</li>
<li>
<p><em>Proporcionar a un proceso tantos marcos como le hagan falta</em>.
Como ya hemos comentados en diversas ocasiones, para evitar la hiperpaginación es necesario asignar al procesos al menos un número mínimos de marcos, que a priori no es conocido.
Una de las estrategias que pretenden estimar dicho número es el <strong>modelo de conjunto de trabajo</strong>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_modelo_del_conjunto_de_trabajo">17.9.3. Modelo del conjunto de trabajo</h4>
<div class="paragraph">
<p>Para entender el modelo de conjunto de trabajo es necesario comenzar definiendo el <strong>modelo de localidad</strong>.
El modelo de localidad establece que:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Una localidad es un conjunto de páginas que se utilizan juntas</em>.</p>
</li>
<li>
<p><em>Cuando un proceso se ejecuta se va moviendo de una localidad a otra</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Por ejemplo, cuando se invoca una función se define una nueva localidad.
En esta localidad las referencias a la memoria se realizan al código de la función, a las variables locales de la misma y a algunas variables globales del programa.</p>
</div>
<div class="paragraph">
<p>Supongamos que proporcionamos a un proceso suficientes marcos como para alojar toda su localidad en un momento dado.
Entonces el proceso generará fallos de página hasta que todas las páginas de su localidad estén cargadas, pero después de eso no volverá a fallar hasta que no cambie a una nueva localidad.
Sin embargo <em>si damos al proceso menos marcos de los que necesita su localidad, éste hiperpaginará</em>.</p>
</div>
<div class="paragraph">
<p><em>El <strong>modelo de conjunto de trabajo</strong> es una estrategia que permite obtener una aproximación de la localidad del programa</em> y consiste en lo siguiente:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Definir el parámetro \$Delta\$ como el tamaño de la ventana del conjunto de trabajo</em>.</p>
</li>
<li>
<p><em>En un instante dado el conjunto de páginas presente en las \$Delta\$ referencias más recientes a la memoria se consideran el <strong>conjunto de trabajo</strong></em>.</p>
</li>
<li>
<p>Por lo tanto, <em>el <strong>conjunto de trabajo</strong> es una aproximación de localidad del programa</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Por ejemplo, dada la siguiente lista de referencias a páginas en la memoria memoria:</p>
</div>
<div class="paragraph">
<p>si \$Delta = 10\$ referencias a la memoria, entonces el conjunto de trabajo en \$t_1\$ es \${1, 2, 5, 6, 7}\$.
Mientras que en \$t_2\$ el conjunto de trabajo es \${3, 4}\$.</p>
</div>
<div class="paragraph">
<p>Obviamente <em>la precisión del conjunto de trabajo como aproximación de la localidad del programa depende del parámetro \$Delta\$</em>.
Por ejemplo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Si \$Delta\$ es muy pequeña, el conjunto de trabajo no cubría toda la localidad.</p>
</li>
<li>
<p>Si \$Delta\$ es muy grande, el conjunto de trabajo se superpondrían a varias localidades.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_uso_del_conjunto_del_trabajo_para_evitar_la_hiperpaginación">17.9.4. Uso del conjunto del trabajo para evitar la hiperpaginación</h4>
<div class="paragraph">
<p>El uso del conjunto de trabajo es bastante sencillo:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Se selecciona \$Delta\$</em>.</p>
</li>
<li>
<p><em>El sistema operativo monitoriza el conjunto de trabajo de cada proceso y le asigna tantos marcos como páginas haya en el conjunto de trabajo</em>.</p>
</li>
<li>
<p><em>Si sobran suficientes marcos otro proceso puede ser iniciado —en el caso de los sistemas multiprogramados— o se puede destinar la memoria libre a otros usos</em>.</p>
</li>
<li>
<p><em>Si el tamaño del conjunto de trabajo D crece y excede el número de marcos disponibles, el sistema podría seleccionar un proceso para ser suspendido</em>.
Éste podrá volver a ser reiniciado más tarde.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Donde el tamaño del conjunto de trabajo \$D\$ es la suma del tamaño de los conjuntos de trabajo \$WSS^i\$ para cada proceso \$i\$:</p>
</div>
<div class="stemblock">
<div class="content">
\$D=sum WSS_i\$
</div>
</div>
<div class="paragraph">
<p>y representa la demanda total de marcos.
Por eso <em>si \$D\$ es mayor que el número de marcos disponibles, habrá hiperpaginación</em>.</p>
</div>
<div class="paragraph">
<p>Este sencillo algoritmo anterior permite evitar la hiperpaginación.
Sin embargo, el problema está en como mover la ventana del conjunto de trabajo en cada referencia, con el fin de volver a calcular el conjunto de trabajo.
Una posible aproximación sería utilizar un temporizador que periódicamente invocase a una función encargada de examinar el bit de referencia de las páginas en la ventana <em>\$Delta\$</em>.
Es de suponer que las páginas con el bit de referencia a 1 forman parte de la localidad del programa y por tanto serán el conjunto de trabajo a lo largo del siguiente periodo.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_otras_consideraciones">17.10. Otras consideraciones</h3>
<div class="paragraph">
<p>Ya hemos comentado que las principales decisiones que deben ser tomadas en el diseño de un sistema con paginación bajo demanda son la elección del algoritmo de reemplazo y la del de asignación de marcos de página.
Sin embargo hay otras consideraciones que deben ser tenidas en cuenta.</p>
</div>
<div class="sect3">
<h4 id="_prepaginado">17.10.1. Prepaginado</h4>
<div class="paragraph">
<p><em>El <strong>prepaginado</strong> es una técnica que consiste en cargar múltiples páginas junto con la página demandada en cada fallo de página</em>.
Esas otras páginas se escogen especulativamente bajo la hipótesis de que van a ser necesitadas por el proceso en un corto espacio de tiempo, de manera que si la predicción es acertada la tasa de fallos de página se reduce significativamente.
Esta técnica puede ser utiliza, por ejemplo, en las siguiente situaciones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>En la paginación bajo demanda pura, donde el sistema sabe de antemano que cuando se inicia un proceso siempre fallan las primeras páginas de código, por lo que son buenas candidatas para el prepaginado.</p>
</li>
<li>
<p>En el acceso secuencial a archivos mapeados en memoria.
El sistema puede determinar que el acceso es de ese tipo tanto mediante el uso de técnicas heurísticas como mediante las indicaciones dadas por el proceso en la llamada al sistema con la que se abrió el archivo.
En cualquier caso, si el sistema determina que el acceso al archivo es secuencial, en cada fallo de página puede cargar tanto la página demanda como las siguientes en previsión de que vayan a ser utilizas por el proceso.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En general el único inconveniente del prepaginado es que debe ser ajustarlo para que el coste del mismo sea inferior al de servir los fallos de página.</p>
</div>
</div>
<div class="sect3">
<h4 id="_aplicaciones_en_modo_raw">17.10.2. Aplicaciones en modo RAW</h4>
<div class="paragraph">
<p><em>Algunas aplicaciones al acceder a sus datos a través de los mecanismos de memoria virtual del sistema operativo ofrecen peor rendimiento del que conseguirían si este mecanismo no existiera</em>.
El ejemplo típico son las bases de datos, que conocen sus necesidades de memoria y disco mejor que cualquier sistema operativo de propósito general, por lo que salen beneficiadas si implementan sus propios algoritmos de gestión de la memoria y de buffering de E/S.</p>
</div>
<div class="paragraph">
<p><em>Muchos sistemas operativos modernos permiten que los programas que lo soliciten puedan acceder a los discos en modo raw</em>.
En el <em>modo raw</em> no hay sistemas de archivos, ni paginación bajo demanda, ni bloqueo de archivos, ni prepaginación, ni nada; por lo que dichas aplicaciones deben implementar sus propios algoritmos de almacenamiento y gestión de la memoria.
Sin embargo, hay que tener en cuenta que la mayor parte de las aplicaciones siempre funcionan mejor utilizando los servicios convencionales ofrecidos por el sistema operativo.</p>
</div>
</div>
<div class="sect3">
<h4 id="_tamaño_de_las_páginas_2">17.10.3. Tamaño de las páginas</h4>
<div class="paragraph">
<p>Como ya comentamos al estudiar el método básico de paginación (véase el <a href="#_paginación">Capítulo 16</a>), una decisión de diseño importante es escoger el tamaño adecuado para las páginas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Con páginas grandes</strong>:</p>
<div class="ulist">
<ul>
<li>
<p><em>Se consiguen menos fallos de páginas</em>.
Por ejemplo, en un caso extremo un proceso de 100 KB solo podría generar un fallo de página si cada página es de 100 KB, pero puede generar 102400 fallos si cada pagina es de 1 byte.</p>
</li>
<li>
<p><em>Se consiguen tablas de páginas más pequeñas</em>.</p>
</li>
<li>
<p><em>La E/S para acceder al contenido de cada página requiere menos tiempo</em>.
En general el tiempo de transferencia es proporcional a la cantidad de información transferida, lo que debería beneficiar a los sistemas con páginas de pequeño tamaño.
Sin embargo la latencia y el tiempo requerido para posicionar la cabeza lectora de los discos es muy superior al tiempo de transferencias de datos, por lo que es más eficiente tener menos transferencias de mayor tamaño —como cuando se usan páginas de grandes— que más transferencias de menor tamaño —como cuando se usan páginas pequeñas—.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Con páginas pequeñas</strong>:</p>
<div class="ulist">
<ul>
<li>
<p><em>Se consigue tener menos fragmentación interna</em> y por tanto un mejor aprovechamiento de la memoria.</p>
</li>
<li>
<p><em>Teóricamente se obtiene mejor resolución para asignar y transferir al disco sólo la memoria que realmente necesitamos</em>.
Esto a la larga debería redundar en menos memoria asignada y menos operaciones de E/S.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>En la actualidad el tamaño de página más común es de 4KB en sistemas de 32 bits y 8 KB en los de 64 bits, ya que son adecuados para la mayor parte de las aplicaciones.
Sin embargo, <em>muchos sistemas modernos soportan el uso simultáneo de múltiples tamaños de página</em>.
Esto permite que la mayor parte de las aplicaciones utilicen el tamaño estándar, mientras las que hacen un uso intensivo de la memoria puedan utilizar páginas de mayor tamaño.
Por ejemplo, en la familia Intel x86 el tamaño estándar es de 4 KB, pero muchas bases de datos —como por ejemplo Oracle— y núcleos de sistema operativo —como por ejemplo Linux o Solaris— utilizan páginas de 4 MB<sup class="footnote">[<a id="_footnoteref_20" class="footnote" href="#_footnotedef_20" title="View footnote.">20</a>]</sup> cuando corren sobre dicha arquitectura.</p>
</div>
</div>
<div class="sect3">
<h4 id="_efecto_de_la_estructura_de_los_programas">17.10.4. Efecto de la estructura de los programas</h4>
<div class="paragraph">
<p><em>Los programas estructurados con un buena localidad de referencia pueden mejorar su rendimiento en los sistemas con paginación bajo demanda</em>.</p>
</div>
<div class="paragraph">
<p>Vamos a ilustrarlo con el siguiente ejemplo de un programa que inicializa a 0 un <em>array</em> de 128 por 128 elementos.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="cpp"><span class="kt">int</span> <span class="n">data</span><span class="p">[][]</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="p">[</span><span class="mi">128</span><span class="p">][</span><span class="mi">128</span><span class="p">];</span>

<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Un <em>array</em> como el indicado es almacenado en filas:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="cpp"><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="p">...,</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">127</span><span class="p">]</span>
<span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="p">...,</span> <span class="n">data</span><span class="p">[</span><span class="mi">127</span><span class="p">][</span><span class="mi">127</span><span class="p">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>De manera que si suponemos que el tamaño de cada página es de 128 palabras, en el mejor de los casos cada fila estará almacenada en una página.
Por lo tanto:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Si el sistema le asigna 128 marcos o más, el proceso solo generará 128 fallos de página.</p>
</li>
<li>
<p>Si el sistema operativo le asigna un solo marco, el proceso tendrá 16,384 fallos aproximadamente.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Sin embargo, el ejemplo sería diferente si el bucle interno del programa recorriera las columnas del <em>array</em> y no las filas:</p>
</div>
<div class="paragraph">
<p>Pues se podrían a 0 primero todas las palabras de una misma página antes de empezar con la siguiente, reduciendo el número de fallos de página a 128 aunque el sistema operativo sólo asigne un marco al proceso.</p>
</div>
<div class="paragraph">
<p>Por lo tanto se puede concluir que:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>La selección cuidadosa de las estructuras de datos y de programación pueden mejorar la localidad, reduciendo la tasa de fallos de páginas y el tamaño del conjunto de trabajo</em>.
Por ejemplo, las pilas tienen buena localidad puesto que el acceso siempre se realiza en lo alto de las mismas.
Sin embargo las tablas de dispersión, obviamente, están diseñadas para dispersar las referencias, lo que produce una mala localidad.</p>
</li>
<li>
<p><em>La elección del lenguaje de programación también puede tener efecto</em>.
En los lenguajes como C y C&#43;&#43; se utilizan punteros con frecuencia, lo que aleatoriza el acceso a la memoria empeorando la localidad de referencia.
Además algunos estudios indican que los lenguajes orientados a objetos tienden a tener peor localidad de referencia que los que no lo son.</p>
</li>
<li>
<p><em>El compilador y el cargador también pueden tener un efecto importante</em>:</p>
<div class="ulist">
<ul>
<li>
<p><em>Separando el código de los datos para permitir que las paginas de código pueda ser de sólo lectura</em>.
Esto es interesante porque las paginas no modificadas no tienen que ser escritas antes de ser reemplazadas.</p>
</li>
<li>
<p><em>El compilador puede colocar las _funciones</em> que se llaman entre sí en la misma página._</p>
</li>
<li>
<p><em>El cargador puede situar las _funciones</em> <em>en la memoria _de _tal</em> forma que <em>en lo posible no _crucen los bordes de las páginas</em>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_interbloqueo_de_es">17.10.5. Interbloqueo de E/S</h4>
<div class="paragraph">
<p><em>Supongamos que un proceso solicita una operación de E/S sobre el contenido de alguna de las páginas de su espacio de direcciones y que la página es reemplazada después de que el proceso queda en espera pero antes de que la operación es realizada</em>.
En ese caso la operación de E/S se podría acabar realizando sobre una página que pertenece a un proceso diferente.
Para evitarlo existen diversas soluciones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Se puede utilizar la memoria del núcleo como búfer en las operaciones de E/S</em>.
En una escritura esto obliga a la llamada al sistema a copiar los datos desde las páginas del proceso a la memoria del núcleo antes de solicitar la operación de E/S.
Mientras que en las operaciones de lectura sería justo al contrario.</p>
</li>
<li>
<p><em>Cada página puede tener un bit de bloqueo</em> que se utiliza para indicar que páginas no pueden ser seleccionadas para reemplazo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><em>Además los bits de bloqueo se pueden utilizar en otras muchas situaciones</em>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Bloquear las páginas del núcleo para evitar que sean reemplazadas</em>.</p>
</li>
<li>
<p><em>Bloquear las páginas que acaban de ser cargadas</em>.
Esto evita que un proceso de mayor prioridad pueda reclamar el marco antes de que el proceso para el que se cargó la página sea reiniciado, desperdiciando el trabajo de cargarla y provocando un nuevo fallo de página.
Para implementarlo se puede poner el bit de bloqueo a 1 cuando la página se carga, volviéndolo a poner a 0 cuando el proceso es planificado por primera vez después del fallo de página que provocó la carga de la misma.</p>
</li>
<li>
<p><em>En los sistemas con tiempo real flexible se suele permitir que las tareas de tiempo real informen de cuales son las páginas más importantes con el fin de que sean bloqueadas para evitar que puedan ser reemplazadas</em>.
Para evitar riesgos, el sistema suele considerar estás solicitudes como <em>consejos de bloqueo</em>, de manera que es libre de descartar dichos consejos si el conjunto de marcos libres llega a ser demasiado pequeño o si un proceso concreto pide bloquear demasiadas páginas.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_interfaz_de_gestión_de_la_memoria">18. Interfaz de gestión de la memoria</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Gracias a la abstracción de las técnicas de memoria virtual —como la paginación bajo demanda— desde el punto de vista de los procesos en cualquier sistema moderno <em>prácticamente sólo hace falta una llamada al sistema para gestionar su espacio de direcciones virtual</em>.
En los sistemas POSIX —como GNU/Linux— esta llamada es <code>mmap()</code> —junto a su opuesta <code>munmap()</code>— y sirve para:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Reservar una porción de espacio de direcciones virtual del proceso</em>.
Obviamente la llamada sólo hace la reserva para que dicha región pueda ser usada por el proceso, siendo el componente de paginación bajo demanda el responsable de asignar la memoria física que la respalda.</p>
</li>
<li>
<p><em>Establecer permisos —lectura, escritura y ejecución—, opciones de compartición entre procesos, bloqueo de páginas en la memoria física, páginas de gran tamaño, etc.</em> en la región de memoria virtual a reservar.</p>
</li>
<li>
<p><em>Mapear archivos en regiones del espacio de direcciones virtual</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Sin embargo <em>en funciones como <code>mmap()</code> la página es la unidad mínima en la gestión de la memoria</em>.
Es decir, las regiones reservadas del espacio de direcciones virtual siempre comienzan en un borde de página y su tamaño es múltiplo del tamaño de página.
La cuestión es como compatibilizar eso con las necesidades reales de los programas, que durante su ejecución necesitan reservar y liberar constantemente memoria para pequeños elementos como: <em>arrays</em>, cadenas de texto, estructuras, objetos, etc.
Para esos casos <em>utilizar directamente <code>mmap()</code> no es una solución puesto que la fragmentación interna con llevaría un importante derroche de recursos</em>.</p>
</div>
<div class="sect2">
<h3 id="_uso_del_espacio_de_direcciones_virtual_del_proceso">18.1. Uso del espacio de direcciones virtual del proceso</h3>
<div class="paragraph">
<p>Los procesos pueden utilizar diversas ubicaciones dentro de su espacio de direcciones virtual para almacenar los datos que necesitan para su ejecución (véase la ):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>La variables y constantes globales se almacenan en la sección de datos</em>, que tiene tamaño fijo ya que las dimensiones de estas variables se conocen de antemano en tiempo de compilación, al igual que ocurre con el código del programa.</p>
</li>
<li>
<p><em>Las variables locales y los argumentos de las _funciones</em> se almacenan en la pila_ junto con la direcciones de retorno de las mismas.
Esta es la ubicación ideal puesto que al retornar de una función, la pila se restablece al estado previo al que tenía cuando se invocó dicha función, haciendo que las variables locales y argumentos desaparezcan automáticamente.</p>
</li>
<li>
<p><em>Las variables asignadas dinámicamente —por ejemplo, usando <code>malloc()</code>/<code>free()</code> en C o <code>new</code>/<code>delete</code> en C&#43;&#43; o Java— se almacenan en el montón</em>, que no es más una región continua de memoria ubicada inmediatamente después de la sección de datos del proceso.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Cada lenguaje de programación debe proporcionar —por ejemplo a través de su <em>librería estándar</em>— un mecanismo en espacio de usuario adecuado para la gestión en tiempo de ejecución de la memoria del <em>montón</em> del proceso.
Para eso cada lenguaje puede utilizar su propia implementación de dicho mecanismo o bien recurrir a la proporcionada por la <em>librería del sistema</em>.
Por ejemplo, en los sistemas POSIX la <em>librería del sistema</em> proporciona su propia implementación, accesible a través de las funciones <code>malloc()</code> y <code>free()</code>, que es utilizada directamente por los programas escritos en C.
Otros lenguajes de programación tienen otras interfaces para gestionar la memoria pero utilizan internamente las funciones <code>malloc()</code> y <code>free()</code> de la <em>librería estándar</em>.
Pero este no es el caso ni de C&#43;&#43; ni de Java ni de otros muchos lenguajes; donde los operadores <code>new</code> y <code>delete</code> utilizan sus propios algoritmos de gestión de la memoria del montón más optimizados que <code>malloc()</code> y <code>free()</code> para la creación y destrucción de objetos de manera eficiente.</p>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_de_la_memoria_del_montón">18.2. Gestión de la memoria del montón</h3>
<div class="paragraph">
<p>Para ilustrar cómo se gestiona la memoria del <em>montón</em> utilizaremos como ejemplo el mecanismo empleado por la <em>librería del sistema</em> de los sistemas POSIX —accesible a través de las funciones <code>malloc()</code> y <code>free()</code>— aunque es importante tener en cuenta que esta tarea se realiza de manera muy similar en las implementaciones de otros sistemas operativos y lenguajes de programación.</p>
</div>
<div class="paragraph">
<p>El funcionamiento básico de <code>malloc()</code> sigue las siguiente reglas:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Cuando la memoria solicitada supera cierto umbral —128KB en sistemas GNU/Linux— es reservada directamente mediante la llamada al sistema `mmap()`</em>.
Eso significa que las peticiones de gran tamaño realmente no consumen espacio del <em>montón</em>.</p>
</li>
<li>
<p><em>En caso contrario la petición de memoria se atiende utilizando un algoritmo de reserva de memoria continua sobre el espacio libre en el montón.</em> Estos algoritmos los veremos posteriormente.</p>
</li>
<li>
<p><em>Si no hay suficiente memoria libre contigua como para atender la petición se utiliza la llamada al sistema <code>brk()</code> para ampliar el tamaño del montón</em> sobre la región no asignada del espacio de direcciones virtual del proceso.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Cuando un proceso hace una petición de memoria dinámica espera que el espacio ofrecido sea continuo en el espacio de direcciones virtual, por lo que es necesario utilizar algún algoritmo de <strong>asignación de memoria contigua</strong>.
Como las peticiones de los procesos son de tamaño variable, la forma más eficiente de enfrentar este problema es utilizando lo que se denomina un esquema de <strong>particionado dinámico</strong>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>La librería mantiene una lista indicando que regiones del montón están libres y cuales no</em>.
El montón se inicializa con un tamaño determinado completamente libre, por lo que es considerado como un gran hueco de memoria disponible.</p>
</li>
<li>
<p><em>Cuando un proceso realiza una petición —a través de <code>malloc()</code>— se busca un hueco lo suficientemente grande para atenderla</em>.
Si se encuentra, sólo se le asigna el espacio necesario, que es marcado como ocupado en la lista.
El resto sigue siendo considerado como un hueco libre, aunque de menor tamaño.</p>
</li>
<li>
<p><em>Si el proceso libera una porción de la memoria y se crean dos huecos adyacentes, se funden en uno solo</em>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>En general, en un momento dado tenemos una petición de tamaño <em>n</em> que debemos satisfacer con una lista de huecos libres de tamaño variable.
Esto no es más que un caso particular del <em>problema _clásico</em> de la asignación dinámica de almacenamiento_ para el que hay diversas soluciones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>En el <strong>primer ajuste</strong> se escoge el primer hueco lo suficientemente grande como para satisfacer la petición</em>.
La búsqueda puede ser desde el principio de la lista o desde donde ha terminado la búsqueda anterior.</p>
</li>
<li>
<p><em>En el <strong>mejor ajuste</strong> se escoge el hueco más pequeño que sea lo suficientemente grande para satisfacer la petición</em>.
Indudablemente esto obliga a recorrer la lista de huecos completa o a tenerla ordenada por tamaño.</p>
</li>
<li>
<p><em>En el <strong>peor ajuste</strong> se escoge el hueco más grande</em>.
Igualmente obliga a buscar en toda la lista de huecos o a tenerla ordenada por tamaño.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En la actualidad <em>la estrategia más común es utilizar el mejor ajuste junto con algún tipo de estructura de datos que mantenga los huecos libres ordenados por tamaño</em>, de manera que puedan ser encontrados eficientemente.</p>
</div>
</div>
<div class="sect2">
<h3 id="_fragmentación">18.3. Fragmentación</h3>
<div class="paragraph">
<p>Las estrategia comentada no sufre de <em>fragmentación interna</em> porque se asigna exactamente la cantidad de memoria solicitada.
Sin embargo si sufre de otro tipo de fragmentación denominada fragmentación externa.</p>
</div>
<div class="paragraph">
<p><em>La <strong>fragmentación externa</strong> ocurre cuando hay suficiente espacio libre para satisfacer una petición pero el espacio no es contiguo</em>.
Es decir, el espacio de almacenamiento está fraccionado en un gran número de huecos de pequeño tamaño, obligando a la librería a invocar la llamada al sistema <code>brk()</code> con el objetivo de incrementar el tamaño del montón.
Este problema:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Afecta tanto a la estrategia del primer como del mejor ajuste</em>.
Siendo el primero mejor en algunos sistemas y el segundo mejor en otros.</p>
</li>
<li>
<p>Algunos análisis estadísticos realizados con el primer ajuste revelan que <em>incluso con algunas optimizaciones, con n bloques asignados se pierden 0.5n por fragmentación externa</em>.
Es decir, un tercio de la memoria no es utilizable.
A esto se lo conoce como la <em>regla del 50%</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Lamentablemente este problema no tiene una solución sencilla ya que aunque se podría intentar mover los bloques de memoria para que toda la memoria libre quedara en un único hueco, sería necesario modificar en tiempo de ejecución las direcciones virtuales utilizadas por el proceso en cada puntero o referencia a los bloques de memoria en el montón.</p>
</div>
</div>
</div>
</div>
<h1 id="_gestión_del_almacenamiento" class="sect0">Parte V: Gestión del almacenamiento</h1>
<div class="sect1">
<h2 id="_dispositivos_de_almacenamiento">19. Dispositivos de almacenamiento</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Los ordenadores pueden almacenar información en diferentes soportes de almacenamiento —por ejemplo en discos magnéticos, en DVD, en memorias de estado sólido, etc.—.
Cada uno tiene propiedades físicas diferentes que pasamos a comentar brevemente a continuación.</p>
</div>
<div class="sect2">
<h3 id="_discos_magnéticos">19.1. Discos magnéticos</h3>
<div class="paragraph">
<p>Los discos magnéticos son el tipo principal de almacenamiento secundario, generalmente en la forma de lo que se denominan discos duros.
Tal y como se puede apreciar en la cada unidad está compuesta por una serie de platos de forma circular recubiertos de material magnético.
La información se almacena grabándola magnéticamente sobre los platos, para lo cual se utilizan unas cabezas de lectura que «flotan» tanto por encima como por debajo de cada plato.</p>
</div>
<div class="paragraph">
<p>Desde el punto de vista lógico (véase la ) <em>la superficie de cada plato está dividida en <strong>pistas</strong> circulares, cada una de las cuales se subdivide en <strong>sectores</strong></em>.
<em>El conjunto de pistas formado por todas aquellas que están situadas en la misma posición en los distintos platos se denomina <strong>cilindro</strong></em>.</p>
</div>
<div class="paragraph">
<p>En estos dispositivos consume mucho más tiempo mover la cabeza de lectura hasta el sector de interés que la lectura y transferencia de los datos almacenados a la memoria RAM.
Por lo tanto el tiempo de acceso aleatorio al disco es mucho mayor que el de acceso secuencial.</p>
</div>
</div>
<div class="sect2">
<h3 id="_discos_ópticos">19.2. Discos ópticos</h3>
<div class="paragraph">
<p>Los discos ópticos —CD, DVD, BluRay, etc.— consisten en un disco circular en el cual la información se almacena haciendo uso de surcos microscópicos que se leen haciendo incidir un láser sobre una de las caras planas que lo componen.</p>
</div>
<div class="paragraph">
<p>En este tipo de discos la información se almacena siguiendo un recorrido continuo en espiral que cubre la superficie entera del disco, extendiéndose desde el interior hacia el exterior.
Dado que el láser siempre debe desplazarse sobre la espiral, el acceso aleatorio a los datos es más lento que con otras tecnologías de disco.</p>
</div>
</div>
<div class="sect2">
<h3 id="_memorias_de_estado_sólido">19.3. Memorias de estado sólido</h3>
<div class="paragraph">
<p>Una memoria de estado sólido —memoria USB, SSD, etc.— es un dispositivo de almacenamiento que usa una memoria no volátil, como las <em>memorias flash</em>, para almacenar datos, en lugar de utilizar discos ópticos o magnéticos.
En este tipo de memorias la información se almacena como en un vector lineal de bytes, que se puede indexar aleatoriamente con la misma eficiencia con la que se accede secuencialmente, como ocurre con la memoria RAM, Aunque algunos dispositivos, de cara al resto del sistema informático, emulan una interfaz y un modo de direccionamiento similar al utilizado por los discos magnéticos —es decir, usando pistas, sectores y cilindros.— por temas de compatibilidad.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_archivos_y_sistemas_de_archivos">20. Archivos y sistemas de archivos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Teniendo en cuenta la gran diversidad de dispositivos de almacenamiento que existen, para que el sistema informático sea cómodo de utilizar el sistema operativo proporciona una visión lógica uniforme de todos los sistemas de almacenamiento.
Es decir, abstrae las propiedades físicas de los dispositivos de almacenamiento para definir una unidad de almacenamiento lógico que sea útil para los usuarios.
Esta unidad es el <em>archivo</em>.</p>
</div>
<div class="paragraph">
<p><em>Un <strong>archivo</strong> es una colección de información relacionada cuya estructura y significado de sus datos los define su creador</em>.
Desde la perspectiva de los usuarios, un archivo es la unidad más pequeña de almacenamiento.
Es decir, no se pueden escribir datos en el almacenamiento secundario a menos que estos se encuentren dentro de un archivo.</p>
</div>
<div class="paragraph">
<p>El sistema operativo puede ofrecer esta abstracción gracia al <strong>sistema de archivos</strong>.
<em>Este proporciona los mecanismos para el almacenamiento de lo datos y programas en archivos</em>, tanto del propio sistema operativo como los de todos los usuarios del sistema informático.</p>
</div>
<div class="paragraph">
<p><em>Los sistemas de archivos están compuestos de dos partes claramente diferenciadas:</em></p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Una colección de archivos</em>, cada uno de los cuales almacena una serie de datos relacionados.</p>
</li>
<li>
<p><em>Una colección de estructuras de metadatos</em>, que contienen información relativa a los archivos almacenados —nombre, ubicación en el disco, permisos, etc.— y que se encarga de organizarlos, generalmente haciendo uso de una estructura de directorios.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_volúmenes_de_datos">21. Volúmenes de datos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Los dispositivos de almacenamiento comentados anteriormente pueden ser utilizados al 100% con un único sistema de archivos.
Sin embargo, en ocasiones es interesante hacer divisiones con el objeto de disponer de múltiples sistemas de archivos en el mismo dispositivo.
Cada una de esas divisiones es un <em>volumen</em>.</p>
</div>
<div class="paragraph">
<p>En otros casos interesa combinar divisiones o dispositivos de almacenamiento completos para crear espacios de mayor tamaño —también denominadas volúmenes— cada una de las cuales puede albergar un único sistema de archivos.
Así que en general <em>utilizaremos el término <strong>volumen</strong> para referirnos a un espacio de almacenamiento que alberga un sistema de archivos</em>, tanto si ese espacio es una pequeña parte del espacio completo del dispositivo como si se trata de una estructura de mayor tamaño compuesta a partir de varios dispositivos.</p>
</div>
<div class="paragraph">
<p>A continuación comentaremos brevemente las tecnologías utilizadas con mayor frecuencia para construir estos volúmenes.</p>
</div>
<div class="sect2">
<h3 id="_raid">21.1. RAID</h3>
<div class="paragraph">
<p>La tecnología <strong>RAID</strong> (<em>Redundant Array of Inexpensive Disks</em>) permite combinar varios discos duros para mejorar las prestaciones a través del paralelismo en el acceso o para mejorar la fiabilidad a través del almacenamiento de información redundante.
En concreto se definen diversos <em>niveles RAID</em>, de entre los cuales los más comunes son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>En un <strong>conjunto RAID 0</strong> se distribuyen los datos equitativamente en bloques de tamaño fijo entrelazados entre dos o más discos</em>, sin incluir ningún tipo de información redundante.
Esto permite leer y escribir más datos en el mismo tiempo ya que se pueden enviar en paralelo peticiones a los distintos discos.
Sin embargo la fiabilidad es inversamente proporcional al número de discos, ya que para que el conjunto falle basta con que lo haga cualquiera de ellos.</p>
</li>
<li>
<p><em>En un <strong>conjunto RAID 1</strong> se crea una copia exacta —en espejo— de los datos en dos o más discos</em>.
El resultado es que, incluso con dos discos, se incrementa exponencialmente la fiabilidad respecto a tener uno solo, ya que para que el conjunto falle es necesario que lo hagan todos los discos.
Adicionalmente el rendimiento en las operaciones de lectura se incrementa linealmente con el número de copias, ya que los datos están disponibles en todos los discos al mismo tiempo, por lo que se pueden balancear la operaciones de lectura entre todos ellos.</p>
</li>
<li>
<p><em>En un <strong>conjunto RAID 5</strong> se distribuyen los datos equitativamente en bloques de tamaño fijo entrelazados entre dos o más discos y se utiliza uno adicional para almacenar la información de paridad de los bloques de una misma división</em><sup class="footnote">[<a id="_footnoteref_21" class="footnote" href="#_footnotedef_21" title="View footnote.">21</a>]</sup>.
El disco utilizado para almacenar el bloque de paridad cambia de forma escalonada de una división a la siguiente, de ahí que se diga que <em>el bloque de paridad está distribuido</em>.
Algunos aspectos adicionales a tener en cuenta son que:</p>
<div class="ulist">
<ul>
<li>
<p><em>Cada vez que se escribe un bloque de datos se debe actualizar el bloque de paridad</em>.
Por lo tanto las escrituras en un conjunto RAID 5 son costosas en términos de operaciones de disco y tráfico.</p>
</li>
<li>
<p><em>Los bloques de paridad no se leen durante las lecturas de datos</em>, ya que eso reduciría el rendimiento.
Sólo se hace en caso de que la lectura de un sector falle, puesto que <em>el sector en la misma posición relativa dentro de cada uno de los otros bloques de datos de la división y en el bloque de paridad se pueden utilizar para reconstruir el sector erróneo.</em></p>
</li>
<li>
<p><em>En un conjunto RAID 5 el fallo de 2 discos provoca la pérdida completa de los datos</em>.
Esto significa que aunque se pueden añadir discos de manera ilimitada, eso no suele ocurrir puesto que <em>a más discos en el conjunto más probabilidad de que fallen dos de ellos</em>.</p>
</li>
</ul>
</div>
</li>
<li>
<p><em>En un <strong>conjunto RAID 6</strong> se utiliza la misma estrategia que en RAID 5 pero _en cada división hay dos _bloques de paridad —_en lugar de uno—</em> <em>en dos discos diferentes</em>.
Esto permite que fallen hasta dos discos sin perder los datos.</p>
</li>
<li>
<p><em>En un conjunto con niveles anidados se combinan varios niveles RAID básicos como si fueran capas superpuestas</em>.
Ejemplos típicos son:</p>
<div class="ulist">
<ul>
<li>
<p>RAID 0+1, donde se hace un espejo de un conjunto RAID 0.</p>
</li>
<li>
<p>RAID 1+0 o RAID 10, donde diversos conjuntos en espejo se combina en un RAID 0, aumentando la capacidad total.</p>
</li>
<li>
<p>RAID 50, donde diversos conjuntos RAID 5 se combinan en un RAID 0, aumentando también la capacidad total.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>La implementación de RAID es otra de las áreas donde existen diversas variantes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>RAID puede implementarse en el hardware de la controladora de disco</em>, de tal forma que sólo los discos conectados a esta pueden formar parte de un conjunto RAID determinado.
Esta solución es muy eficiente, especialmente cuando se utilizan niveles que requieren cálculo de la paridad, ya que se evita utilizar tiempo de CPU para ese trabajo.
Sin embargo estas controladoras son notablemente más caras que las que carecen de soporte para RAID.</p>
</li>
<li>
<p><em>RAID puede implementarse dentro del sistema operativo en lo que se denomina el software de <strong>gestión de volúmenes</strong></em>.
En este caso las soluciones RAID con paridad son bastante lentas por lo que normalmente sólo se soportan los niveles RAID 0, 1, 10 o 0+1.
Algunas controladoras de disco modernas que dicen venir con soporte RAID realmente implementan esta tecnología en software, a nivel del controlador de dispositivo, mientras que en el hardware sólo se implementan unas características de apoyo mínimas<sup class="footnote">[<a id="_footnoteref_22" class="footnote" href="#_footnotedef_22" title="View footnote.">22</a>]</sup>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Cada conjunto RAID se comporta como una unidad de almacenamiento independiente desde el punto de vista del resto del sistema, por lo que se puede utilizar entero para albergar un único sistema de archivos.
Sin embargo, lo más común es dividirlo en regiones con el objeto de utilizar múltiples sistemas de archivos o combinarlo en estructuras de mayor tamaño, para lo cuál se pueden utilizar alguna de las técnicas que veremos a continuación.</p>
</div>
</div>
<div class="sect2">
<h3 id="_particiones">21.2. Particiones</h3>
<div class="paragraph">
<p><em>Un disco, un conjunto RAID o cualquier otro dispositivo de almacenamiento se puede dividir en regiones para utilizar en cada una de ellas un sistema de archivos diferente</em>.
A esas regiones se las conoce comúnmente como <strong>particiones</strong>, <strong>franjas</strong> o <strong>minidiscos</strong>.</p>
</div>
<div class="paragraph">
<p>Según la plataforma, existen diversas maneras de implementar el soporte de particiones.
Entre los sistemas de escritorio las tecnologías más difundidas y utilizadas son la <strong>MBR</strong> (<em>Master Boot Record</em>) y la <strong>GPT</strong> (<em>GUID Partition Table</em>).
En ambas <em>se almacena, en los primeros sectores del dispositivo de almacenamiento, una tabla con una entrada por partición donde se guardan las direcciones del primer y último sector de cada una de ellas en el dispositivo</em>, así como otra información.
Eso es todo lo que necesita el sistema operativo para determinar los límites de la región ocupada por cada sistema de archivos.</p>
</div>
</div>
<div class="sect2">
<h3 id="_volúmenes_dinámicos">21.3. Volúmenes dinámicos</h3>
<div class="paragraph">
<p>Según la tecnología que se utilice para particionar es posible encontrarse con una serie de restricciones comunes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>El limitado número de particiones diferentes que puede contener un mismo dispositivo.</p>
</li>
<li>
<p>Limitaciones o imposibilidad de redimencionar las particiones.
Especialmente si el sistema operativo está en ejecución.</p>
</li>
<li>
<p>La imposibilidad de crear particiones que hagan uso de regiones libres en diferentes dispositivos de almacenamiento.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Para resolverlo algunos sistemas operativos incluyen un <em>software de gestión de volúmenes</em> que hace uso de tecnología propia para superar estas limitaciones.
Estas herramientas generalmente permiten agrupar dispositivos completos, conjuntos RAID, particiones, etc.
y sobre ellos construir los volúmenes que sean necesarios.
Estos volúmenes pueden ser redimensionados —en ocasiones sin tener que detener la ejecución del sistema operativo— y en caso de que haga falta se pueden incluir dinámicamente nuevos dispositivos para incrementar el espacio disponible.
Además, como ya hemos comentado, el software de gestión de volúmenes puede incluir alguna funcionalidad propia de conjuntos RAID con el objeto de mejorar las prestaciones, a través del paralelismo en el acceso, o mejorar la fiabilidad a través del almacenamiento de información redundante.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_sistemas_de_archivos">22. Sistemas de archivos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Cada volumen puede albergar un sistema de archivos.
A continuación estudiaremos los elementos más comunes a la mayor parte de los sistemas de archivos.</p>
</div>
<div class="sect2">
<h3 id="_estructura_de_un_sistema_de_archivos">22.1. Estructura de un sistema de archivos</h3>
<div class="paragraph">
<p>Un sistema de archivos suele estar compuesto de varios niveles diferentes.
En la se muestra un ejemplo típico de la estructura de un sistema de archivos diseñado en niveles.
Cada nivel utiliza las funciones de los niveles inferiores y proporciona nuevas funciones a los niveles superiores:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>En el nivel más bajo, accediendo directamente a los dispositivos de almacenamiento, se encuentra el <strong>control de E/S</strong>.
<em>Éste está compuesto por los controladores de dispositivo encargados de transferir la información entre la memoria principal y el disco</em>.
Estos controladores, que generalmente son compartidos entre los distintos sistemas de archivos, transfieren los datos en unidades de <em>bloques</em> —en lugar de transferir un byte cada vez— para mejorar la eficiencia .
Cada <em>bloque</em> está formado por uno o más sectores<sup class="footnote">[<a id="_footnoteref_23" class="footnote" href="#_footnotedef_23" title="View footnote.">23</a>]</sup>.</p>
</li>
<li>
<p><em>El <strong>sistema básico de archivos</strong> se encarga de enviar comandos genéricos al controlador de dispositivo apropiado con el fin de leer y escribir bloques físicos en el disco</em>.
Cada bloque físico se identifica mediante su dirección de disco numérica (por ejemplo: unidad 1, cilindro 73, cabeza 2, sector 10).</p>
</li>
<li>
<p><em>El <strong>módulo de organización de archivos</strong> tiene conocimiento de los archivos y se encarga de traducir las direcciones lógicas de bloque —posición del bloque dentro del archivo— en las direcciones físicas de bloque —poe ejemplo, cilindro, cabeza y sector de los bloques correspondientes en el dispositivo de almacenamiento—</em> que serán enviadas al <em>sistema básico de archivos</em> para que realice las transferencias solicitadas.
Los bloques lógicos de cada archivo son numerados de 0 a <em>N</em>, pero los bloques físicos asignados a estos bloques lógicos no tienen porqué coincidir en los números de bloque.
Por eso el <em>módulo de organización de archivos</em> debe utilizar la ubicación del contenido del archivo y la información sobre la asignación de bloques, para traducir las direcciones lógicas en direcciones físicas.
Además, el módulo de organización incluye el gestor de espacio libre, que controla los bloques no asignados y proporciona dichos bloques cuando el <em>módulo de organización de archivos</em> lo necesita.</p>
</li>
<li>
<p><em>El <strong>sistema lógico de archivos</strong> gestiona los metadatos</em>.
Los metadatos incluyen toda la estructura del sistema de archivos, excepto los propios datos de los archivos.
Entre dichos metadatos está la estructura de directorios y los <em>bloques de control de archivo</em>.
<em>Un <strong>bloque de control de archivo</strong> o <strong>FCB</strong> (File Control Block) contiene información acerca del archivo</em>, incluyendo su propietario, los permisos y la ubicación del contenido del mismo.
Además, el <em>sistema lógico de archivos</em> también es responsable de las tareas de protección y seguridad.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Cada sistema operativo puede soportar uno o más sistemas de archivos para dispositivos de disco.
Por ejemplo, en los sistemas UNIX se utiliza el <em>sistema de archivos UNIX</em> o UFS (<em>UNIX File System</em>), que está basado en el sistema FFS (<em>Fast File System</em>) de Berkeley.
Microsoft Windows soporta los sistemas de archivo FAT, FAT32 y NTFS (<em>NT File System</em>).
En Linux se soportan más de cuarenta sistemas de archivo, entre los que podríamos destacar: el <em>sistema de archivos extendido</em> —ext2, ext3 y ext4— XFS y BTRFS.
Además, la mayoría de los sistemas operativos modernos soportan otros sistemas de archivo, como los utilizados en los soportes removibles.
Por ejemplo el ISO-9660, utilizado por la mayor parte de los CD-ROM, o el UFS (<em>Universal File System</em>), utilizado por los DVD-ROM.</p>
</div>
</div>
<div class="sect2">
<h3 id="_estructuras_de_metadatos">22.2. Estructuras de metadatos</h3>
<div class="paragraph">
<p>Para implementar un sistema de archivos se utilizan diversas estructuras de metadatos alojadas tanto en el disco como en la memoria.
Estas estructuras varían dependiendo del sistema operativo y del sistema de archivos.
Sin embargo, a continuación intentaremos describir brevemente las estructuras en disco de uso más común:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Un <strong>bloque de control de arranque</strong> (<strong>bloque de inicio</strong> o <strong>sector de arranque</strong>) que suele ocupar el primer bloque de cada volumen y que contiene la información necesaria para iniciar un sistema operativo a partir de dicho volumen</em>.
Este bloque puede estar vacío, si el volumen no contiene un sistema operativo.</p>
</li>
<li>
<p><em>Un <strong>bloque de control de volumen</strong> que contiene todos los detalles acerca del volumen</em>, tales como: el número máximo de bloques, el tamaño de los bloques, el número de bloques libres y punteros a los mismos, así como un contador de bloques de información FCB y punteros a estos.
En los sistemas de archivos para UNIX y Linux, a esta estructura se la denomina <strong>superbloque</strong>.
Mientras que en NTFS esta información se almacena en la <strong>tabla maestra de archivos</strong> o <strong>MFT</strong> (<em>Master File Table</em>).</p>
</li>
<li>
<p><em>Un FCB por cada archivo</em> donde se almacenan numerosos detalles sobre el mismo, por ejemplo: los permisos, el propietario, el tamaño y la ubicación de los bloques de datos.
En términos generales todos los FCB del sistema de archivos se almacenan en una tabla denominada directorio de dispositivo o tabla de contenidos del volumen.
En los sistemas de archivos para UNIX y Linux cada FCB se denomina <strong>inodo</strong> y se almacenan a continuación del superbloque.
En NTFS esta información se almacena en la MFT, ya que cada entrada de dicha tabla es un FCB.</p>
</li>
<li>
<p><em>Una estructura de directorios para organizar los archivos</em>.
En los sistemas de archivos para UNIX y Linux, cada directorio es como un archivo especial que almacena los nombres de los archivos que contiene y los números de FCB asociados a los mismos.
En NTFS es similar, aunque la estructura de directorios completa se almacena en la propia MFT.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>La información almacenada en memoria se utiliza tanto para la gestión del sistema de archivo como para mejorar el rendimiento del mismo mediante mecanismos de caché.
Los datos se cargan en el momento de comenzar a utilizar el sistema de archivos —montaje— y se descartan cuando se va a dejar de hacer uso del mismo —desmontaje—.
Las estructuras existentes en la memoria pueden incluir las que a continuación se describen:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Una tabla de montaje en memoria que contiene información acerca de cada volumen montado</em>.</p>
</li>
<li>
<p><em>Una caché en memoria de la estructura de directorios que almacena la información relativa a los directorios a los que se han accedió recientemente</em>.
Los directorios que actúan como puntos de montaje puede contener un puntero a la entrada, en la tabla de montaje, del volumen montado en el directorio.</p>
</li>
<li>
<p><em>La tabla global de archivos abiertos que contiene una copia del FCB de cada archivo abierto en el sistema</em>, además de otras informaciones.</p>
</li>
<li>
<p><em>La <strong>tabla de archivos abiertos</strong> de cada proceso</em>.
El PCB de cada proceso contiene una tabla donde se listan los archivos abiertos por el proceso.
La tabla contiene para cada archivo un puntero a la entrada correspondiente del mismo archivo en la tabla global de archivos abiertos, así como otras informaciones adicionales que son particulares de cada proceso.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_montaje_de_sistemas_de_archivos">22.3. Montaje de sistemas de archivos</h3>
<div class="paragraph">
<p>Un sistema de archivos debe <em>montarse</em> para que sus archivos sean accesibles a los procesos del sistema.
El proceso de montaje incluye los siguientes pasos:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Al sistema operativo se le debe proporcionar el nombre o identificador del dispositivo y el punto de montaje.
El <strong>punto de montaje</strong> es la ubicación dentro de la estructura de directorios —el directorio concreto— a la que queremos conectar el sistema de archivos</em>.
Después de que el proceso de montaje se haya completado, los archivos y directorios del sistema de archivos montado serán accesibles como descendientes del directorio del punto de montaje.</p>
</li>
<li>
<p>A continuación <em>el sistema operativo verifica que el dispositivo contiene un sistema de archivos válido</em>.
Para ello lee el <em>bloque de control de volumen</em> y comprueba que tiene un formato válido.</p>
</li>
<li>
<p>Finalmente <em>el sistema operativo registra en la tabla de montaje _el tipo de sistema de archivos y el identificador del del dispositivo montado, mientras en la copia en memoria del FCB del directorio que hace de punto de montaje almacena un identificador de la entrada correspondiente en la tabla de montaje</em>.
Esto permite que pueda ser recorrida la estructura de directorios de distintos sistemas de archivos, pasando de uno a otro de forma transparente, según sea necesario.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>En muchos sistemas operativos modernos el montaje se ejecuta automáticamente cuando los dispositivos son detectados durante el arranque del sistema o cuando se conectan durante el funcionamiento del mismo —por ejemplo, cuando se inserta un medio en la unidad CD-ROM o se pincha una memoria flash en un puerto USB—.
Además, en algunos se permite que el administrador del equipo ejecute operaciones de montaje manuales.</p>
</div>
</div>
<div class="sect2">
<h3 id="_archivos">22.4. Archivos</h3>
<div class="paragraph">
<p>Cada sistema de archivos almacena en disco una tabla donde cada entrada guarda un bloque de control de archivo o FCB (File Control Block) por archivo.
Concretamente, en cada FCB se almacena diversa información acerca del archivo al que representa.</p>
</div>
<div class="sect3">
<h4 id="_atributos_de_archivos">22.4.1. Atributos de archivos</h4>
<div class="paragraph">
<p>La colección de atributos asociada a un archivo varía de un sistema operativo a otro, pero típicamente son los siguientes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Nombre</strong>.
Nombre simbólico del archivo que se mantiene en un formato legible para conveniencia de las personas.</p>
</li>
<li>
<p><strong>Identificador</strong>.
Identifica de forma unívoca el archivo dentro del sistema de archivos.
Generalmente es el índice del FCB en la tabla de contenidos del volumen, donde se almacenan los FCB.</p>
</li>
<li>
<p><strong>Tipo</strong>.
Es un atributo necesario en los sistemas que soportan diferentes tipos de archivos.</p>
</li>
<li>
<p><strong>Ubicación</strong>.
Es un puntero a un dispositivo y a la ubicación del archivo dentro del mismo.</p>
</li>
<li>
<p><strong>Tamaño</strong>.
Indica el tamaño actual de archivo —en bytes, palabras o bloques— y, posiblemente, el tamaño máximo permitido.</p>
</li>
<li>
<p><strong>Protección</strong>.
Información de control de acceso que determina quién puede leerlo, escribirlo, ejecutarlo, etc.</p>
</li>
<li>
<p><strong>Fecha, hora e identificación del usuario</strong>.
Esta información puede mantenerse para los sucesos de creación, de última modificación y último uso del archivo.
Esto puede resultar útil para la protección, seguridad y monitorización del uso del archivo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Los atributos de los archivos se almacenan en las estructuras de metadatos.
Normalmente el nombre se almacena en la estructura de directorios, de tal manera que una entrada de directorio está compuesta del nombre de un archivo y del identificador de su FCB.
Dicho identificador permite localizar el FCB en la tabla de contenidos del volumen, que contiene el resto de los atributos del archivo.</p>
</div>
</div>
<div class="sect3">
<h4 id="_operaciones_con_los_archivos">22.4.2. Operaciones con los archivos</h4>
<div class="paragraph">
<p>Un archivo es un tipo abstracto de datos sobre el que pueden realizarse diversas operaciones.
Concretamente <em>el sistema operativo proporciona llamadas al sistema para: crear, escribir, leer, reposicionar<sup class="footnote">[<a id="_footnoteref_24" class="footnote" href="#_footnotedef_24" title="View footnote.">24</a>]</sup>, borrar y truncar archivos</em>.
Además en muchos sistemas se suelen incluir llamadas para otras operaciones comunes, como añadir datos al final de un archivo o el renombrado de un archivo existente.
Estas operaciones primitivas puede combinarse a su vez para realizar otras operaciones más complejas —por ejemplo, crear una copia de un archivo o moverlo a otro lugar de la estructura de directorios—.
Además, muchos sistemas también disponen de operaciones para consultar y modificar diversos atributos de un archivo, como la longitud o el propietario del mismo.</p>
</div>
<div class="paragraph">
<p>La mayor parte de estas operaciones implican realizar una búsqueda en el directorio para encontrar la entrada asociada con el archivo cuyo nombre se ha indicado.
Para evitarlo <em>muchos sistemas requieren<sup class="footnote">[<a id="_footnoteref_25" class="footnote" href="#_footnotedef_25" title="View footnote.">25</a>]</sup> que el proceso haga una llamada al sistema open(), antes de realizar cualquiera de estas operaciones por primera vez sobre un archivo</em>.
En concreto esta llamada al sistema:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Busca en el directorio el nombre del archivo hasta encontrar la entrada asociada y recupera el identificador del mismo.</p>
</li>
<li>
<p>Utiliza el identificador del archivo para recuperar el FCB correspondiente.</p>
</li>
<li>
<p>Crea una entrada para el archivo en la tabla de archivos abiertos donde se almacena la información del FCB.</p>
</li>
<li>
<p>Retorna devolviendo un identificador —en forma de puntero o de índice— a la nueva entrada en la tabla de archivos abiertos.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>El nombre con el que se designa a esas entradas en la tabla de archivos abiertos varía de unos sistemas a otros.
En los sistemas UNIX se utiliza el término <strong>descriptor de archivo</strong> —o <em>file descriptor</em>— mientras que en los sistemas Microsoft Windows se prefiere el término <strong>manejador de archivo</strong> —o <em>file handler</em>—.</p>
</div>
<div class="paragraph">
<p>Después de utilizar la llamada al sistema <code>open()</code>, cuando se desee solicitar una operación sobre un archivo, sólo es necesario proporcionar el identificador devuelto, evitando así que haga falta realizar exploración alguna del directorio.
Cuando el archivo deja de ser utilizado activamente por el proceso, puede ser cerrado utilizado la llamada al sistema <code>close()</code>.</p>
</div>
<div class="paragraph">
<p><em>En los sistemas operativos donde varios procesos pueden abrir un mismo archivo se suelen utilizar dos niveles de tablas de archivos abiertos</em>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Una tabla para cada proceso —almacenada en el PCB— donde se indican todos los archivos que éste ha abierto</em>.
En dicha tabla se almacena toda la información referente al uso de cada archivo por parte de un proceso.
Por ejemplo, se puede almacenar la posición actual utilizada por las operaciones de lectura y escritura o los derechos de acceso.</p>
</li>
<li>
<p><em>Una tabla global para todo el sistema donde se almacena toda la información independiente de los procesos</em>, como la ubicación del archivo en el disco, las fechas de acceso y el tamaño del archivo.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Cuando un proceso invoca la llamada <code>open()</code> se añade una entrada en la tabla de archivos abiertos del proceso, que a su vez apunta a la entrada correspondiente dentro de la tabla global del sistema.
Si el archivo no existe en esta última, también hay que crear una entrada en la tabla global del sistema haciendo uso de la información contenida en disco en el FCB correspondiente.
Es muy común que la tabla global almacene un <em>contador de aperturas</em> para cada archivo con el objetivo de indicar cuantos procesos lo mantienen abierto.
Dicho contador se decrementa con cada llamada al sistema <code>close()</code>, de forma que cuando alcance cero querrá decir que la entrada puede ser eliminada de la tabla global de archivos abiertos.</p>
</div>
</div>
<div class="sect3">
<h4 id="_tipos_de_archivo">22.4.3. Tipos de archivo</h4>
<div class="paragraph">
<p>Cuando se diseña un sistema operativo es necesario considerar si debe reconocer y soportar el concepto de tipo de archivo.
Si el sistema operativo reconoce el tipo de un archivo puede operar con el mismo de formas razonables.
Por ejemplo, el sistema puede impedir que un usuario intente imprimir los archivos que contienen programas en formato binario, pues el documento impreso sería ininteligible.</p>
</div>
<div class="paragraph">
<p>En los sistemas operativos más comunes las técnicas utilizadas para implementar los tipos de archivo son las siguientes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>En MSDOS y Microsoft Windows el tipo de archivo se incluye como parte del nombre del archivo</em>.
Es decir, el nombre se divide en dos partes: un nombre y una extensión; normalmente separadas por un carácter de punto.
El sistema puede utilizar la extensión para conocer el tipo de archivo y el tipo de operaciones que se pueden realizar con el mismo.</p>
</li>
<li>
<p><em>En macOS cada archivo tiene un atributo que almacena el tipo</em> —por ejemplo, <code>TEXT</code> para los archivos de texto o <code>APPL</code> para las aplicaciones— y otro que contiene el nombre del programa que lo creó.
Cuando el usuario hace clic con el ratón sobre el icono de un archivo, el programa que lo creó se ejecuta automáticamente y el archivo se carga en la memoria.</p>
</li>
<li>
<p><em>En los sistemas UNIX se utiliza un <strong>número mágico</strong> almacenado al principio de algunos archivos</em> para indicar el tipo del mismo.
No todos los archivos tienen números mágicos, por lo que se permite hacer sugerencias en forma de extensiones del nombre del archivo.
Sin embargo estas extensiones ni son obligatorias ni el sistema depende de ellas.
Fundamentalmente su objetivo es ayudar a los usuarios a determinar el tipo de contenido de un archivo, por lo que pueden ser utilizadas o ignoradas por cada aplicación concreta, en función de las preferencias de sus desarrolladores.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_estructura_de_directorios">22.5. Estructura de directorios</h3>
<div class="paragraph">
<p>Algunos sistemas de archivos pueden almacenar millones de archivos en terabytes de disco.
Para gestionar todos esos datos necesitamos organizarlos de alguna manera, lo que generalmente implica el uso de directorios.
<em>Un <strong>directorio</strong> puede considerarse una tabla de símbolos que traduce los nombre de los archivos en los identificadores que permiten recuperar sus correspondientes entradas en la tabla de contenidos del volumen</em>, donde se almacenan los FCB.
A continuación vamos a estudiar los diversos esquemas para definir la estructura lógica del sistema de directorios.</p>
</div>
<div class="sect3">
<h4 id="_directorios_de_un_nivel">22.5.1. Directorios de un nivel</h4>
<div class="paragraph">
<p><em>En la estructura de directorios de un nivel todos los archivos están contenidos en un único directorio</em>.
Esto presenta algunas limitaciones:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando el número de usuarios del sistema aumenta se hace más difícil que cada uno escoja nombres diferentes para sus archivos, lo cual es necesario puesto que todos los archivos se encuentran en el mismo directorio.</p>
</li>
<li>
<p>Incluso en los sistemas operativos monousuario puede ser difícil para un usuario mantener organizados sus datos a media que se incrementa el número de archivos.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Este esquema fue utilizado por la primera versión del sistema operativo MSDOS.</p>
</div>
</div>
<div class="sect3">
<h4 id="_directorio_de_dos_niveles">22.5.2. Directorio de dos niveles</h4>
<div class="paragraph">
<p><em>En la estructura de directorios de dos niveles cada usuario tiene su propio <strong>directorio de archivos de usuario</strong> o <strong>UFD</strong> (User File Directory) que cuelga del <strong>directorio maestro de archivos</strong> o <strong>MFD</strong> (Master File Directory)</em>.
Cuando un usuario se conecta al sistema o inicia un trabajo se explora el MFD, que es una tabla indexada por el nombre de los usuarios o por los números de cuenta, donde cada una de sus entradas apunta al UFD de dicho usuario.
Puesto que cada UFD incluye sólo los archivos del usuario al que pertenece, el sistema operativo puede confinar todas las operaciones que puede realizar un usuarios sobre los archivos a su UFD.
Sin embargo, aunque esto resuelve el problema de la colisión de nombres entre diferentes usuarios, también presenta algunas desventajas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La estructura descrita aísla a los usuarios, lo cual puede ser un problema cuando éstos quieren compartir datos para cooperar en alguna tarea.
La solución pasa por utilizar <strong>nombres de ruta</strong> para designar a un archivo de forma unívoca.
Por ejemplo, si el usuario <code>usera</code> quiere acceder a su archivo <code>test</code>, simplemente debe referirse a el como <code>test</code>.
Mientras que si quiere acceder al archivo <code>test</code> del usuario <code>userb</code>, debe utilizar un <em>nombre de ruta</em> como <code>/userb/test</code>, donde se indica el nombre del usuario y el nombre del archivo.
En general, cada sistema operativo utiliza su propia sintaxis par nombrar los archivos contenidos en los directorios de otros usuarios.</p>
</li>
<li>
<p>Incluso en este caso puede ser difícil para un usuario mantener organizados sus datos a media que se incrementa el número de archivos personales.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_directorios_con_estructura_de_árbol">22.5.3. Directorios con estructura de árbol</h4>
<div class="paragraph">
<p><em>La estructura de directorio de dos niveles puede generalizarse en la estructura de directorios en árbol de altura arbitraria</em>.
Esto permite que los usuarios puedan crear sus propios subdirectorios para organizar sus archivo de la forma más conveniente.</p>
</div>
<div class="paragraph">
<p>Cada sistema de archivos tiene un <strong>directorio raíz</strong> que puede contener tanto archivos como otros directorios.
A su vez cada directorio puede contener un conjunto de archivos y subdirectorios.
Normalmente cada entrada de directorio incluye un bit donde se indica si dicha entrada apunta a un archivo o a un subdirectorio.
Esto se hace así porque los directorios no son más que archivos con un formato interno especial, por lo que el sistema debe saber si la entrada apunta a un directorio para interpretar correctamente los datos del directorio.</p>
</div>
<div class="paragraph">
<p>Generalmente en el PCB de cada proceso se guarda cual es su <strong>directorio de trabajo actual</strong>, de forma que cuando se hace referencia a un archivo usando solo su nombre, se le busca en ese directorio.
Si se necesita un archivo que no se encuentra en el directorio de trabajo actual, entonces el usuario debe especificar un nombre de ruta desde el directorio de trabajo actual.
O cambiar con una llamada al sistema el directorio de trabajo del proceso al directorio donde está almacenado el archivo.
Los nombres de ruta pueden ser de dos tipos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Un <strong>nombre de ruta absoluto</strong> comienza en la raíz y va indicando los directorios que componen la ruta de forma descendente hasta llegar al archivo especificado</em>.</p>
</li>
<li>
<p><em>Un <strong>nombre de ruta relativo</strong> define una ruta a partir del directorio actual</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Con una estructura de directorios en árbol se puede permitir que unos usuarios accedan a los archivos de otros.
Para eso sólo es necesario que se utilicen nombres de ruta para designar los archivos o que se cambie el directorio de trabajo actual.</p>
</div>
<div class="paragraph">
<p>Este tipo de estructura de directorios es la utilizada por MSDOS y por las distintas versiones de Microsoft Windows.</p>
</div>
</div>
<div class="sect3">
<h4 id="_directorios_en_grafo_acíclico">22.5.4. Directorios en grafo acíclico</h4>
<div class="paragraph">
<p>La estructura de directorio en grafo acíclico es una generalización natural del esquema con estructura en árbol.
A diferencia de éste último, <em>la estructura en grafo acíclico permite que los mismo archivos y subdirectorios existan simultáneamente en distintos lugares de la estructura de directorios.</em> Esto, por ejemplo, hace que los usuarios puedan compartir archivos de forma que se puedan acceder a los mismo directamente desde el directorio propiedad de los distintos usuarios.
Indudablemente eso significa que para acceder a un archivo o directorio pueden existir diversas rutas.</p>
</div>
<div class="paragraph">
<p>Los archivos y subdirectorios compartidos pueden implementarse de diversas formas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Se pueden crear una entrada de directorio denominada <strong>enlace</strong></em>.
Un enlace es, generalmente, un archivo que contiene la ruta relativa o absoluta de otro archivo o subdirectorio.
En los sistemas UNIX a estos se los conoce como <strong>enlaces simbólicos</strong>.</p>
</li>
<li>
<p><em>También se pueden duplicar toda la información de la entrada de directorio del archivo compartido en todos los directorios que también contienen dicho archivo</em>.
Así, mientras que los <em>enlaces</em> son claramente diferentes de la entrada original de directorio, las entradas de directorio duplicadas hacen que la entrada original y la copia sean indistinguibles.
En los sistemas UNIX a las entradas duplicadas se las conoce como <strong>enlaces duros</strong>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Una estructura en grafo acíclico es más flexible que una estructura en árbol, pero no por eso está exenta de inconvenientes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Si estamos intentando recorrer el sistema de archivos completo</em> —por ejemplo, para buscar un archivo o para copiarlos en un dispositivo de copias de seguridad— <em>debemos evitar acceder más de una vez a los archivos y subdirectorios compartidos</em>.
No olvidemos que en los sistemas con estructura en grafo acíclico cada archivo puede tener múltiples nombres de ruta absoluta.
Esto es más sencillo de resolver en el caso de los enlaces, puesto que podemos evitar recorrerlos al ser claramente distinguibles del archivo original.</p>
</li>
<li>
<p>¿Cuándo puede liberarse el espacio asignado a un archivo compartido? Si lo hacemos cuando un usuario lo borra podríamos dejar punteros que referencian a archivos que no existen.</p>
</li>
<li>
<p>El caso más sencillo de resolver es el de los <em>enlaces</em> ya que pueden ser borrados sin que el archivo original se vea afectado, puesto que lo que se elimina es el enlace y no el archivo original.</p>
<div class="ulist">
<ul>
<li>
<p>Si lo que se pretende borrar es la entrada de un archivo original que es apuntado desde un <em>enlace</em>, entonces no hay problema en hacerlo y liberar el espacio asignado al mismo, dejando que el enlace apunte a un archivo que no existe.
Ciertamente podríamos plantearnos la posibilidad de buscar esos enlaces y eliminarlos pero, a menos que el FCB de cada archivo guarde las rutas a los enlaces que le señalan, esta búsqueda puede ser muy costosa.
Por eso lo más común es conservar los enlaces hasta que se produzca un intento de utilizarlos, en cuyo caso determinaremos que el archivo referenciado fue borrado y trataremos el acceso al enlace de forma similar a cualquier otro acceso ilegal a un archivo que no existe.</p>
</li>
<li>
<p>Otra opción es almacenar en la entrada del archivo original un contador con el número de referencias al archivo.
Así, cuando el contador sea 0, sabremos que a llegado el momento de liberar el espacio asignado.
En los sistemas UNIX se utiliza esta técnica para los <em>enlaces duros</em>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Por último <em>no debemos olvidar que la estructura de directorios en grafo se conserva acíclica si se prohíbe que hayan múltiples referencias a un mismo directorio</em>.
Ese es el motivo por el que en los sistemas UNIX no se permite que los <em>enlaces duros</em> hagan referencia a directorios.
Sin embargo si se pueden utilizar <em>enlaces simbólicos</em> para este fin, puesto que al ser distinguibles del directorio original podemos evitar los ciclos si mientras se explora se ignorar dichos enlaces.</p>
</div>
</div>
<div class="sect3">
<h4 id="_directorios_en_forma_de_grafo_general">22.5.5. Directorios en forma de grafo general</h4>
<div class="paragraph">
<p>Uno de los principales problemas de la estructura de directorios en grafo acíclico es garantizar que no exista ningún ciclo.
Esto es interesante puesto que mientras sea así los algoritmos diseñados para recorrer el grafo y para determinar cuando no existen más referencias a un archivo son relativamente simples.
No olvidemos que:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Es importante evitar encontrar cualquier archivo dos o más veces</em>, tanto por razones de corrección como de rendimiento.</p>
</li>
<li>
<p><em>En una estructura de directorios en forma de grafo general donde existan ciclos puede que el contador de referencias no sea 0, aunque no hayan más referencias al archivo</em>.
Esto significa que generalmente se necesita algún mecanismo de recolección de basura<sup class="footnote">[<a id="_footnoteref_26" class="footnote" href="#_footnotedef_26" title="View footnote.">26</a>]</sup> para determinar con seguridad cuando se ha borrado la última referencia.
Sin embargo la recolección de basura para un sistema de archivos basado en disco consume mucho tiempo, por lo que en pocas ocasiones se utiliza.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Por tanto, es mucho más sencillo trabajar con estructuras de directorio en grafo acíclico.
Para evitar que en un grafo aparezca un ciclo al añadir un nuevo enlace, se pueden utilizar diversos algoritmos.
Sin embargo, puesto que suelen ser muy costosos, lo más simple es ignorar todos los enlaces en los casos en los que se recorre el árbol de directorios para realizar una tarea en la que es importante no entrar en un bucle —por ejemplo, al hacer una búsqueda— En el caso de la duplicación de entradas de directorio —donde las entradas duplicadas no se pueden distinguir de la original y, por tanto, no se pueden ignorar— lo más sencillo es que el sistema operativo no permita crear múltiples referencias a un mismo directorio.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_compartición_de_archivos">23. Compartición de archivos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Como ya hemos comentado, el que los usuarios puedan compartir archivos es algo muy deseable pues permite que éstos puedan colaborar en la realización de una tarea determinada.
Sin embargo al añadir esta característica hay que tener en cuenta algunos aspectos que deben ser resueltos en el diseño del sistema operativo.</p>
</div>
<div class="sect2">
<h3 id="_múltiples_usuarios_y_protección">23.1. Múltiples usuarios y protección</h3>
<div class="paragraph">
<p>Cuando un sistema operativo admite múltiples usuarios y utiliza una estructura de directorio que permite que éstos compartan archivos, cobra gran importancia la protección de los datos.
En este sentido el sistema operativo debe adoptar un papel de mediador en lo que respecta a la compartición de los archivos.</p>
</div>
<div class="paragraph">
<p>Para implementar la compartición y los mecanismos de protección el sistema debe soportar más atributos para cada archivo y directorio que los que necesita en un sistema monousuario.
Aunque a lo largo de la historia se han adoptado diversos enfoques, la mayoría han evolucionado hasta utilizar los conceptos de <em>propietario</em> (o <em>usuario</em>) y <em>grupo</em> de un archivo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>El propietario de un archivo es el usuario que puede cambiar los atributos y conceder el acceso</em>.
Se trata del usuario que dispone del mayor grado de control sobre el archivo.</p>
</li>
<li>
<p><em>El grupo es un conjunto de usuarios que pueden compartir el acceso al archivo</em>.
El propietario del archivo es quien define que operaciones pueden ser ejecutadas por los miembros del grupo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Los identificadores del propietario y el grupo de un archivo se almacenan junto con los otros atributos en el FCB.
Cuando un usuarios solicita realiza una operación sobre un archivo, se compara el identificador del usuario con el atributo del propietario para determinar si el solicitante es el propietario.
Exactamente de la misma manera se puede proceder con los identificadores de grupo.
El resultado de la comparación indicará que permisos son aplicables.
A continuación el sistema aplicará dichos permisos a la operación solicitada y la autorizará o denegará según sea el caso.</p>
</div>
<div class="paragraph">
<p>Existen diversas implementaciones del esquema utilizado para determinar los permisos aplicables aun usuario que pretende operar sobre un archivo concreto:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>El esquema más general consiste en <em>asociar a cada archivo o directorio una <strong>lista de control de acceso</strong> o <strong>ACL</strong> (Access-control list) que especifique los nombres de usuario o grupos y los tipos de acceso para cada uno</em>.
Cuando un usuario solicita acceder a un archivo concreto, el sistema operativo comprueba la ACL asociada a dicho archivo.
Si dicho usuario, o alguno de sus grupos, está incluido en la lista para el tipo de acceso solicitado, se permite el acceso.
Esta técnica presenta diversas ventajas e inconvenientes:</p>
<div class="ulist">
<ul>
<li>
<p><em>Se trata de la técnica más general</em>, permitiendo la implementación de políticas de acceso muy complejas.</p>
</li>
<li>
<p>Sin embargo, <em>construir la lista puede ser una tarea tediosa</em>.
Por ejemplo, si queremos que varios usuarios puedan leer unos archivos determinados, es necesario enumerar todos los usuarios que disponen de ese acceso en las ACL de dichos archivos.</p>
</li>
<li>
<p><em>El FCB, que hasta el momento tenía un tamaño fijo, ahora tendrá que ser de tamaño variable para almacenar la ACL</em>, lo que requiere mecanismos más complejos de gestión del espacio.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para solucionar algunos de los problemas de las ACL <em>muchos sistemas utilizan listas de control de acceso condensadas</em>.
Para condensar la longitud de la lista de control de acceso, muchos sistemas clasifican a los usuarios en tres grupos: <em>propietario</em>, <em>grupo</em> y <em>otros</em>.
Así sólo es necesario un campo para cada clase de usuario, siendo cada campo una colección de bits, donde cada uno permite o deniega el tipo de acceso asociado al mismo.
Por ejemplo, en los sistemas UNIX se definen 3 campos (<em>propietario</em>, <em>grupo</em> y <em>otros</em>) de 3 bits cada uno: <code>rwx</code>, donde <code>r</code> controla el acceso de lectura, <code>w</code> controla el acceso de escritura y <code>x</code> controla la ejecución.
Las ACL condensadas son más sencillas de construir, al mismo tiempo que por tener una longitud fija es mucho más simple gestionar el espacio para el FCB donde se almacena.</p>
</li>
<li>
<p><em>La técnica más común en los sistemas operativos modernos consiste en combinar ambos tipos de listas de control de acceso</em>.
Sin embargo esta solución no está exenta de dificultades:</p>
<div class="ulist">
<ul>
<li>
<p><em>Uno de los problemas es que los usuarios deben poder determinar cuando están activados los permisos ACL más generales</em>.
En Linux, por ejemplo, se utiliza el símbolo <code>+</code> a listar los permisos de la ACL condensada para indicar dicha circunstancia.
Esos permisos pueden ser gestionados utilizando los comandos <code>setfacl</code> y <code>getfacl</code>.</p>
</li>
<li>
<p><em>Otra dificultad es la relativa a la asignación de precedencias cuando ambas ACL entran en conflicto</em>.
En general se suele asignar a la ACL más prioridad que a la ACL condensada, pues la primera tiene una granularidad más fina y no se crea de forma predeterminada.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>La familia de sistemas operativos Microsoft Windows utiliza las ACL más generales, mientras que en los sistemas operativos Linux y Solaris se implementan ambos tipos de ACL.</p>
</div>
<div class="paragraph">
<p><em>Otra técnica para resolver el problema de la protección consiste en asociar una contraseña con cada archivo o directorio</em>.
Sin embargo esto tiene el inconveniente de que el número de contraseñas que un usuario puede tener que recordar puede ser muy grande.
No olvidemos que si se utiliza la misma contraseña para todos los archivo, desde el momento en que esa contraseña sea descubierta todos los archivos serán accesibles.</p>
</div>
</div>
<div class="sect2">
<h3 id="_semántica_de_coherencia">23.2. Semántica de coherencia</h3>
<div class="paragraph">
<p><em>La <strong>semántica de coherencia</strong> especifica cuando las modificaciones que un usuario realice en los archivos serán observables por los otros usuarios</em>.
La semántica de coherencia está directamente relacionada con los algoritmos de sincronización de procesos (véase tema <a href="#_sincronización">Capítulo 13</a>).
Sin embargo es normal que esos complejos algoritmos no se implementen en el caso de la E/S de archivo, debido a la alta latencia y las bajas velocidades de la transferencia de los discos y de las redes.</p>
</div>
<div class="paragraph">
<p>A continuación vamos comentar algunos ejemplos de semántica de coherencia:</p>
</div>
<div class="sect3">
<h4 id="_semántica_de_unix">23.2.1. Semántica de UNIX</h4>
<div class="paragraph">
<p>Los sistemas de archivos de los sistemas operativos UNIX utilizan la siguiente semántica de coherencia:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Las escrituras en un archivo abierto por parte de un proceso son visibles inmediatamente para los procesos que tengan abierto el mismo archivo</em>.</p>
</li>
<li>
<p><em>Existe un modo de compartición que permite a los procesos compartir el puntero de ubicación actual dentro del archivo</em>.
Así, el incremento de ese puntero por parte de un proceso afecta a todos los procesos que estén compartiendo el archivo.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En la semántica de UNIX cada archivo está asociado con una única imagen física a la que se accede en forma de recurso de acceso exclusivo —por ejemplo, un proceso que haga un <code>read()</code> sobre un archivo podrá quedar en espera si al mismo tiempo otro proceso está ejecutando un <code>write()</code>, hasta que este último termine—.
La contienda por acceder a esta imagen única provoca retardos en los procesos debido a estos bloqueos.</p>
</div>
</div>
<div class="sect3">
<h4 id="_semántica_de_sesión">23.2.2. Semántica de sesión</h4>
<div class="paragraph">
<p>Suponiendo que <em>una <strong>sesión de archivo</strong> es el conjunto de operaciones entre las llamadas `open()`y `close()`</em>, el sistema de archivos Andrew —o AFS— utiliza la siguiente semántica de coherencia:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Las escrituras en un archivo abierto por parte de un proceso no son visibles inmediatamente para los otros usuarios que hayan abierto ese mismo archivo</em>.</p>
</li>
<li>
<p><em>Una vez que se cierra un archivo, los cambios realizados en él son visibles únicamente en las sesiones que comiencen posteriormente</em>.
Las sesiones ya abiertas sobre el archivo no reflejarán dichos cambios.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Esto significa que un archivo puede permanecer temporalmente asociado a varias imágenes físicas al mismo tiempo.
Así se permite que múltiples usuarios realicen accesos concurrentes, tanto de lectura como de escritura, en sus propias imágenes del archivo, evitando los retardos.</p>
</div>
</div>
<div class="sect3">
<h4 id="_semántica_de_archivos_compartidos_inmutables">23.2.3. Semántica de archivos compartidos inmutables</h4>
<div class="paragraph">
<p>En esta semántica, <em>cuando un archivo es declarado como compartido por su creador ya no puede ser ser modificado</em>.
Estos archivos inmutables cumplen dos propiedades clave: su nombre no puede reutilizarse y su contenido no puede ser modificado.
Así podemos estar seguros de que el contenido de un archivo inmutable es fijo.
La implementación de esta semántica en un sistema distribuido es muy simple.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_bloqueos_de_archivo">23.3. Bloqueos de archivo</h3>
<div class="paragraph">
<p>Algunos sistemas operativos proporcionan funciones para bloquear un archivo —o determinadas porciones de un archivo— abierto.
Esto permite que un proceso <em>impida que otros procesos puedan acceder al archivo bloqueado</em>.
Los bloqueos de archivo resultan útiles para encadenar varias operaciones de E/S sobre un archivo teniendo la seguridad de que otros procesos no podrán hacer modificaciones en el mismo mientras tanto.</p>
</div>
<div class="paragraph">
<p>Los sistemas operativos pueden proporcionar diferentes tipos de bloqueos de archivo:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Un <strong>bloqueo compartido</strong> es un tipo de bloqueo que puede ser adquirido —bloquear el archivo— al mismo tiempo por varios procesos.</em></p>
</li>
<li>
<p><em>Un <strong>bloqueo exclusivo</strong> sólo puede ser adquirido por un proceso cada vez</em>.
Si otro proceso intenta adquirir bloqueo exclusivo sobre un archivo ya bloqueado, se suspende a la espera.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Algunos sistemas operativos sólo proporcionan el <em>bloqueo exclusivo</em>.
Sin embargo en los que implementan ambos tipos de bloqueo, lo normal es que los procesos que pretenden acceder a un archivo compartido para sólo lectura utilicen el <em>bloqueo compartido</em>, mientras que los que acceden para modificar el contenido utilicen el <em>bloqueo exclusivo</em>.
Así varios procesos puedan leer el archivo al mismo tiempo, pero si un proceso accede para escribir ningún otro podrá acceder ni para leer ni para escribir.</p>
</div>
<div class="paragraph">
<p>Además los sistemas operativos pueden proporcionar mecanismos de bloqueo de archivos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Obligatorios</strong>.
Si un bloqueo es obligatorio, después de que un proceso adquiera un bloqueo exclusivo, <em>el sistema operativo impedirá a todos los demás procesos que hagan cualquier operación sobre el archivo bloqueado</em>.
Esto ocurrirá incluso si los otros procesos no han sido programados para intentar adquirir el bloqueo.
Por tanto, el sistema operativo es el encargado de garantizar que los bloqueos se cumplen, haciendo las comprobaciones pertinentes en las llamadas al sistema.</p>
</li>
<li>
<p><strong>Sugeridos</strong>.
Si un bloqueo es sugerido, <em>el sistema operativo sólo impedirá que accedan al archivo bloqueado aquellos procesos programados para adquirir el bloqueo explícitamente</em> —usando la llamada al sistema correspondiente—.
El sistema operativo no impedirá el acceso al archivo a un proceso que lo abre, lee o escribe sin más.
Son los desarrolladores del software los encargados de intentar adquirir el bloqueo y de liberarlo cuando ya no es necesario.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Como regla general los sistemas operativos Microsoft Windows implementan un mecanismo de bloqueo obligatorio, mientras que los sistemas UNIX emplean bloqueos sugeridos.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_coherencia">24. Coherencia</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Como hemos comentado anteriormente, parte de los metadatos se almacena en la memoria principal para acelerar el acceso.
Dicha información generalmente está más actualizada que la correspondiente en el disco, puesto que la información almacenada en la memoria no tiene porque ser escrita inmediatamente después de una actualización.</p>
</div>
<div class="paragraph">
<p>¿Qué ocurriría entonces si fallase el sistema? Pues que el contenido de la caché y de los búferes se perdería y con ellos también los cambios realizados en los directorios y archivos abiertos.
Esto puede dejar el sistema de archivos en un estado incoherente, pues el estado real de algunos archivos no sería el que se describe en la estructura de metadatos.</p>
</div>
<div class="sect2">
<h3 id="_comprobación_de_coherencia">24.1. Comprobación de coherencia</h3>
<div class="paragraph">
<p><em>El <strong>comprobador de coherencia</strong> comprueba la estructura de metadatos y tratar de corregir todas las incoherencias que detecte</em>.</p>
</div>
<div class="paragraph">
<p>Los algoritmos de asignación y de gestión del espacio de almacenamiento dictan los tipos de problemas que el comprobador puede tratar de detectar y también el grado de éxito que el comprobador puede tener en esa tarea.
Por ejemplo la pérdida de un FCB, cuando es este el que almacena la lista de bloques que contienen los datos del archivo, es desastrosa porque no hay forma de saber en todo el disco que datos le pertenecen.
Por esta razón UNIX almacena en caché las entradas de directorio para acelerar las lecturas, pero todas las escrituras de datos que provoquen algún cambio en la asignación de espacio o en algún otro tipo de metadato se realizan síncronamente —antes de volver al proceso desde la llamada al sistema—.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, si se hace un escritura de datos que extiende el tamaño de un archivo; el cambio del FCB correspondiente, con el nuevo tamaño de archivo y la lista actualizada de las direcciones de los bloques que contienen o van a contener los datos del archivo, se escribe en disco antes de terminar la llamada al sistema y devolver el control al proceso que la invocó.
Sin embargo, no ocurre lo mismo con los datos que el proceso quería escribir en el archivo.
El sistema operativo puede copiarlos a búferes internos en la memoria para escribirlos en disco más adelante, evitando interrumpir el proceso durante más tiempo.</p>
</div>
</div>
<div class="sect2">
<h3 id="_soft_updates">24.2. Soft Updates</h3>
<div class="paragraph">
<p>Para mejorar la eficiencia del sistema de archivos, sin comprometer la coherencia en caso de fallo, los distintos sabores de los sistemas UNIX BSD utilizan una técnica denominada <em>soft updates</em>.
<em>Cuando se monta un sistema de archivos con la opción <strong>soft updates</strong> el sistema operativo desactiva la escritura síncrona de los metadatos, permitiendo que estos sean escritos cuando los algoritmos de gestión de la caché lo consideren necesario, pero se impone cierto orden en el que dichas operaciones de escritura deben ser realizadas</em>.
Por ejemplo, cuando se van a escribir en el disco las modificaciones debidas a la creación de un nuevo archivo, el sistema se asegura de que primero se escribe el nuevo FCB —un <em>inodo</em>, en los sistemas UNIX BSD— y posteriormente escribe el directorio con la nueva entrada de archivo con el identificador a dicho FCB.
Es sencillo darse cuenta de que haciéndolo al revés, si el sistema fallase antes de crear el FCB, acabaríamos con una entrada de directorio que apuntaría a un FCB inválido.
Mientras que de esta manera el sistema de archivos permanecerá consistente aunque el sistema falle entre ambas operaciones.</p>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_de_archivos_basados_en_registro">24.3. Sistemas de archivos basados en registro</h3>
<div class="paragraph">
<p>Otra solución al problema de la coherencia consiste en aplicar técnicas de recuperación basadas en registro durante las actualizaciones de los metadatos del sistema de archivos.</p>
</div>
<div class="paragraph">
<p>Fundamentalmente <em>en los <strong>sistemas de archivos basados en registro</strong> —o con <strong>journaling</strong>— todos los cambios en los metadatos se escriben secuencialmente en un registro</em><sup class="footnote">[<a id="_footnoteref_27" class="footnote" href="#_footnotedef_27" title="View footnote.">27</a>]</sup>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Cada conjunto de operaciones necesario para realizar una tarea específica sobre el sistema de archivos es una <strong>transacción</strong></em>.
Por ejemplo, es una transacción el conjunto de operaciones necesarias para crear un nuevo archivo.</p>
</li>
<li>
<p><em>La lista de operaciones necesarias para completar una transacción se escribe secuencialmente y síncronamente —antes de terminar la llamada al sistema— en el registro</em>.
Cuando la lista de operaciones pendientes termina de ser escrita en el registro, se considera que las operaciones ha sido <em>confirmadas</em> y la llamada al sistema puede volver al proceso de usuario, permitiendo que continúe con su ejecución.</p>
</li>
<li>
<p>Mientras tanto, el sistema operativo va ejecutando las operaciones indicadas en el registro sobre las estructuras reales del sistema de archivos.
<em>A medida que se realizan los cambios se actualiza el registro para indicar las operaciones completadas</em>.</p>
</li>
<li>
<p><em>Cuando todas las operaciones de una transacción se han ejecutado con éxito, dicha transacción se considera completada y se elimina del registro</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En el supuesto de que el sistema falle:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Se comprueba el registro durante el montaje del sistema de archivos, antes de que pueda ser utilizado de nuevo.</em></p>
</li>
<li>
<p><em>Todas las transacciones confirmadas que contenga el registro estarán a medias</em>, por lo que será necesario terminar de aplicar las <em>operaciones pendientes</em> antes de finalizar el proceso de montaje.</p>
</li>
<li>
<p>Es posible que existan transacciones no confirmadas, es decir, transacciones que no terminaron de ser escritas en el registro antes del fallo y, por tanto, cuya lista de operaciones no está completa.
En ese caso, <em>todos los cambios correspondientes a las transacciones no confirmadas que hubieran sido aplicados al sistema de archivos, deberán deshacerse</em> para preservar la coherencia.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Esta técnica está empezando a resultar común en muchos sistemas operativos.
Hasta el punto de que es utilizada en sistemas tales como: ext3, ext4, NTFS, XFS, JFS, ReiserFS, etc.</p>
</div>
<div class="paragraph">
<p><em>Un efecto colateral de la utilización de un registro es la mejora del rendimiento en el acceso al sistema de archivo</em>.
La razón de esta mejora es que las costosas escrituras síncronas —es decir, antes de devolver el control al proceso— de los metadatos en lugares aleatorios del volumen se transforman en escrituras síncronas secuenciales —que son mucho más eficientes— en el registro.
Mientras que todas las operaciones indicadas en el registro se aplican asíncronamente mediante escrituras aleatorias en las estructuras apropiadas, por lo que pueden ser reordenadas a conveniencia para maximizar el rendimiento.
Recordemos que en el registro pueden haber operaciones de distintos procesos que afecten a regiones próximas del disco.
El resultado global es una significativa ganancia en la velocidad de las operaciones relativas a los metadatos, como por ejemplo la creación y borrado de archivos.</p>
</div>
<div class="paragraph">
<p>El sistema de archivos XFS modifica ligeramente esta técnica, sustituyendo las escrituras síncronas necesarias para actualizar el registro por escrituras asíncronas —es decir, el control se devuelve al proceso antes de terminar de escribir las operaciones en el registro y confirmar la transacción—.
El resultado es:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cierta mejora del rendimiento, porque el registro deja de ser el cuello de botella para las operaciones sobre los metadatos.
El registro es un recurso de acceso exclusivo.
Las operaciones de una transacción se deben escribir antes de devolver el control al proceso y de permitir que otro proceso a la espera escriba las operaciones de su transacción.</p>
</li>
<li>
<p>En el caso de que el sistema fallase, el uso de escrituras asíncronas podría provocar la corrupción del registro porque pueden ocurrir en cualquier orden.
Para evitarlo, XFS impone cierto orden en las operaciones de escritura sobre el registro, de forma similar a como se hace con los <em>soft updates</em>, de tal forma que asegura la coherencia del registro.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_de_archivos_basados_en_copia_durante_la_escritura">24.4. Sistemas de archivos basados en copia durante la escritura</h3>
<div class="paragraph">
<p><em>Las técnicas anteriores son necesarias para preservar la coherencia porque la modificación de los metadatos se hace sobrescribiendo los datos que ya existen</em>.
Es decir, cuando se crea un nuevo archivo el sistema busca un FCB libre, sobrescribe el bloque del dispositivo donde lo encuentra para almacenar el nuevo FCB, busca una entrada libre en el directorio y, nuevamente, sobrescribe el bloque del disco donde se almacena el directorio para incorporar la nueva entrada.
Si algunos de estos cambios tienen lugar pero otros no, el disco puede quedar inconsistente.</p>
</div>
<div class="paragraph">
<p><em>Los <strong>sistemas de archivos basados en copia durante la escritura</strong></em> —o <em>copy-on-write</em>— <em>evitan cambiar los metadatos sobrescribiendo en el sitio</em>.
En su lugar buscan un hueco libre, hacen en él una copia del bloque completo con los cambios y después modifican los metadatos del sistema de archivos que sirven para localizar el bloque modificado en su nueva ubicación.
Estos cambios, a su vez, tampoco se hacen sobrescribiendo, sino que disparan la creación de copias modificadas de los bloques afectados, lo que nuevamente va seguido de cambios en los metadatos que ayudan a localizarlos.
El proceso se repite hasta que se alcanza el <em>bloque de control de volumen</em> y se cambia, momento en el que toda la secuencia de cambios se consolida.</p>
</div>
<div class="paragraph">
<p>Los sistemas de archivos basados en copy-on-write suele hacer hacer uso intensivo de estructuras de datos basadas en árbol porque es muy sencillo mover un nodo de bloque, con un efecto mínimo en el resto de la estructura.
Por ejemplo, al crear un archivo:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Se busca un FCB libre, se lee el bloque que lo contiene en la memoria principal, se modifica y se escribe en un bloque libre</em>.
El sistema de archivos debe tener alguna estructura de datos que permita encontrar el bloque que contiene un FCB a partir de su identificador.
Por lo general esta estructura es algún tipo de árbol.
Así que se modifica el nodo del árbol que señala al bloque con el nuevo FCB para que conozca la nueva ubicación.
Este cambio implica crear un copia del bloque de dicho nodo con el cambio, lo que a su vez significa modificar el nodo que señala a este.
Y así sucesivamente hasta llegar a la raíz del árbol de FCB.</p>
</li>
<li>
<p><em>Se busca una entrada libre en el directorio que va a contener al archivo y se modifica para añadir el nombre del archivo, el identificador de su FCB y otras propiedades</em>.
Nuevamente, este cambio significa crear una copia, con los cambios descritos, del bloque que contiene la entrada y modificar el FCB del directorio para que contenga la nueva ubicación del bloque con el contenido del directorio.
Como antes, este cambio en el FCB dispara copias y modificaciones por todo el árbol de FCB, hasta la raíz</p>
</li>
<li>
<p>Una vez la raíz del árbol ha sido copiada a una nueva ubicación con los cambios, se actualiza su nueva posición en el <em>bloque de control de volumen.</em></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Si el sistema falla antes de la modificación del <em>bloque de control de volumen</em>, durante el montaje del sistema de archivos no quedará ni rastro de ninguno de los cambios porque dicho bloque aun hace referencia a la antigua raíz del árbol de FCB y, a partir de ellas, a todos los nodos, bloques y FCB originales.
Obviamente los sistemas que implementan este tipo de sistemas de archivo usan la memoria principal como caché con el objeto de combinar varias modificaciones sobre un mismo bloque antes de proceder a su escritura en disco, evitando desencadenar múltiples veces los cambios posteriores.</p>
</div>
<div class="paragraph">
<p>Los sistemas de archivos ZFS y Btrfs son los principales ejemplos de sistemas de archivos basados en <em>copy-on-write</em>.
Esta solución no sólo les permite tener las mismas propiedades que el uso de registro en cuanto a la preservación de la coherencia —con la ventaja de evitar dos escrituras en disco, una en el registro y otra para el cambio propiamente dicho— sino que además facilita que puedan ofrecer características adicionales, como la creación de copias instantáneas del volumen.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_implementación_de_sistemas_de_archivos">25. Implementación de sistemas de archivos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Como ya se ha comentado, un sistema de archivos suele estar compuesto de varios niveles diferentes.
En la se muestra un ejemplo de la estructura de un sistema de archivos diseñado en niveles.
Cada nivel utiliza las funciones de los niveles inferiores y proporciona nuevas funciones a los niveles superiores.
Estos niveles han sido descritos en el apartado <a href="#_estructura_de_un_sistema_de_archivos">Apartado 22.1</a>, mientras que las estructuras de metadatos utilizadas tanto en la memoria como en disco fueron tratadas brevemente en el <a href="#_estructuras_de_metadatos">Apartado 22.2</a>.</p>
</div>
<div class="paragraph">
<p>A continuación vamos a profundizar aun más en las estructuras y operaciones utilizadas para implementar los sistemas de archivos</p>
</div>
<div class="sect2">
<h3 id="_implementación_de_directorios">25.1. Implementación de directorios</h3>
<div class="paragraph">
<p>Cada directorio suele contener una estructura de datos que relaciona el nombre de cada archivo que contiene con el identificador de su FCB.
Dicho identificador permite localizar el FCB en la tabla de contenidos del volumen, que contiene el resto de los atributos del archivo.</p>
</div>
<div class="paragraph">
<p>En esta sección vamos a estudiar las formas más comunes de implementar la estructura de datos de un directorio.</p>
</div>
<div class="sect3">
<h4 id="_lista_lineal">25.1.1. Lista lineal</h4>
<div class="paragraph">
<p>El método mas simple para implementar un directorio <em>consiste en utilizar una lista lineal o vector de nombres de archivos junto al identificador al FCB de cada uno</em>.</p>
</div>
<div class="paragraph">
<p>Las acciones a realizar, para implementar cada una de las posibles operaciones sobre el directorio, serían:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Crear un archivo</strong>.
Primero se explora el directorio para estar seguros de que no haya ningún archivo con el mismo nombre.
Después se añade una nueva entrada al final del directorio.</p>
</li>
<li>
<p><strong>Borrar un archivo</strong>.
Primero se explora la lista en busca del archivo especificado y una vez localizada se libera la entrada correspondiente.
Para reutilizar la entrada del directorio tenemos diversas alternativas:</p>
<div class="ulist">
<ul>
<li>
<p><em>Se puede marcar la entrada como no utilizada</em>.
Para eso se puede emplear un nombre especial o utilizar algún campo adicional —a parte de nombre de archivo e identificador del FSB— que se ha añadido a la entrada con ese propósito.</p>
</li>
<li>
<p><em>Insertar un puntero a la entrada en una lista de entradas libres</em>, que se guarda dentro del mismo directorio.</p>
</li>
<li>
<p><em>Copiar la última entrada del directorio en la ubicación que ha quedado libre</em> y reducir la longitud del directorio.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>La principal desventaja de un directorio implementado como una lista lineal de entrada es que <em>para localizar un archivo es necesario realizar una búsqueda lineal</em>, lo cual puede resultar muy costoso en directorios con un número muy grande de archivos.
Utilizando una lista ordenada se puede reducir el tiempo medio de búsqueda, pero eso complica los procesos de creación y borrado, pues puede que sea necesario mover cantidades importantes de información para mantener la lista ordenada.
También se <em>puede utilizar una lista enlazada tanto para reducir el tiempo necesario para borrar un archivo como para facilitar la tarea de mantener ordenada la lista</em>.</p>
</div>
<div class="paragraph">
<p>Los sistemas de archivos FAT y FAT32 implementan los directorios utilizando una lista lineal, donde en cada entrada no sólo se almacena el nombre del archivo sino también el FCB del mismo.
Los sistemas de archivos ext2 y UFS también utilizan una lista lineal no ordenada, donde sólo se almacena el nombre del archivo o subdirectorio y el identificador del <em>inodo</em> —el FCB, esos sistemas de archivo— correspondiente.</p>
</div>
</div>
<div class="sect3">
<h4 id="_tabla_de_dispersión">25.1.2. Tabla de dispersión</h4>
<div class="paragraph">
<p>En los directorios implementados con una tabla de dispersión también <em>se almacenan las entradas de directorio en una lista lineal, pero al mismo tiempo se utiliza una tabla de dispersión para reducir enormemente el tiempo de búsqueda en el directorio</em>.
La tabla de dispersión se indexa con un valor calculado por cierta función de dispersión a partir del nombre del archivo para obtener la ubicación de dicho archivo dentro de la lista lineal.</p>
</div>
<div class="paragraph">
<p><em>El único inconveniente es que debemos tratar la posible aparición de colisiones</em>, que son aquellas situaciones en las que dos nombres de archivo proporcionan, al aplicar la función de dispersión, la misma ubicación en la tabla.
Esto se puede resolver utilizando una lista enlazada en cada entrada de la lista —cada entrada en al lista señalaría la ubicación de la siguiente entrada de la lista que tiene el mismo valor para la función de dispersión— a cambio de que las búsquedas sean un poco más lentas.
En cualquier caso, éste método será normalmente más rápido que una búsqueda lineal por todo el directorio.</p>
</div>
</div>
<div class="sect3">
<h4 id="_árbol_b">25.1.3. Árbol B</h4>
<div class="paragraph">
<p>Para mantener el directorio ordenado, algunos sistemas de archivos modernos utilizan estructuras de datos en árbol más sofisticadas, como por ejemplo árboles B.</p>
</div>
<div class="paragraph">
<p>Un caso concreto es el sistema de archivos NTFS, utilizado por Microsoft Windows.
NTFS utiliza una estructura de datos denominada árbol B+ para almacenar el índice de los nombres de archivo contenidos en un directorio.
En la entrada en la MFT de cada directorio se almacena un atributo, denominado <em>raíz del índice</em> que, si el directorio es de pequeño tamaño, contiene todas las entradas de archivos del directorio.
Pero para un directorio de gran tamaño, la <em>raíz del índice</em> sólo puede almacenar unas pocas entradas de archivos del directorio.
En ese caso la <em>raíz del índice</em> contiene el nivel superior del árbol B+.
Es decir, cada una de esas entradas de archivos en la <em>raíz del índice</em> incluye también un puntero al bloque del disco que contiene un nodo del árbol con las entradas con nombres alfabéticamente anteriores a ese.
Si en dicho nodo tampoco caben todas las entradas, sólo podrá contener algunas de ellas, por lo que cada una tendrá a su vez un puntero a un nuevo nodo del árbol; y así sucesivamente</p>
</div>
<div class="paragraph">
<p>Las <em>ventajas</em> de los árboles B+ son:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Eliminan el coste de reordenar las entradas del directorio.</em></p>
</li>
<li>
<p><em>La longitud desde la raíz del árbol hasta un nodo hoja es la misma para todas los caminos por el árbol</em>.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El sistema de archivos XFS también utiliza un árbol B+, pero en éste
caso la implementación es un poco más compleja:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Un directorio de pequeño tamaño almacena sus entradas como una lista lineal no ordenada dentro de su mismo <em>inodo</em> o FCB.</p>
</li>
<li>
<p>Cuando el directorio no cabe en el <em>inodo</em> se le asigna un bloque propio, donde el directorio es implementado con una tabla de dispersión, tal y como hemos visto anteriormente.</p>
</li>
<li>
<p>Cuando el tamaño del directorio excede el tamaño del bloque, la tabla de dispersión se extrae y se almacena en un bloque diferente. La lista lineal también se extrae, pero no tiene que ser almacenada en un único bloque, sino que puede estar repartida por distintos bloques a lo largo del disco.</p>
</li>
<li>
<p>Finalmente, cuando la tabla de dispersión excede el tamaño de un bloque, dicha tabla se convierte en un árbol B+.</p>
</li>
</ol>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_métodos_de_asignación">25.2. Métodos de asignación</h3>
<div class="paragraph">
<p>El siguiente problema es <em>cómo</em> asignar el espacio disponible en el disco a los archivos almacenados, de forma que el espacio sea utilizado de la forma más eficiente y que se pueda acceder a los archivos de la forma más rápida posible.</p>
</div>
<div class="paragraph">
<p>Como la unidad mínima de asignación de espacio a un archivo es el bloque, la fragmentación interna suele ser un problema común a todos los métodos que veremos a continuación.</p>
</div>
<div class="sect3">
<h4 id="_asignación_contigua">25.2.1. Asignación contigua</h4>
<div class="paragraph">
<p><em>La <strong>asignación contigua</strong> requiere que cada archivo ocupe un conjunto contiguo de bloques en el disco</em>.
Esto es muy eficiente, puesto que el acceso a todos los datos de un archivo requiere un movimiento mínimo del cabezal del disco.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>El problema de la asignación contigua puede verse como un caso concreto del problema de la asignación dinámica del almacenamiento</em> (véase el <a href="#_hiperpaginación">Apartado 17.9</a>).
Es decir, que en un momento dado tendremos una petición de tamaño <em>n</em> que deberemos satisfacer con una lista de huecos libres de tamaño variable.
Como ya estudiamos anteriormente, las estrategias más comunes son las de el <em>primer ajuste</em> y el <em>mejor ajuste</em>.</p>
</li>
<li>
<p><em>La asignación contigua sufre el problema de la <strong>fragmentación externa</strong></em>.
La solución sería utilizar alguna forma de <strong>compactación</strong>, pero esto puede llevar mucho tiempo en discos duros de gran tamaño y en algunos sistemas esta tarea tiene que realizarse con el dispositivo desmontado.
Por eso es conveniente evitar utilizar técnicas de compactación en los sistemas en producción.
Afortunadamente, la mayor parte de los sistemas operativos modernos que necesitan mecanismos de <em>desfragmentación</em> pueden realizar esta tarea sin detener el sistema, aunque la perdida de rendimiento puede ser significativa.</p>
</li>
<li>
<p><em>En la asignación contigua es necesario determinar cuanto espacio necesita un archivo antes de asignárselo, pero esto no siempre es posible</em>.
Por ejemplo, si vamos a copiar un archivo, es indudable que conocemos de antemano cuanto espacio necesita la copia.
¿Pero qué pasa cuando, por ejemplo, vamos a crear uno nuevo? Entonces cuando se cree el archivo es necesario que el usuario indique una estimación del espacio que va necesitar.
¿Y si posteriormente que queremos añadir nuevos datos? Entonces, si hemos utilizado la estrategia del <em>mejor ajuste</em>, lo más probable es que el espacio situado a ambos lados del archivo ya esté ocupado.
Para resolver esto existen dos posibilidades:</p>
<div class="ulist">
<ul>
<li>
<p><em>La primera es terminar el programa de usuario</em>, emitiendo un error.
Entonces, el usuario deberá volver a crear el archivo indicando más espacio y volver a ejecutar el programa.
Puesto que las ejecuciones repetidas pueden ser muy costosas, lo más común es que el usuario acabe sobrestimando el espacio, lo que dará como resultado un desperdicio de espacio considerable.</p>
</li>
<li>
<p><em>La segunda es buscar un hueco libre de mayor tamaño y copiar el contenido del archivo al nuevo espacio</em>.
Esto puede hacerse siempre que exista suficiente espacio, aunque puede consumir bastante tiempo.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Para minimizar estos problemas, se puede implementar un esquema de asignación contigua modificado, donde <em>se asigna inicialmente un bloque contiguo de espacio al archivo y, posteriormente, si dicho espacio resulta no ser lo suficientemente grande, se añade otra área de espacio contiguo, denominado *extensión*</em>.
La ubicación de los bloques de un archivo se registra incluyendo en el FCB la dirección del primer bloque de cada extensión que compone el archivo, así como el número de bloques que ocupa cada una.</p>
</div>
<div class="paragraph">
<p>Los sistemas de archivo XFS y ext4 utilizan extensiones para optimizar su funcionamiento, pues cuantos más bloques contiguos sean asignados a un archivo, menos reposicionamientos del cabezal del disco son necesarios para leerlos.
Por ejemplo, en ext4 el espacio se asigna a los archivos en extensiones de hasta 128MB en bloques, generalmente, de 4KB.</p>
</div>
</div>
<div class="sect3">
<h4 id="_asignación_enlazada">25.2.2. Asignación enlazada</h4>
<div class="paragraph">
<p><em>En la <strong>asignación enlazada</strong> cada archivo es una lista enlazada de bloques de disco</em>, pudiendo estos bloques estar dispersos por todo el disco:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Cada entrada de directorio contiene un puntero al primer</em> bloque y, en ocasiones, al último para facilitar que se puedan añadir nuevos datos al final</p>
</li>
<li>
<p><em>Cada bloque contiene un puntero al bloque siguiente</em>.
Por ejemplo, si cada bloque tiene 512 bytes de tamaño y un puntero requiere 4 bytes, los bloques de disco tendrán un tamaño efectivo de 508 bytes.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Este mecanismo resuelve todos los problemas de la asignación contigua.
Además:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>No hay fragmentación externa</em>, puesto que pueden utilizarse cualquier bloque libre para satisfacer una solicitud de espacio.</p>
</li>
<li>
<p><em>No es necesario declarar el espacio del archivo en el momento de crearlo</em>, pues siempre podrá seguir creciendo mientras hayan bloques libres.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Sin embargo, la asignación enlazada también tiene sus desventajas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Sólo resulta eficaz para archivos de acceso secuencial</em>.
Si queremos ir directamente al bloque i-esimo de un archivo, tendremos que comenzar desde el principio e ir leyendo cada bloque para obtener el puntero que nos indica el siguiente bloque.
Es muy posible que en ocasiones esas lecturas deban ir precedidas de un reposicionamiento de los cabezales del disco.</p>
</li>
<li>
<p><em>Se pierde cierta cantidad de espacio con los punteros</em>.
Si, por ejemplo, un puntero ocupa 4 bytes y un bloque tienen un tamaño de 512 bytes, el 0,758% del espacio en disco será utilizado para los punteros, en lugar de para almacenar información útil.
La solución para este problema consiste en asignar los bloques en grupos, denominados <strong>clusters</strong>.
Así, el primer bloque de cada <em>cluster</em> sólo tendría que almacenar un puntero al siguiente <em>clúster</em>, lo que reduciría la cantidad de espacio desperdiciada en los punteros y mejoraría la eficiencia al reducir el número de reposicionamiento del cabezal del disco.
Sin embargo, también incrementaría el grado de fragmentación interna pues se pierde más espacio cuando un <em>cluster</em> está parcialmente lleno.</p>
</li>
<li>
<p><em>Otro problema es la fiabilidad</em>.
Teniendo en cuenta que los archivos están enlazados mediante punteros, ¿qué sucedería si uno de esos punteros se pierde o resulta dañado?</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El sistema de archivos FAT utiliza una variante del mecanismo de
asignación enlazada en la que se utiliza una <strong>tabla de asignación de
archivo</strong> o <strong>FAT</strong> (<em>File-Allocation Table</em>). Éste método consiste
en lo siguiente:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>La FAT es una tabla que contiene una entrada por cada bloque del disco y que se indexa según el número de bloque. Es decir, la entrada 10 de la FAT contiene información del bloque 10 del disco. La FAT se almacena en una sección al principio del volumen.</p>
</li>
<li>
<p>Cada entrada de directorio de un archivo contiene, a parte del nombre de dicho archivo y otras atributos, el número de bloque del primer bloque del disco con datos del archivo.</p>
</li>
<li>
<p>La entrada de la FAT indexada según ese número de bloque del primer bloque del archivo contiene el número de bloque del siguiente bloque del archivo. Iterando de esa manera se puede conocer los números de bloque de todos los bloques de un archivo.</p>
</li>
<li>
<p>El último bloque del archivo se indicar con un valor especial en su entrada en la FAT.</p>
</li>
<li>
<p>Los bloques no utilizados se indican con un valor igual a 0 en su entrada en la FAT.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El uso de la FAT puede provocar un número importante de
reposicionamientos del cabezal de disco debido a que siempre es
necesario volver al principio del volumen para leer la FAT. Por eso, es
muy habitual que el sistema operativo intente mantener una copia de la
FAT en la memoria a modo de cache.</p>
</div>
<div class="paragraph">
<p>Una de las ventajas de este esquema es que mejora el tiempo de acceso
aleatorio, respecto a la asignación enlazada convencional, porque el
cabezal del disco puede encontrar la ubicación de cualquier bloque a
partir de la información en la FAT.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_asignación_indexada">25.2.3. Asignación indexada</h4>
<div class="paragraph">
<p><em>El mecanismo de <strong>asignación indexada</strong> agrupa todos los punteros de la asignación enlazada en una única ubicación</em>: el <strong>bloque de índices</strong>.
Así se resuelve la falta de eficiencia de la asignación enlazada —convencional, en ausencia de FAT— cuando se realizan accesos aleatorios:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Cada archivo tiene su propio bloque de índices</em>, que es un vector de direcciones de bloques de disco.</p>
</li>
<li>
<p><em>La entrada i-ésima del bloque de índice contiene la dirección del bloque i-ésimo del archivo</em>.</p>
</li>
<li>
<p><em>Cada entrada de directorio contiene la dirección del bloque de índices del archivo correspondiente</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Este mecanismo soporta el acceso aleatorio eficiente, además de no sufrir el problema de la fragmentación externa.
Sin embargo, también tiene sus desventajas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Se pierde más espacio en los punteros que con el mecanismo de asignación enlazada</em>.
No olvidemos que siempre hay que reservar un bloque de índices completo para cada archivo, mientras que con la asignación enlazada sólo se pierde el espacio de los punteros que realmente es necesario utilizar.</p>
</li>
<li>
<p><em>Debemos determinar el tamaño del bloque de índices</em>.
Por lo anterior y puesto que cada archivo debe tener un bloque de índices, ese bloque debe ser lo más pequeño posible para no perder espacio.
Pero si es demasiado pequeño, no podrá almacenar suficientes punteros para un archivo de gran tamaño.
Entre los mecanismos que pueden utilizarse para resolver este problema están los siguientes:</p>
<div class="ulist">
<ul>
<li>
<p><em>En el <strong>esquema enlazado</strong> se enlazan los bloques de índices</em>.
Por ejemplo, se puede utilizar el último puntero del bloque de índices para apuntar al siguiente bloque de índices.
Si dicho puntero tiene el valor nulo, entonces estamos en el último bloque de índices.</p>
</li>
<li>
<p><em>En el <strong>índice multinivel</strong> los punteros del bloque de índices no señalan a los bloques del archivo, sino a conjunto de bloques de índices de segundo nivel</em>.
Estos a su vez señalan a los bloques del archivo.
Esta técnica puede puede ampliarse utilizando un tercer o cuarto nivel, dependiendo del tamaño máximo de archivo que se desee.</p>
</li>
<li>
<p><em>En el *esquema combinado*</em> las primeras entradas del bloque de índices apuntan directamente a los primeros bloques del archivo.
Mientras que las siguientes entradas contiene punteros indirectos, que apunta a un conjunto de bloques de índices de segundo nivel, seguidos por entradas que contienen punteros doblemente indirectos, e incluso triplemente indirectos.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Para mejorar el rendimiento de los mecanismos de asignación indexados, es muy común que el sistema operativo intente mantener los bloques de índices en la memoria caché.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Los sistemas de archivos ext2 y ext3 utilizan el mecanismo de
asignación indexada con esquema combinado. Concretamente el mecanismo en
ext2 se implementa de la siguiente manera:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>El disco se divide en múltiples grupos de bloques.</p>
</li>
<li>
<p>En cada grupo, los primeros bloques se utilizan para almacenar una tabla de <em>inodos</em> –los FCB de los archivos en el grupo–. El resto de los bloques se intentan utilizar para almacenar los datos de los archivos representados por los <em>inodos</em> del grupo.</p>
</li>
<li>
<p>Entre otra información, dentro de cada <em>inodo</em> se almacenan los punteros a los bloques del archivo, en lugar de utilizar un bloque de índices.</p>
</li>
<li>
<p>Los primeros 12 punteros en el <em>inodo</em> son directos, seguidos de un puntero indirecto y un puntero doblemente indirecto. Esto permite que el puntero de archivo sea de 64 bits y, por tanto, que se puedan almacenar 264 bytes de información en cada archivo.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_gestión_del_espacio_libre">25.3. Gestión del espacio libre</h3>
<div class="paragraph">
<p>Puesto que el espacio en disco es limitado, necesitamos poder reutilizar el espacio de los archivos borrados.
Para controlar el espacio libre en el disco, <em>el sistema mantiene una <strong>lista de espacio libre</strong> que contiene todos los bloques de disco libres</em>.
Para crear un archivo, se explora la lista de espacio libre hasta obtener la cantidad de espacio requerida y asignamos ese espacio al nuevo archivo.
A continuación estudiaremos como puede ser implementada esa lista.</p>
</div>
<div class="sect3">
<h4 id="_vector_de_bits">25.3.1. Vector de bits</h4>
<div class="paragraph">
<p><em>La lista de espacio libre puede ser implementada como un <strong>vector de bits</strong> o <strong>mapa de bits</strong>, donde cada bloque es representado por un bit</em>.
Si el bloque está libre, el bit está a 1; mientras que si el bloque está asignado, el bit está a 0.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Este enfoque es relativamente sencillo y eficiente</em>, puesto que muchos procesadores disponen de instrucciones para manipulación de bits que pueden utilizarse para obtener el primer bloque libre.
Por ejemplo, la familia de procesadores x86, a partir del 80386, tiene instrucciones que devuelven la posición del primer bit a 1 en el valor de un registro.</p>
</li>
<li>
<p>Sin embargo, <em>los vectores de bits son ineficientes a menos que se mantenga el vector completo en la memoria principal</em>, escribiéndose ocasionalmente en el disco.
Esto puede ser imposible para los discos de gran tamaño, en función de la cantidad de memoria principal.
Por ejemplo, un disco de 40 GB con bloques de 1 KB necesitará un mapa de bits de más de 5 MB, lo que no es un gran requisito para un sistema moderno pero si lo era hace dos décadas.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El sistema de archivo NTFS y la familia <em>extended filesystem</em> —es decir, ext, ext2, ext3, etc.— utilizan mapas de bits tanto para gestionar los bloques de datos libres como las entradas disponibles en la tabla de <em>inodos</em>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lista_enlazada">25.3.2. Lista enlazada</h4>
<div class="paragraph">
<p>Otra técnica <em>consiste en enlazar todos los bloques de disco libres</em>.
Para eso se puede mantener un puntero al primer bloque libre en una ubicación especial del disco y que ese bloque contenga un puntero al siguiente bloque libre del disco.
El segundo bloque contendría un puntero al tercer bloque libre y así sucesivamente.</p>
</div>
<div class="paragraph">
<p><em>El inconveniente es que recorrer la lista no resulta eficiente</em>, pues tenemos que leer cada bloque para conocer la dirección del siguiente bloque libre en disco.
Sin embargo, debemos tener en cuenta que no es frecuente tener que recorrer la lista de espacio libre completa porque, por lo general, basta con encontrar el primer bloque libre para asignar el espacio.</p>
</div>
<div class="paragraph">
<p>El método FAT incorpora el control de bloques libres dentro de la <em>tabla de asignación de archivos</em>, por lo que no se necesita ningún método adicional</p>
</div>
</div>
<div class="sect3">
<h4 id="_agrupamiento">25.3.3. Agrupamiento</h4>
<div class="paragraph">
<p><em>Una modificación de la técnica basada en la lista enlazada consiste en almacenar las direcciones de n bloques libres en el primer bloque libre</em>.
Los primeros <em>n — 1</em> de esos bloques estarían realmente libres, pero el último de esos bloques apuntaría a otro bloque con <em>n</em> bloques libres.
Así, podrían localizarse rápidamente las direcciones de un gran número de bloques libres, lo cual mejora la eficiencia respecto a la técnica de lista enlazada.</p>
</div>
</div>
<div class="sect3">
<h4 id="_recuento">25.3.4. Recuento</h4>
<div class="paragraph">
<p>Generalmente los bloques son asignados o liberados en bloques contiguos, especialmente si el espacio es asignado mediante asignación contigua o en <em>extensiones</em> o <em>clusters</em>.
Esto puede ser aprovechado para <em>mantener una lista donde cada entrada almacena la dirección del primer bloque de un conjunto de bloques libres contiguo, así como el número de bloques del conjunto</em>.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, el sistema de archivos XFS utiliza un árbol B+ para almacenar las direcciones de las extensiones de bloques libres y mantenerlas ordenadas por el tamaño de la extensión a la que apuntan.
Así el sistema operativo puede localizar rápidamente el espacio libre necesario para satisfacer una necesidad de espacio concreta.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sistemas_de_archivos_virtuales">25.4. Sistemas de archivos virtuales</h3>
<div class="paragraph">
<p>En el <a href="#_montaje_de_sistemas_de_archivos">Apartado 22.3</a> vimos cómo el sistema operativo <em>monta</em> sistemas de archivos de tal forma que aparenten estar integrados en una única estructura de directorios, permitiendo a los usuarios moverse de forma transparente entre distintos dispositivos y tipos de sistemas de archivos.
Para hacerlo, un sistema operativo moderno debe ser capaz de soportar de manera eficiente distintos tipos de sistemas de archivos, ocultando sus diferencias de cara a los usuarios.</p>
</div>
<div class="paragraph">
<p>Un método para implementar múltiples tipos de sistemas de archivos consiste en escribir diferentes rutinas de acceso, manipulación y gestión, a los directorios y a los archivos, para cada uno de los tipos de sistema de archivo existentes.
Sin embargo, en lugar de esta solución, la mayoría de los sistemas operativos utilizan técnicas de orientación a objetos para implementar diferentes tipos de sistemas de archivos detrás de una misma interfaz de programación.
Es decir, <em>se utilizan estructuras de datos y procedimientos comunes para separar las llamadas al sistema de los detalles de su implementación real para cada uno de los sistemas de archivos</em>.</p>
</div>
<div class="paragraph">
<p>La implementación de un sistema de archivos está compuesta de tres niveles fundamentales:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>El primer nivel es la <em>interfaz del sistema de archivos</em>, a la que acceden los desarrolladores a través de las llamadas al sistema.
Estamos hablando de las llamadas <code>open()</code>, <code>read()</code>, <code>write()</code> y <code>close()</code>, entre otras, y de los descriptores de archivos.
Esta interfaz es la misma sea cual sea el sistema de archivos al que se esté intentando acceder.</p>
</li>
<li>
<p>El segundo nivel es <em>la interfaz del <strong>sistema de archivos virtual</strong> o <strong>VFS</strong> (Virtual File System)</em>.
Este nivel es utilizado por el anterior para atender las peticiones realizadas.
Describe operaciones genéricas sobre cualquier sistema de archivos y estructuras genéricas como, por ejemplo, un FCB virtual —que en algunos sistemas operativos se denomina <em>vnodo</em>— <em>que identifica de forma unívoca a cada archivo o directorio en uso en el sistema</em> —un <em>inodo</em> en los sistemas de archivos de Linux solo identifica a un archivo de forma unívoca dentro del mismo sistema de archivos— y que da acceso a sus metadatos.
Este nivel cumple con dos importantes funciones:</p>
<div class="ulist">
<ul>
<li>
<p><em>Separa las operaciones genéricas sobre el sistema de archivos con respecto a su implementación</em>.
VFS define una interfaz muy clara común para todos los sistemas de archivos.
Pero en el mismo sistema existirán diversas implementaciones de la interfaz VFS, una para cada sistema de archivos diferente.</p>
</li>
<li>
<p><em>Proporcionar un mecanismo para acceder de forma coherente a los archivos a través de la red</em>.
Una implementación de VFS no tiene que estar limitada exclusivamente a ofrecer acceso a archivos en dispositivos conectados físicamente al sistema.
Las operaciones de la interfaz VFS pueden resolverse utilizando un protocolo de acceso a algún servidor de archivos conectado a la red.</p>
</li>
</ul>
</div>
</li>
<li>
<p>El tercer nivel es donde <em>se implementa cada tipo de sistema de archivos o los distintos protocolos de los servidores de archivos en la red</em>.
La interfaz VFS recurre a la implementación correspondiente para cada tipo de sistema de archivos para satisfacer las solicitudes de los niveles superiores.
Así, por ejemplo, un <code>read()</code> puede implicar que se tenga que recuperar el <em>vnodo</em> del archivo involucrado desde la tabla del archivos abiertos, usando el descriptor indicado en la llamada al sistema.
Después se <em>invocaría la operación _VFS</em> <code>read()</code>, sobre el <em>vnodo</em>, en la implementación concreta de VFS según el tipo de sistema de archivos involucrado.
Será esa implementación quien extraiga del <em>vnodo</em> la información necesaria —por ejemplo, el <em>inodo</em> real del archivo en el sistema de archivos— para llevar acabo la operación indicada, según las especificidades del sistema de archivos.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_planificación_de_disco">26. Planificación de disco</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Como ya hemos comentado, es responsabilidad del sistema operativo usar los recursos del hardware de forma eficiente.
Eso incluye planificar los procesos en la CPU para conseguir el mínimo tiempo de espera que sea posible o aprovechar de la mejor forma la memoria principal disponible para atender la demanda de los distintos procesos al mismo tiempo; pero también, intentar obtener el menor tiempo de acceso y el mayor ancho de banda posible en el acceso a los discos.</p>
</div>
<div class="sect2">
<h3 id="_rendimiento_del_acceso_a_disco">26.1. Rendimiento del acceso a disco</h3>
<div class="paragraph">
<p>En un disco duro magnético el <strong>tiempo de acceso al disco</strong> \$T^d\$ viene determinado por el <strong>tiempo de búsqueda</strong> \$T^b\$ y la <strong>latencia rotacional</strong> \$T^r\$:</p>
</div>
<div class="stemblock">
<div class="content">
\$T_d=T_b+T_r\$
</div>
</div>
<div class="paragraph">
<p><em>El tiempo de búsqueda \$T^b\$ es el tiempo que se tarda en mover el brazo del disco hasta el cilindro deseado.
Mientras que la latencia rotacional \$T^r\$ es el tiempo que hay que esperar para que el disco gire _asta que la cabeza llegue al sector deseado</em> del cilindro.
Por lo tanto, el <em>tiempo de acceso al disco</em> es menor cuando se realizan accesos consecutivos a sectores físicamente próximos que cuando están dispersos por todo el disco.</p>
</div>
<div class="paragraph">
<p><em>El <strong>ancho de banda</strong> o <strong>tasa de transferencia</strong> del disco es el número total de bytes transferidos dividido por el tiempo total que transcurre desde la primera solicitud de servicio a la terminación de la última transferencia</em> con la que se atiende la petición.
Al considerar todo el tiempo necesario para atender la petición, a más <em>tiempo de acceso al disco</em> menor es el <em>ancho de banda</em>.</p>
</div>
<div class="paragraph">
<p>En los dispositivos de almacenamiento basados en memorias de estado sólido (véase el <a href="#_memorias_de_estado_sólido">Apartado 19.3</a>) el tiempo de acceso viene determinado por las características de la memoria, entre otros factores, lo que hace que las diferencias entre accesos secuenciales y accesos aleatorios sean mucho menos significativas.</p>
</div>
</div>
<div class="sect2">
<h3 id="_cola_de_es_al_disco">26.2. Cola de E/S al disco</h3>
<div class="paragraph">
<p>Cuando se solicita una operación de E/S sobre el almacenamiento el sistema operativo puede atender la petición sobre la marcha si la controladora y la unidad de disco están disponibles.
Pero si están ocupadas, la solicitud se almacena en una cola de peticiones pendientes.
Cuando se resuelve una solicitud, el sistema operativo escoge otra de la cola y se comunica con el hardware para programar la siguiente petición.
La cuestión es ¿cuál es el orden adecuado para escoger la peticiones de E/S de la cola si se quiere acceder al disco de la forma más eficaz posible?</p>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_fcfs">26.3. Planificación FCFS</h3>
<div class="paragraph">
<p>En la planificación <strong>FCFS</strong> (<em>First Come, First Served</em>) o <em>primero que llega, primero servido</em> la cola es FIFO.
Es decir, <em>se atienden las solicitudes en orden de llegada</em>.
Es la planificación más simple y es equitativa —pues se atiende a todos los procesos por igual— pero no proporciona el servicio más rápido en disco duros magnéticos, donde interesa mover el brazo del disco lo menos posible.</p>
</div>
<div class="paragraph">
<p>En los sistemas operativos Linux el FCFS es denominado NOOP y se suele utilizar en los discos basados en memorias de estado sólido, donde reordenar las solicitudes no proporciona una mejora significativa del rendimiento, o cuando se utilizan controladoras de disco inteligentes que pueden reordenar las solicitudes según su propio criterio.</p>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_sstf">26.4. Planificación SSTF</h3>
<div class="paragraph">
<p>En la planificación <strong>SSTF</strong> (<em>Sortest</em> <em>Seek Time First</em>) o algoritmo de <em>tiempo de búsqueda más corto</em>, de toda cola se selecciona la solicitud con el menor <em>tiempo de búsqueda</em> desde la posición actual de la cabeza.
Como el <em>tiempo de búsqueda</em> se incrementa a medida que lo hace el número de cilindros que es necesario recorrer, este algoritmo de planificación primero da servicio a las solicitudes cercanas a la posición actual de la cabeza, antes de alejarse para dar servicio a otras solicitudes.
Aun así, la solución no es óptima.</p>
</div>
<div class="paragraph">
<p>El problema de SSTF es que <em>puede provocar inanición de algunas solicitudes</em> si van llegando constantemente nuevas solicitudes sobre regiones cercanas a donde está actualmente la cabeza del disco.</p>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_scan_y_c_scan">26.5. Planificación SCAN y C-SCAN</h3>
<div class="paragraph">
<p>En la planificación <strong>SCAN</strong> o algoritmo de <em>exploración</em> o del <em>ascensor</em> <em>el brazo del disco comienza en un extremo del disco y se mueve hacia el otro atendiendo solicitudes a medida que pasa por cada cilindro</em>, hasta llegar al otro extremo del disco.
En el otro extremo la dirección de movimiento de la cabeza se invierte para recorrer el disco en sentido inverso, repitiendo el proceso.</p>
</div>
<div class="paragraph">
<p>Suponiendo que las solicitudes se distribuyen de forma uniforme a lo largo del disco, es de suponer que cuando se llega a un extremo, antes de volver, la cantidad de solicitudes en dicho extremo será notablemente menor que en el otro extremo del disco.
Entonces ¿por qué no empezar por el otro extremo?</p>
</div>
<div class="paragraph">
<p><em>A la variante del SCAN que cuando llega a un extremo vuelve al inicio, sin atender ninguna solicitud por el camino, para volver a empezar se la denomina <strong>C-SCAN</strong></em>.
El resultado es que el tiempo que tiene que esperar una solicitud para ser atendida es más uniforme que con el algoritmo SCAN.</p>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_look_y_c_look">26.6. Planificación LOOK y C-LOOK</h3>
<div class="paragraph">
<p>En teoría los algoritmos SCAN y C-SCAN hacen que el brazo recorra los cilindros del primero al último.
Sin embargo realmente no se suelen implementar así.
Por lo general, <em>cuando en el recorrido del brazo, tras atender una solicitud, se descubre que ya no hay más solicitudes siguiendo la misma dirección, el brazo invierte la dirección sin llegar hasta el extremo del disco</em>.
A estas variantes de SCAN y C-SCAN se las denomina <strong>LOOK</strong> y <strong>C-LOOK</strong>, respecitvamente.</p>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_n_step_scan_n_step_look_y_fscan">26.7. Planificación N-Step-SCAN, N-Step-LOOK y FSCAN</h3>
<div class="paragraph">
<p>Los algoritmos <em><strong>N-Step-SCAN</strong> y <strong>N-Step-LOOK</strong></em> son variantes de los algoritmos SCAN y LOOK, respectivamente, donde <em>se limita a N el número de solicitudes que se atenderán en cada barrido del brazo del disco</em>.
Estos algoritmos funcionan de la siguiente manera:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Se utiliza una cola con espacio para <em>N</em> solicitudes pendientes que se van atendiendo mientras el brazo barre el disco.</p>
</li>
<li>
<p>Mientras tanto, todas las nuevas solicitudes se incorporan a una cola diferente.</p>
</li>
<li>
<p>Cuando el brazo termina el barrido y las <em>N</em> primeras solicitudes han sido atendidas, el planificador toma otras <em>N</em> solicitudes de la segunda cola y las introduce en la primera para repetir el proceso.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Si en lugar de copiar <em>N</em> peticiones de la segunda a la primera cola se copian todas las solicitudes pendientes, el algoritmo se denomina F-SCAN.</p>
</div>
<div class="paragraph">
<p>Estos algoritmos previenen un problema denominado <em>rigidez del brazo</em> —<em>arm stickiness</em>, en inglés— a diferencia de los algoritmos SSTF, SCAN, C-SCAN, LOOK y C-LOOK.
El termino <em>rigidez del brazo</em> hace referencia a cuando hay un flujo continuo de solicitudes para el mismo cilindro, lo que hace que con los algoritmos anteriores el brazo no avance por los cilindros hasta llegar la otro extremo.
Como FSCAN, N-Step-SCAN y N-Step-LOOK separan las solicitudes en dos colas, haciendo que las nuevas tengan que esperar, el brazo siempre continua su barrido hacia el extremo del disco.</p>
</div>
</div>
<div class="sect2">
<h3 id="_planificación_cfq">26.8. Planificación CFQ</h3>
<div class="paragraph">
<p><em>El planificador <strong>CFQ</strong> (Completely Fair Queuing) se diseñó para compartir de forma equitativa el ancho de banda entre todos los procesos que solicitan acceso al disco</em>.
Es utilizado actualmente por defecto en los sistemas Linux modernos y funciona de la siguiente manera:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>CFQ mantiene una cola de solicitudes para cada proceso y en ella inserta las solicitudes síncronas de E/S.
Cada cola tiene una ventana de tiempo —o <em>cuanto</em>— para acceder al disco.
La longitud de la ventana de tiempo y el tamaño máximo de cada cola dependen de la prioridad de E/S que tenga el proceso.</p>
</li>
<li>
<p>CFQ mantiene una cola de solicitudes por cada prioridad de E/S, donde se insertan las solicitudes asíncronas de todos los procesos.
Una solicitud asíncronas se inserta en una cola u otra según la prioridad del proceso que la generó.</p>
</li>
<li>
<p>Usando el algoritmo <em>round-robin</em>, el planificador CFQ recorre las colas y extrae de ellas las solicitudes durante el tiempo marcado por el cuanto de cada una.
Las solicitudes extraídas se insertan en la cola de envío, donde se ordenar para minimizar el <em>tiempo de búsqueda</em>, antes de ser enviadas <em>al</em> dispositivo.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_bibliografía">Bibliografía</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Parte de los contenidos de este documento están basados en las siguientes fuentes:</p>
</div>
<div class="ulist bibliography">
<ul class="bibliography">
<li>
<p><a id="Bavier2000"></a>[Bavier2000]
Bavier, A. «Creating New CPU Schedulers with Virtual Time». En 21st IEEE Real-Time Systems Symposium (RTSS 2000) WIP Proceedings, 2000.</p>
</li>
<li>
<p><a id="Friedman1999"></a>[Friedman1999]
Friedman, M. B. «Windows NT Page Replacement Policies». En 25th International Computer Measurement Group Conference, December 5-10, 1999, Pag. 234-244.</p>
</li>
<li>
<p><a id="Ganger2000"></a>[Ganger2000]
Ganger, G. R., McKusick, M. K., Soules, C. A. N. y Patt, Y. N. «Soft Updates: A Solution to the Metadata Update Problem in File Systems». En ACM Transactions on Computer Systems, Vol. 18, No. 2, May 2000, Pag. 127—153.</p>
</li>
<li>
<p><a id="Gorman2004"></a>[Gorman2004]
Gorman, M. «Understanding the Linux Virtual Memory Manager». Prentice Hall, 2004.</p>
</li>
</ul>
</div>
<div class="ulist bibliography">
<ul class="bibliography">
<li>
<p><a id="Hailperin2006"></a>[Hailperin2006]
Hailperin, M. «Operating Systems and Middleware: Supporting Controlled Interaction». Course Technology, 2006.</p>
</li>
<li>
<p><a id="Jacob1998"></a>[Jacob1998]
Jacob, B y Mudge, T. «Virtual Memory: Issues of Implementation». Computer, 31:33-43, 1998. ISSN 0018-9162. DOI: 10.1109/2.683005. URL <a href="http://dx.doi.org/10.1109/2.683005" class="bare">http://dx.doi.org/10.1109/2.683005</a>.</p>
</li>
</ul>
</div>
<div class="ulist bibliography">
<ul class="bibliography">
<li>
<p><a id="Microsoft2005"></a>[Microsoft2005]
«Kernel Enhancements for Microsoft Windows Vista and Windows Server Longhorn» [en línea]. Microsoft Corporation, 2005. URL <a href="https://www.slideserve.com/iolani/kernel-enhancements-for-windows-server-longhorn" class="bare">https://www.slideserve.com/iolani/kernel-enhancements-for-windows-server-longhorn</a>.</p>
</li>
</ul>
</div>
<div class="ulist bibliography">
<ul class="bibliography">
<li>
<p><a id="Microsoft2003"></a>[Microsoft2003]
«Kernel Enhancements for Windows XP» [en línea]. Microsoft Corporation, 2003 [2006]. URL <a href="http://goo.gl/ugED" class="bare">http://goo.gl/ugED</a>.</p>
</li>
</ul>
</div>
<div class="ulist bibliography">
<ul class="bibliography">
<li>
<p><a id="SGI2006"></a>[SGI2006]
«XFS Filesystem Structure» [en línea]. Silicon Graphics Inc, 2006 [2007]. URL <a href="https://goo.gl/YF82JB" class="bare">https://goo.gl/YF82JB</a></p>
</li>
<li>
<p><a id="Silberschatz2004"></a>[Silberschatz2004]
Silberschatz, A., Galvin, P. y Gagne, G. <a href="http://absysnetweb.bbtk.ull.es/cgi-bin/abnetopac?ACC=DOSEARCH&amp;xsqf99=184173.titn./">«Operating System Concepts with Java»</a>. 6º ed. John Wiley &amp; Sons Inc., 2004.</p>
</li>
<li>
<p><a id="Silberschatz2005"></a>[Silberschatz2005]
Silberschatz, A., Galvin, P. y Gagne, G. <a href="http://absysnetweb.bbtk.ull.es/cgi-bin/abnetopac?ACC=DOSEARCH&amp;xsqf99=345629.titn./">«Fundamentos de Sistemas Operativos»</a>. 7ª ed. McGraw Hill, 2005.</p>
</li>
<li>
<p><a id="Wikipedia-cmalloc"></a>[Wikipedia-cmalloc]
«C dynamic memory allocation» [en línea]. Wikipedia (en), [2011]. URL <a href="http://goo.gl/OkFJ3" class="bare">http://goo.gl/OkFJ3</a></p>
</li>
</ul>
</div>
<div class="ulist bibliography">
<ul class="bibliography">
<li>
<p><a id="Wikipedia-RAID"></a>[Wikipedia-RAID]
«RAID» [en línea]. Wikipedia (en), [2011]. URL <a href="http://goo.gl/GTQU" class="bare">http://goo.gl/GTQU</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="footnotes">
<hr>
<div class="footnote" id="_footnotedef_1">
<a href="#_footnoteref_1">1</a>. POSIX Threads se implementa en el núcleo en los sistemas Linux y en la mayor parte de los UNIX actuales.
</div>
<div class="footnote" id="_footnotedef_2">
<a href="#_footnoteref_2">2</a>. Más información de Stackless Python: <a href="http://www.stackless.com/" class="bare">http://www.stackless.com/</a>
</div>
<div class="footnote" id="_footnotedef_3">
<a href="#_footnoteref_3">3</a>. Más información de GNU Pthreads: <a href="http://www.gnu.org/software/pth/" class="bare">http://www.gnu.org/software/pth/</a>.
</div>
<div class="footnote" id="_footnotedef_4">
<a href="#_footnoteref_4">4</a>. De ahora en adelante, cuando usemos el término función nos estaremos refiriendo a cualquier procedimiento, función, método, subprograma, subrutina o rutina del programa.
</div>
<div class="footnote" id="_footnotedef_5">
<a href="#_footnoteref_5">5</a>. Una operación o conjunto de operaciones es atómica o no interrumpible si de cara al resto del sistema parece que la operación ocurre de forma instantánea e indivisible.
</div>
<div class="footnote" id="_footnotedef_6">
<a href="#_footnoteref_6">6</a>. En la literatura sobre algoritmos de planificación de la CPU se indica que SJF (<em>Shortest-Job First</em>) y SRTF (<em>Shortest-Remaing-Time First</em>) son los óptimos respecto al tiempo de espera promedio precisamente porque siempre escogen al proceso con la ráfaga de CPU más corta de entre los que esperan en la cola de preparados.
</div>
<div class="footnote" id="_footnotedef_7">
<a href="#_footnoteref_7">7</a>. Los algoritmos FCFS y RR se pueden combinar de múltiples maneras. En algunos sistemas todas las colas son o bien FCFS o bien RR, mientras que en otros unas colas pueden ser de un tipo y otras del otro. Por ejemplo, en el núcleo Linux las prioridades más altas —las etiquetadas como de tiempo real— tienen tanto una cola FCFS como una cola RR. En cada prioridad primero se planifican los procesos de la cola FCFS y después lo de la cola RR.
</div>
<div class="footnote" id="_footnotedef_8">
<a href="#_footnoteref_8">8</a>. Por ejemplo, dados tres procesos con una duración cada uno de ellos de 10 unidades de tiempo y cuanto igual a 1, el tiempo de ejecución promedio será de 29 unidades. Sin embargo si el cuanto de tiempo fuera 10, el tiempo de ejecución promedio caería a 20 unidades de tiempo.
</div>
<div class="footnote" id="_footnotedef_9">
<a href="#_footnoteref_9">9</a>. De manera práctica actualmente se utilizan tiempos de cuanto de entre 10 y 100 ms. Estos tiempos son mucho mayores que los tiempos de cambios de contexto, que generalmente son inferiores a 10µs.
</div>
<div class="footnote" id="_footnotedef_10">
<a href="#_footnoteref_10">10</a>. Microsoft Windows, macOS, Oracle/Sun Microsystems Solaris, las versiones de Linux anteriores a la 2.6.23 y, en general, casi la totalidad de los sistemas operativos modernos de propósito general utilizan este tipo de planificación de prioridades dinámicas con RR como planificador en cada prioridad.
</div>
<div class="footnote" id="_footnotedef_11">
<a href="#_footnoteref_11">11</a>. Linux desde la versión 2.6.23 utiliza un tipo de <strong>planificador equitativo ponderado</strong> denominado <strong>CFS</strong> (<em>Completely Fair Scheduler</em>) o <strong>planificador completamente justo.</strong>
</div>
<div class="footnote" id="_footnotedef_12">
<a href="#_footnoteref_12">12</a>. Linux, Microsoft Windows y la mayor parte de los sistemas operativos modernos de propósito general dividen el rango de prioridades en dos partes. El conjunto de prioridades más altas son prioridades de tiempo real y por tanto son fijas. Mientras que el grupo de prioridades más bajas son de tiempo no real y dinámicas. Además el planificador se implementa de tal manera que un proceso con prioridad dinámica nunca puede alcanzar el rango de prioridades de tiempo real.
</div>
<div class="footnote" id="_footnotedef_13">
<a href="#_footnoteref_13">13</a>. Un ejemplo de lo contrario —de sistema heterogéneo— se puede observar en los PC modernos donde muchos disponen tanto de una CPU como de una GPU especializada en el procesamiento de gráficos y en las operaciones de coma flotante.
</div>
<div class="footnote" id="_footnotedef_14">
<a href="#_footnoteref_14">14</a>. El <em>HyperThreading</em> disponible en algunos procesadores de Intel es una implementación de la tecnología <em>Simultaneous Multithreading</em>.
</div>
<div class="footnote" id="_footnotedef_15">
<a href="#_footnoteref_15">15</a>. En los sistemas de <em>multiprocesamiento asimétrico</em> hay una CPU maestra y varias esclavas a quienes la primera entrega el trabajo. En ocasiones las CPU esclavas se distinguen por haber sido diseñadas para realizar algún tipo de trabajo de forma eficiente —como es el caso las GPU, que no son sino CPU diseñadas para el procesamiento de gráficos— o por el hardware al que están conectadas —como por ejemplo las CPU unidas a discos para gestionarlos—.
</div>
<div class="footnote" id="_footnotedef_16">
<a href="#_footnoteref_16">16</a>. En los sistemas de <em>multiprocesamiento simétrico</em> o <em>SMP</em> (<em>Symmetric Multiprocessing</em>) todos los procesadores son iguales. Todos comparten los mismos recursos, pueden acceder a los mismos dispositivos y cada uno ejecuta una copia del núcleo del sistema operativo. Por lo tanto el sistema operativo debe saber compartir los recursos y repartir la carga entre las CPU. Casi todos los sistemas multiprocesador modernos son de este tipo.
</div>
<div class="footnote" id="_footnotedef_17">
<a href="#_footnoteref_17">17</a>. Desde el Intel Pentium las CPU de la familia x86 incorporan un contador de marca de tiempo (Time Stamp Counter o TSC) de 64 bits que indica el número de ciclos transcurridos desde el último <em>reset</em> del procesador.
</div>
<div class="footnote" id="_footnotedef_18">
<a href="#_footnoteref_18">18</a>. La solución a este problema pasa porque la CPU disponga de una eficiente y pequeña —de entre 64 y 1024 entradas— memoria caché en la que almacenar las entradas de la tabla de página previamente utilizadas en la traducción de las direcciones. A dicha caché se la denomina TLB (Translation Look-aside Buffer). Obviamente es necesario que el asignador borre la TLB durante los cambios de contexto.
</div>
<div class="footnote" id="_footnotedef_19">
<a href="#_footnoteref_19">19</a>. Se trata de una aproximación puesto que usando el <em>bit de referencia</em> el sistema operativo no puede conocer con exactitud la última vez que una página fue utilizada. Sin embargo, aunque existen soluciones exactas que hacen uso de un contador o de una pila que se actualiza en cada acceso a las páginas, se trata de soluciones muy costosas como para ser implementarlas en hardware.
</div>
<div class="footnote" id="_footnotedef_20">
<a href="#_footnoteref_20">20</a>. Es común que los núcleos de los sistemas operativos utilicen páginas de gran tamaño para alojar su código y sus datos. De esta forma se minimiza el número de entradas de la TLB que utilizan, con el fin de disponer de más entradas libres para los procesos en ejecución.
</div>
<div class="footnote" id="_footnotedef_21">
<a href="#_footnoteref_21">21</a>. En RAID se denomina división o stripe a la serie de bloques consecutivos escogido cada uno de uno de los discos del conjunto.
</div>
<div class="footnote" id="_footnotedef_22">
<a href="#_footnoteref_22">22</a>. En algunos entornos se denomina a este tipo de implementaciones <em>fakeRAID</em> o <em>hostRAID</em>.
</div>
<div class="footnote" id="_footnotedef_23">
<a href="#_footnoteref_23">23</a>. Dependiendo de la unidad de disco, los sectores pueden tener tamaños de entre 32 bytes y 4096 bytes. Lo más común es que su tamaño sea de 512 bytes.
</div>
<div class="footnote" id="_footnotedef_24">
<a href="#_footnoteref_24">24</a>. Generalmente el sistema mantiene un puntero de lectura/escritura que hace referencia a la ubicación dentro del archivo en la que debe tener lugar la siguiente operación. Este puntero se actualiza avanzando cada vez que se realiza un nueva lectura/escritura. Para desplazarse aleatoriamente por el archivo, el sistema operativo debe ofrecer una llamada al sistema que permita reposicionar el puntero allí donde interese.
</div>
<div class="footnote" id="_footnotedef_25">
<a href="#_footnoteref_25">25</a>. En unos pocos sistemas los archivos se abren automáticamente cuando un proceso solicita su primera operación sobre los mismos y se cierran cuando el proceso termina. Sin embargo lo más común es que los procesos tengan que abrir los archivos explícitamente.
</div>
<div class="footnote" id="_footnotedef_26">
<a href="#_footnoteref_26">26</a>. La recolección de basura implica recorrer todo el sistema de archivos y marcar todos aquellos elementos que sean accesibles. Después, en una segunda pasada, se elimina todo lo que no esté marcado.
</div>
<div class="footnote" id="_footnotedef_27">
<a href="#_footnoteref_27">27</a>. El registro generalmente se almacena en el mismo sistema de archivos. Sin embargo también <em>suele ser</em> posible almacenarlo en otro volumen o incluso en otro disco.
</div>
</div>
<div id="footer">
<div id="footer-text">
Última actualización 2020-10-03 02:03:12 +0100
</div>
</div>
<style>
pre.rouge table td { padding: 5px; }
pre.rouge table pre { margin: 0; }
pre.rouge .cm {
  color: #999988;
  font-style: italic;
}
pre.rouge .cp {
  color: #999999;
  font-weight: bold;
}
pre.rouge .c1 {
  color: #999988;
  font-style: italic;
}
pre.rouge .cs {
  color: #999999;
  font-weight: bold;
  font-style: italic;
}
pre.rouge .c, pre.rouge .ch, pre.rouge .cd, pre.rouge .cpf {
  color: #999988;
  font-style: italic;
}
pre.rouge .err {
  color: #a61717;
  background-color: #e3d2d2;
}
pre.rouge .gd {
  color: #000000;
  background-color: #ffdddd;
}
pre.rouge .ge {
  color: #000000;
  font-style: italic;
}
pre.rouge .gr {
  color: #aa0000;
}
pre.rouge .gh {
  color: #999999;
}
pre.rouge .gi {
  color: #000000;
  background-color: #ddffdd;
}
pre.rouge .go {
  color: #888888;
}
pre.rouge .gp {
  color: #555555;
}
pre.rouge .gs {
  font-weight: bold;
}
pre.rouge .gu {
  color: #aaaaaa;
}
pre.rouge .gt {
  color: #aa0000;
}
pre.rouge .kc {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kd {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kn {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kp {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kr {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kt {
  color: #445588;
  font-weight: bold;
}
pre.rouge .k, pre.rouge .kv {
  color: #000000;
  font-weight: bold;
}
pre.rouge .mf {
  color: #009999;
}
pre.rouge .mh {
  color: #009999;
}
pre.rouge .il {
  color: #009999;
}
pre.rouge .mi {
  color: #009999;
}
pre.rouge .mo {
  color: #009999;
}
pre.rouge .m, pre.rouge .mb, pre.rouge .mx {
  color: #009999;
}
pre.rouge .sb {
  color: #d14;
}
pre.rouge .sc {
  color: #d14;
}
pre.rouge .sd {
  color: #d14;
}
pre.rouge .s2 {
  color: #d14;
}
pre.rouge .se {
  color: #d14;
}
pre.rouge .sh {
  color: #d14;
}
pre.rouge .si {
  color: #d14;
}
pre.rouge .sx {
  color: #d14;
}
pre.rouge .sr {
  color: #009926;
}
pre.rouge .s1 {
  color: #d14;
}
pre.rouge .ss {
  color: #990073;
}
pre.rouge .s, pre.rouge .sa, pre.rouge .dl {
  color: #d14;
}
pre.rouge .na {
  color: #008080;
}
pre.rouge .bp {
  color: #999999;
}
pre.rouge .nb {
  color: #0086B3;
}
pre.rouge .nc {
  color: #445588;
  font-weight: bold;
}
pre.rouge .no {
  color: #008080;
}
pre.rouge .nd {
  color: #3c5d5d;
  font-weight: bold;
}
pre.rouge .ni {
  color: #800080;
}
pre.rouge .ne {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nf, pre.rouge .fm {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nl {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nn {
  color: #555555;
}
pre.rouge .nt {
  color: #000080;
}
pre.rouge .vc {
  color: #008080;
}
pre.rouge .vg {
  color: #008080;
}
pre.rouge .vi {
  color: #008080;
}
pre.rouge .nv, pre.rouge .vm {
  color: #008080;
}
pre.rouge .ow {
  color: #000000;
  font-weight: bold;
}
pre.rouge .o {
  color: #000000;
  font-weight: bold;
}
pre.rouge .w {
  color: #bbbbbb;
}
pre.rouge {
  background-color: #f8f8f8;
}
</style>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>